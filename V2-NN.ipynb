{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erc2A41DMzku"
   },
   "source": [
    "# DSBA 22/23 HSE & University of London\n",
    "\n",
    "# Practical assignment 1. DL in classification.\n",
    "\n",
    "## General info\n",
    "Release data: 26.09.2022\n",
    "\n",
    "Soft deadline: 10.10.2022 23:59 MSK\n",
    "\n",
    "Hard deadline: 13.10.2021 23:59 MSK\n",
    "\n",
    "In this task, you are to build a NN for a binary classification task. We suggest using Google Colab for access to GPU. Competition invite link: https://www.kaggle.com/t/1917e22edb71437ca24d790ab1d57695\n",
    "\n",
    "## Evaluation and fines\n",
    "\n",
    "Each section has a defined \"value\" (in brackets near the section). Maximum grade for the task - 10 points, other points can be assigned to your tests.\n",
    "\n",
    "**Your notebook with the best solution must be reproducible should be sent to the dropbox!** If the assessor cannot reproduce your results, you may be assigned score = 0, so make all your computations fixed!\n",
    "\n",
    "**You can only use neural networks / linear / nearest neighbors models for this task - tree-based models are forbidden!**\n",
    "\n",
    "All the parts must be done independently.\n",
    "\n",
    "After the hard deadline is passed, the hometask is not accepted. If you send the hometask after the soft deadline, you will be excluded from competition among your mates and the homework will only be scored by the \"Beating the baseline\" part.\n",
    "\n",
    "Feel free to ask questions both the teacher and your mates, but __do not copy the code or do it together__. \"Similar\" solutions are considered a plagiarism and all the involved students (the ones who gave & the ones who did) cannot get more than 0.01 points for the task. If you found a solution in some open source, you __must__ reference it in a special block at the end of your work (to exclude the suspicions in plagiarism).\n",
    "\n",
    "\n",
    "## Format of handing over\n",
    "\n",
    "The tasks are sent to the dropbox: https://www.dropbox.com/request/Y6TJouxNbm3r0RgcBL35. Don't forget to attach your name, surname & your group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwMZDBm4S9o3"
   },
   "source": [
    "## 1. Model training\n",
    "\n",
    "**Important!** Public Leaderboard contains only 33% of the test data. Your points will be measured wrt to the whole test set, therefore your position on the LB after the end of the competition may change.\n",
    "\n",
    "* test_accuracy > weak baseline (public LB): 3 points\n",
    "\n",
    "* test_accuracy > medium baseline (public LB): + 3 points\n",
    "\n",
    "* test_accuracy > strong baseline (public LB): + 2 points\n",
    "\n",
    "* You are among 25% most successful students (private LB): + 2 point\n",
    "\n",
    "* You are among top-3 most successful students (private LB): + 1 point\n",
    "\n",
    "* You are among top-2 most successful students (private LB): + 1 point\n",
    "\n",
    "* You are among top-1 most successful students (private LB): + 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "VnJmCRD8S9o3"
   },
   "outputs": [],
   "source": [
    "# Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "WLBmP2zTFmnB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "c6tn9gN7ohs9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "3Tj4gkZnWENb"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "LudqW7xct2rH"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9PHJ1f-gPTm"
   },
   "source": [
    "# **Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "P3YAH9EgS9o3"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "target_df = pd.read_csv('train_target.csv')\n",
    "train_expected_target1 = pd.read_csv('train_expected_target_agent_1.csv')\n",
    "train_expected_target2 = pd.read_csv('train_expected_target_agent_2.csv')\n",
    "train_target_agent_1 = pd.read_csv('train_target_agent_1.csv')\n",
    "train_target_agent_2 = pd.read_csv('train_target_agent_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_agent_1 = train_target_agent_1.rename(columns={\"0\": \"expected_target1\"})\n",
    "train_target_agent_2 = train_target_agent_2.rename(columns={\"0\": \"expected_target2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_target_agent_1, train_target_agent_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "XtxGrhyjVEee",
    "outputId": "d81db566-83f9-47d1-c8e8-4c9333b09d31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>agent_1_feat_ODC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>14.16</td>\n",
       "      <td>267.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>7.66</td>\n",
       "      <td>191.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.53</td>\n",
       "      <td>195.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>8.76</td>\n",
       "      <td>161.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.8                85.1                     15.8   \n",
       "1                      44.8                71.1                     23.4   \n",
       "2                      46.3                70.8                     21.7   \n",
       "3                      50.2                77.5                     24.4   \n",
       "4                      44.9                75.0                     17.2   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.99               1.143700                0.928715   \n",
       "1                 6.84               0.954159                0.975350   \n",
       "2                 6.77               0.918434                1.118603   \n",
       "3                 6.87               1.037613                0.956836   \n",
       "4                 6.77               0.983691                0.948837   \n",
       "\n",
       "   agent_1_feat_PPDA  agent_1_feat_OPPDA  agent_1_feat_DC  agent_1_feat_ODC  \\\n",
       "0               7.13               14.16            267.0             194.0   \n",
       "1               9.99                7.66            191.0             287.0   \n",
       "2               9.56                7.34            179.0             298.0   \n",
       "3               9.60                9.53            195.0             239.0   \n",
       "4              12.24                8.76            161.0             283.0   \n",
       "\n",
       "   ...  agent_2_feattotal_xg_1  agent_2_feattotal_xg_mean_3  \\\n",
       "0  ...                2.739439                     2.739439   \n",
       "1  ...                2.336756                     2.336756   \n",
       "2  ...                2.120322                     2.120322   \n",
       "3  ...                2.216415                     2.216415   \n",
       "4  ...                2.604025                     2.604025   \n",
       "\n",
       "   agent_2_feattotal_xg_mean  agent_2_featboth_scored_3  \\\n",
       "0                        NaN                   0.473684   \n",
       "1                        NaN                   0.578947   \n",
       "2                        NaN                   0.368421   \n",
       "3                        NaN                   0.210526   \n",
       "4                        NaN                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_2  agent_2_featboth_scored_1  \\\n",
       "0                   0.473684                   0.473684   \n",
       "1                   0.578947                   0.578947   \n",
       "2                   0.368421                   0.368421   \n",
       "3                   0.210526                   0.210526   \n",
       "4                   0.421053                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_mean_3  agent_2_featboth_scored_mean  \\\n",
       "0                        0.473684                           NaN   \n",
       "1                        0.578947                           NaN   \n",
       "2                        0.368421                           NaN   \n",
       "3                        0.210526                           NaN   \n",
       "4                        0.421053                           NaN   \n",
       "\n",
       "   expected_target1  expected_target2  \n",
       "0                 1                 2  \n",
       "1                 2                 2  \n",
       "2                 0                 1  \n",
       "3                 0                 1  \n",
       "4                 2                 2  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "fi9w8WcKVID2",
    "outputId": "3acc7dd6-6503-4c25-ccee-9bbc933f764b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>agent_1_feat_ODC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_3</th>\n",
       "      <th>agent_2_feattotal_xg_2</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.844742</td>\n",
       "      <td>1.165049</td>\n",
       "      <td>9.19</td>\n",
       "      <td>16.50</td>\n",
       "      <td>337.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.661870</td>\n",
       "      <td>1.893116</td>\n",
       "      <td>4.241360</td>\n",
       "      <td>2.932115</td>\n",
       "      <td>2.690442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.7</td>\n",
       "      <td>81.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>1.152593</td>\n",
       "      <td>10.31</td>\n",
       "      <td>13.63</td>\n",
       "      <td>311.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.550724</td>\n",
       "      <td>2.373700</td>\n",
       "      <td>4.197010</td>\n",
       "      <td>3.373811</td>\n",
       "      <td>3.075302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.3</td>\n",
       "      <td>81.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.954509</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>14.21</td>\n",
       "      <td>11.82</td>\n",
       "      <td>207.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.693652</td>\n",
       "      <td>2.042668</td>\n",
       "      <td>0.966665</td>\n",
       "      <td>1.900995</td>\n",
       "      <td>3.007033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.5</td>\n",
       "      <td>84.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1.155612</td>\n",
       "      <td>1.049618</td>\n",
       "      <td>10.95</td>\n",
       "      <td>12.46</td>\n",
       "      <td>339.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.938100</td>\n",
       "      <td>1.466409</td>\n",
       "      <td>0.922046</td>\n",
       "      <td>2.108852</td>\n",
       "      <td>2.643923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>6.81</td>\n",
       "      <td>1.199718</td>\n",
       "      <td>0.856327</td>\n",
       "      <td>11.27</td>\n",
       "      <td>11.52</td>\n",
       "      <td>193.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.358338</td>\n",
       "      <td>2.138405</td>\n",
       "      <td>1.872476</td>\n",
       "      <td>2.456406</td>\n",
       "      <td>3.113815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.6                87.0                     15.2   \n",
       "1                      50.7                81.3                     14.2   \n",
       "2                      47.3                81.4                     17.7   \n",
       "3                      54.5                84.8                     14.5   \n",
       "4                      51.3                81.8                     16.4   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.83               0.844742                1.165049   \n",
       "1                 6.65               0.743218                1.152593   \n",
       "2                 6.73               0.954509                0.956938   \n",
       "3                 6.85               1.155612                1.049618   \n",
       "4                 6.81               1.199718                0.856327   \n",
       "\n",
       "   agent_1_feat_PPDA  agent_1_feat_OPPDA  agent_1_feat_DC  agent_1_feat_ODC  \\\n",
       "0               9.19               16.50            337.0             179.0   \n",
       "1              10.31               13.63            311.0             208.0   \n",
       "2              14.21               11.82            207.0             270.0   \n",
       "3              10.95               12.46            339.0             186.0   \n",
       "4              11.27               11.52            193.0             293.0   \n",
       "\n",
       "   ...  agent_2_feattotal_xg_3  agent_2_feattotal_xg_2  \\\n",
       "0  ...                2.661870                1.893116   \n",
       "1  ...                3.550724                2.373700   \n",
       "2  ...                2.693652                2.042668   \n",
       "3  ...                3.938100                1.466409   \n",
       "4  ...                3.358338                2.138405   \n",
       "\n",
       "   agent_2_feattotal_xg_1  agent_2_feattotal_xg_mean_3  \\\n",
       "0                4.241360                     2.932115   \n",
       "1                4.197010                     3.373811   \n",
       "2                0.966665                     1.900995   \n",
       "3                0.922046                     2.108852   \n",
       "4                1.872476                     2.456406   \n",
       "\n",
       "   agent_2_feattotal_xg_mean  agent_2_featboth_scored_3  \\\n",
       "0                   2.690442                        1.0   \n",
       "1                   3.075302                        0.0   \n",
       "2                   3.007033                        0.0   \n",
       "3                   2.643923                        1.0   \n",
       "4                   3.113815                        0.0   \n",
       "\n",
       "   agent_2_featboth_scored_2  agent_2_featboth_scored_1  \\\n",
       "0                        0.0                        1.0   \n",
       "1                        1.0                        1.0   \n",
       "2                        1.0                        1.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   agent_2_featboth_scored_mean_3  agent_2_featboth_scored_mean  \n",
       "0                        0.666667                      0.333333  \n",
       "1                        0.666667                      0.625000  \n",
       "2                        0.666667                      0.555556  \n",
       "3                        0.333333                      0.444444  \n",
       "4                        0.000000                      0.555556  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WlvCdFqVUSf",
    "outputId": "95181e8f-d145-49d6-8c1f-7520814b665c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2470, 236)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjIbnhiPVYT-",
    "outputId": "8c96af8c-bf60-401c-b737-9294f66f3cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2470 entries, 0 to 2469\n",
      "Columns: 236 entries, agent_1_feat_Possession% to expected_target2\n",
      "dtypes: float64(212), int64(24)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "ceY_OeBgqdO8"
   },
   "outputs": [],
   "source": [
    "target_df.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "p0N_mUFAqMIj"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([target_df, train_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "1TZbR6awq_C9",
    "outputId": "12ad58c1-8a7b-4bb0-dff6-5aac2487450b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>14.16</td>\n",
       "      <td>267.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>7.66</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.53</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>8.76</td>\n",
       "      <td>161.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.032989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.684860</td>\n",
       "      <td>4.024907</td>\n",
       "      <td>3.872622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1</td>\n",
       "      <td>42.9</td>\n",
       "      <td>76.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.066236</td>\n",
       "      <td>16.14</td>\n",
       "      <td>7.60</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568175</td>\n",
       "      <td>2.000313</td>\n",
       "      <td>2.572016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.026472</td>\n",
       "      <td>15.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.871643</td>\n",
       "      <td>2.496854</td>\n",
       "      <td>2.555157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1</td>\n",
       "      <td>51.4</td>\n",
       "      <td>79.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.161401</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.47</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.904164</td>\n",
       "      <td>2.977092</td>\n",
       "      <td>2.495116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>13.16</td>\n",
       "      <td>9.72</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.945618</td>\n",
       "      <td>3.414186</td>\n",
       "      <td>2.861741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2470 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  agent_1_feat_Possession%  agent_1_feat_Pass%  \\\n",
       "0            1                      58.8                85.1   \n",
       "1            1                      44.8                71.1   \n",
       "2            0                      46.3                70.8   \n",
       "3            0                      50.2                77.5   \n",
       "4            1                      44.9                75.0   \n",
       "...        ...                       ...                 ...   \n",
       "2465         1                      41.6                76.0   \n",
       "2466         1                      42.9                76.1   \n",
       "2467         0                      41.0                72.2   \n",
       "2468         1                      51.4                79.3   \n",
       "2469         1                      43.5                71.6   \n",
       "\n",
       "      agent_1_feat_AerialsWon  agent_1_feat_Rating  agent_1_feat_XGrealiz  \\\n",
       "0                        15.8                 6.99               1.143700   \n",
       "1                        23.4                 6.84               0.954159   \n",
       "2                        21.7                 6.77               0.918434   \n",
       "3                        24.4                 6.87               1.037613   \n",
       "4                        17.2                 6.77               0.983691   \n",
       "...                       ...                  ...                    ...   \n",
       "2465                     17.1                 6.62               1.046406   \n",
       "2466                     18.3                 6.61               1.161802   \n",
       "2467                     19.1                 6.51               1.000858   \n",
       "2468                     14.1                 6.62               1.037986   \n",
       "2469                     23.4                 6.64               0.865460   \n",
       "\n",
       "      agent_1_feat_XGArealiz  agent_1_feat_PPDA  agent_1_feat_OPPDA  \\\n",
       "0                   0.928715               7.13               14.16   \n",
       "1                   0.975350               9.99                7.66   \n",
       "2                   1.118603               9.56                7.34   \n",
       "3                   0.956836               9.60                9.53   \n",
       "4                   0.948837              12.24                8.76   \n",
       "...                      ...                ...                 ...   \n",
       "2465                1.032989              18.00                8.27   \n",
       "2466                1.066236              16.14                7.60   \n",
       "2467                1.026472              15.99                7.99   \n",
       "2468                1.161401               9.73               10.47   \n",
       "2469                0.931256              13.16                9.72   \n",
       "\n",
       "      agent_1_feat_DC  ...  agent_2_feattotal_xg_1  \\\n",
       "0               267.0  ...                2.739439   \n",
       "1               191.0  ...                2.336756   \n",
       "2               179.0  ...                2.120322   \n",
       "3               195.0  ...                2.216415   \n",
       "4               161.0  ...                2.604025   \n",
       "...               ...  ...                     ...   \n",
       "2465            138.0  ...                3.684860   \n",
       "2466            201.0  ...                1.568175   \n",
       "2467            164.0  ...                3.871643   \n",
       "2468            222.0  ...                4.904164   \n",
       "2469            233.0  ...                3.945618   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "0                        2.739439                        NaN   \n",
       "1                        2.336756                        NaN   \n",
       "2                        2.120322                        NaN   \n",
       "3                        2.216415                        NaN   \n",
       "4                        2.604025                        NaN   \n",
       "...                           ...                        ...   \n",
       "2465                     4.024907                   3.872622   \n",
       "2466                     2.000313                   2.572016   \n",
       "2467                     2.496854                   2.555157   \n",
       "2468                     2.977092                   2.495116   \n",
       "2469                     3.414186                   2.861741   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "0                      0.473684                   0.473684   \n",
       "1                      0.578947                   0.578947   \n",
       "2                      0.368421                   0.368421   \n",
       "3                      0.210526                   0.210526   \n",
       "4                      0.421053                   0.421053   \n",
       "...                         ...                        ...   \n",
       "2465                   1.000000                   0.000000   \n",
       "2466                   0.000000                   0.000000   \n",
       "2467                   0.000000                   0.000000   \n",
       "2468                   1.000000                   0.000000   \n",
       "2469                   1.000000                   1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "0                      0.473684                        0.473684   \n",
       "1                      0.578947                        0.578947   \n",
       "2                      0.368421                        0.368421   \n",
       "3                      0.210526                        0.210526   \n",
       "4                      0.421053                        0.421053   \n",
       "...                         ...                             ...   \n",
       "2465                   0.000000                        0.333333   \n",
       "2466                   0.000000                        0.000000   \n",
       "2467                   1.000000                        0.333333   \n",
       "2468                   0.000000                        0.333333   \n",
       "2469                   0.000000                        0.666667   \n",
       "\n",
       "      agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "0                              NaN                 1                 2  \n",
       "1                              NaN                 2                 2  \n",
       "2                              NaN                 0                 1  \n",
       "3                              NaN                 0                 1  \n",
       "4                              NaN                 2                 2  \n",
       "...                            ...               ...               ...  \n",
       "2465                      0.444444                 1                 2  \n",
       "2466                      0.444444                 2                 3  \n",
       "2467                      0.500000                 0                 5  \n",
       "2468                      0.222222                 1                 3  \n",
       "2469                      0.333333                 3                 2  \n",
       "\n",
       "[2470 rows x 237 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VaUeSE29_6w"
   },
   "source": [
    "## Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "CkheOAfn_zOK",
    "outputId": "000d0384-64b4-4d66-f341-0a872abe165e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_expected_target2</th>\n",
       "      <th>train_expected_target1</th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278076</td>\n",
       "      <td>1.166350</td>\n",
       "      <td>1</td>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613273</td>\n",
       "      <td>1.278300</td>\n",
       "      <td>1</td>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.117570</td>\n",
       "      <td>1.900670</td>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991901</td>\n",
       "      <td>1.683430</td>\n",
       "      <td>1</td>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_expected_target2  train_expected_target1  category  \\\n",
       "0                0.278076                1.166350         1   \n",
       "1                0.613273                1.278300         1   \n",
       "2                1.117570                1.900670         0   \n",
       "3                0.909774                0.423368         0   \n",
       "4                0.991901                1.683430         1   \n",
       "\n",
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.8                85.1                     15.8   \n",
       "1                      44.8                71.1                     23.4   \n",
       "2                      46.3                70.8                     21.7   \n",
       "3                      50.2                77.5                     24.4   \n",
       "4                      44.9                75.0                     17.2   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.99               1.143700                0.928715   \n",
       "1                 6.84               0.954159                0.975350   \n",
       "2                 6.77               0.918434                1.118603   \n",
       "3                 6.87               1.037613                0.956836   \n",
       "4                 6.77               0.983691                0.948837   \n",
       "\n",
       "   agent_1_feat_PPDA  ...  agent_2_feattotal_xg_1  \\\n",
       "0               7.13  ...                2.739439   \n",
       "1               9.99  ...                2.336756   \n",
       "2               9.56  ...                2.120322   \n",
       "3               9.60  ...                2.216415   \n",
       "4              12.24  ...                2.604025   \n",
       "\n",
       "   agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "0                     2.739439                        NaN   \n",
       "1                     2.336756                        NaN   \n",
       "2                     2.120322                        NaN   \n",
       "3                     2.216415                        NaN   \n",
       "4                     2.604025                        NaN   \n",
       "\n",
       "   agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "0                   0.473684                   0.473684   \n",
       "1                   0.578947                   0.578947   \n",
       "2                   0.368421                   0.368421   \n",
       "3                   0.210526                   0.210526   \n",
       "4                   0.421053                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "0                   0.473684                        0.473684   \n",
       "1                   0.578947                        0.578947   \n",
       "2                   0.368421                        0.368421   \n",
       "3                   0.210526                        0.210526   \n",
       "4                   0.421053                        0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "0                           NaN                 1                 2  \n",
       "1                           NaN                 2                 2  \n",
       "2                           NaN                 0                 1  \n",
       "3                           NaN                 0                 1  \n",
       "4                           NaN                 2                 2  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_expected_target1 = train_expected_target1.rename(columns={\"0\": \"train_expected_target1\"})\n",
    "train_expected_target2 = train_expected_target2.rename(columns={\"0\": \"train_expected_target2\"})\n",
    "train_df = pd.concat([train_expected_target1, train_df], axis = 1)\n",
    "train_df = pd.concat([train_expected_target2, train_df], axis = 1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJHCElVu-906",
    "outputId": "df35fdc8-6e8d-4af7-9ecf-e96d0c76a9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deleting:  2470\n",
      "Rows after deleting:  2295\n"
     ]
    }
   ],
   "source": [
    "print('Rows before deleting: ', train_df.shape[0])\n",
    "train_df = train_df.drop(train_df[(train_df.train_expected_target2 > 1) &\n",
    "                                  (train_df.train_expected_target1 > 1) &\n",
    "                                  (train_df.category == 0)].index)\n",
    "train_df.drop(['train_expected_target1', 'train_expected_target2'], axis = 1, inplace = True)\n",
    "print('Rows after deleting: ', train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ruuBsKl75SR"
   },
   "source": [
    "## Work with missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc2PbEGDRIjw",
    "outputId": "3042e755-cbf8-4661-ac14-71b4a75e601c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deleting:  2295\n",
      "Rows after deleting:  2163\n"
     ]
    }
   ],
   "source": [
    "print('Rows before deleting: ', train_df.shape[0])\n",
    "train_df = train_df.dropna()  \n",
    "print('Rows after deleting: ', train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>25.1</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.711201</td>\n",
       "      <td>0.915529</td>\n",
       "      <td>10.74</td>\n",
       "      <td>9.43</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.608046</td>\n",
       "      <td>2.112304</td>\n",
       "      <td>1.608046</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>15.9</td>\n",
       "      <td>7.07</td>\n",
       "      <td>1.094698</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>7.57</td>\n",
       "      <td>13.92</td>\n",
       "      <td>575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479335</td>\n",
       "      <td>2.214160</td>\n",
       "      <td>2.479335</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>48.1</td>\n",
       "      <td>76.9</td>\n",
       "      <td>17.7</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.994530</td>\n",
       "      <td>1.235052</td>\n",
       "      <td>9.77</td>\n",
       "      <td>8.24</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.712261</td>\n",
       "      <td>2.183093</td>\n",
       "      <td>1.712261</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.675331</td>\n",
       "      <td>2.627794</td>\n",
       "      <td>2.675331</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>50.7</td>\n",
       "      <td>82.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.124694</td>\n",
       "      <td>0.875939</td>\n",
       "      <td>11.79</td>\n",
       "      <td>10.66</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>2.260683</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.032989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.684860</td>\n",
       "      <td>4.024907</td>\n",
       "      <td>3.872622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1</td>\n",
       "      <td>42.9</td>\n",
       "      <td>76.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.066236</td>\n",
       "      <td>16.14</td>\n",
       "      <td>7.60</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568175</td>\n",
       "      <td>2.000313</td>\n",
       "      <td>2.572016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.026472</td>\n",
       "      <td>15.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.871643</td>\n",
       "      <td>2.496854</td>\n",
       "      <td>2.555157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1</td>\n",
       "      <td>51.4</td>\n",
       "      <td>79.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.161401</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.47</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.904164</td>\n",
       "      <td>2.977092</td>\n",
       "      <td>2.495116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>13.16</td>\n",
       "      <td>9.72</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.945618</td>\n",
       "      <td>3.414186</td>\n",
       "      <td>2.861741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2163 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  agent_1_feat_Possession%  agent_1_feat_Pass%  \\\n",
       "20           0                      44.0                70.3   \n",
       "21           0                      57.0                84.6   \n",
       "22           1                      48.1                76.9   \n",
       "23           0                      46.3                70.8   \n",
       "24           0                      50.7                82.1   \n",
       "...        ...                       ...                 ...   \n",
       "2465         1                      41.6                76.0   \n",
       "2466         1                      42.9                76.1   \n",
       "2467         0                      41.0                72.2   \n",
       "2468         1                      51.4                79.3   \n",
       "2469         1                      43.5                71.6   \n",
       "\n",
       "      agent_1_feat_AerialsWon  agent_1_feat_Rating  agent_1_feat_XGrealiz  \\\n",
       "20                       25.1                 6.79               0.711201   \n",
       "21                       15.9                 7.07               1.094698   \n",
       "22                       17.7                 6.74               0.994530   \n",
       "23                       21.7                 6.77               0.918434   \n",
       "24                       14.4                 6.86               1.124694   \n",
       "...                       ...                  ...                    ...   \n",
       "2465                     17.1                 6.62               1.046406   \n",
       "2466                     18.3                 6.61               1.161802   \n",
       "2467                     19.1                 6.51               1.000858   \n",
       "2468                     14.1                 6.62               1.037986   \n",
       "2469                     23.4                 6.64               0.865460   \n",
       "\n",
       "      agent_1_feat_XGArealiz  agent_1_feat_PPDA  agent_1_feat_OPPDA  \\\n",
       "20                  0.915529              10.74                9.43   \n",
       "21                  0.938272               7.57               13.92   \n",
       "22                  1.235052               9.77                8.24   \n",
       "23                  1.118603               9.56                7.34   \n",
       "24                  0.875939              11.79               10.66   \n",
       "...                      ...                ...                 ...   \n",
       "2465                1.032989              18.00                8.27   \n",
       "2466                1.066236              16.14                7.60   \n",
       "2467                1.026472              15.99                7.99   \n",
       "2468                1.161401               9.73               10.47   \n",
       "2469                0.931256              13.16                9.72   \n",
       "\n",
       "      agent_1_feat_DC  ...  agent_2_feattotal_xg_1  \\\n",
       "20              218.0  ...                1.608046   \n",
       "21              575.0  ...                2.479335   \n",
       "22              175.0  ...                1.712261   \n",
       "23              179.0  ...                2.675331   \n",
       "24              156.0  ...                1.331644   \n",
       "...               ...  ...                     ...   \n",
       "2465            138.0  ...                3.684860   \n",
       "2466            201.0  ...                1.568175   \n",
       "2467            164.0  ...                3.871643   \n",
       "2468            222.0  ...                4.904164   \n",
       "2469            233.0  ...                3.945618   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "20                       2.112304                   1.608046   \n",
       "21                       2.214160                   2.479335   \n",
       "22                       2.183093                   1.712261   \n",
       "23                       2.627794                   2.675331   \n",
       "24                       2.260683                   1.331644   \n",
       "...                           ...                        ...   \n",
       "2465                     4.024907                   3.872622   \n",
       "2466                     2.000313                   2.572016   \n",
       "2467                     2.496854                   2.555157   \n",
       "2468                     2.977092                   2.495116   \n",
       "2469                     3.414186                   2.861741   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "20                     0.578947                   0.578947   \n",
       "21                     0.526316                   0.526316   \n",
       "22                     0.526316                   0.526316   \n",
       "23                     0.421053                   0.421053   \n",
       "24                     0.368421                   0.368421   \n",
       "...                         ...                        ...   \n",
       "2465                   1.000000                   0.000000   \n",
       "2466                   0.000000                   0.000000   \n",
       "2467                   0.000000                   0.000000   \n",
       "2468                   1.000000                   0.000000   \n",
       "2469                   1.000000                   1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "20                          1.0                        0.719298   \n",
       "21                          1.0                        0.684211   \n",
       "22                          1.0                        0.684211   \n",
       "23                          1.0                        0.614035   \n",
       "24                          0.0                        0.245614   \n",
       "...                         ...                             ...   \n",
       "2465                        0.0                        0.333333   \n",
       "2466                        0.0                        0.000000   \n",
       "2467                        1.0                        0.333333   \n",
       "2468                        0.0                        0.333333   \n",
       "2469                        0.0                        0.666667   \n",
       "\n",
       "      agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "20                        1.000000                 0                 0  \n",
       "21                        1.000000                 0                 1  \n",
       "22                        1.000000                 3                 3  \n",
       "23                        1.000000                 1                 0  \n",
       "24                        0.000000                 3                 0  \n",
       "...                            ...               ...               ...  \n",
       "2465                      0.444444                 1                 2  \n",
       "2466                      0.444444                 2                 3  \n",
       "2467                      0.500000                 0                 5  \n",
       "2468                      0.222222                 1                 3  \n",
       "2469                      0.333333                 3                 2  \n",
       "\n",
       "[2163 rows x 237 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_target1          1.000000\n",
      "agent_1_feat_ScoredAv     0.385431\n",
      "agent_1_feat_XgAv         0.360820\n",
      "agent_1_feat_DC           0.341588\n",
      "agent_1_feat_pl_median    0.328869\n",
      "                            ...   \n",
      "agent_1_feat_PPDA        -0.213783\n",
      "agent_2_feat_Rating      -0.215384\n",
      "agent_1_feat_MissedAv    -0.260551\n",
      "agent_1_feat_XgaAv       -0.267009\n",
      "agent_1_feat_ODC         -0.290223\n",
      "Name: expected_target1, Length: 237, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix1 = train_df.corr()\n",
    "corr1 = corr_matrix1[\"expected_target1\"].sort_values(ascending=False)\n",
    "print(corr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_target2         1.000000\n",
      "category                 0.471964\n",
      "agent_2_feat_ScoredAv    0.335948\n",
      "agent_2_feat_XgAv        0.324758\n",
      "agent_2_feat_pl_mean     0.294398\n",
      "                           ...   \n",
      "agent_2_feat_MissedAv   -0.225085\n",
      "agent_1_feat_pl_mean    -0.225340\n",
      "agent_2_feat_XgaAv      -0.241378\n",
      "agent_1_feat_Rating     -0.250496\n",
      "agent_2_feat_ODC        -0.263211\n",
      "Name: expected_target2, Length: 237, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix2 = train_df.corr()\n",
    "corr2 = corr_matrix2[\"expected_target2\"].sort_values(ascending=False)\n",
    "print(corr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expected_target1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agent_1_feat_ScoredAv</td>\n",
       "      <td>0.385431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent_1_feat_XgAv</td>\n",
       "      <td>0.360820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agent_1_feat_DC</td>\n",
       "      <td>0.341588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agent_1_feat_pl_median</td>\n",
       "      <td>0.328869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>agent_1_feat_PPDA</td>\n",
       "      <td>-0.213783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>agent_2_feat_Rating</td>\n",
       "      <td>-0.215384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>agent_1_feat_MissedAv</td>\n",
       "      <td>-0.260551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>agent_1_feat_XgaAv</td>\n",
       "      <td>-0.267009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>agent_1_feat_ODC</td>\n",
       "      <td>-0.290223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature  correlation\n",
       "0          expected_target1     1.000000\n",
       "1     agent_1_feat_ScoredAv     0.385431\n",
       "2         agent_1_feat_XgAv     0.360820\n",
       "3           agent_1_feat_DC     0.341588\n",
       "4    agent_1_feat_pl_median     0.328869\n",
       "..                      ...          ...\n",
       "232       agent_1_feat_PPDA    -0.213783\n",
       "233     agent_2_feat_Rating    -0.215384\n",
       "234   agent_1_feat_MissedAv    -0.260551\n",
       "235      agent_1_feat_XgaAv    -0.267009\n",
       "236        agent_1_feat_ODC    -0.290223\n",
       "\n",
       "[237 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr1_df = pd.DataFrame({'feature': corr1.index, 'correlation':corr1.values})\n",
    "corr1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>expected_target2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>category</td>\n",
       "      <td>0.471964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agent_2_feat_ScoredAv</td>\n",
       "      <td>0.335948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agent_2_feat_XgAv</td>\n",
       "      <td>0.324758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agent_2_feat_pl_mean</td>\n",
       "      <td>0.294398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>agent_2_feat_MissedAv</td>\n",
       "      <td>-0.225085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>agent_1_feat_pl_mean</td>\n",
       "      <td>-0.225340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>agent_2_feat_XgaAv</td>\n",
       "      <td>-0.241378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>agent_1_feat_Rating</td>\n",
       "      <td>-0.250496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>agent_2_feat_ODC</td>\n",
       "      <td>-0.263211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  correlation\n",
       "0         expected_target2     1.000000\n",
       "1                 category     0.471964\n",
       "2    agent_2_feat_ScoredAv     0.335948\n",
       "3        agent_2_feat_XgAv     0.324758\n",
       "4     agent_2_feat_pl_mean     0.294398\n",
       "..                     ...          ...\n",
       "232  agent_2_feat_MissedAv    -0.225085\n",
       "233   agent_1_feat_pl_mean    -0.225340\n",
       "234     agent_2_feat_XgaAv    -0.241378\n",
       "235    agent_1_feat_Rating    -0.250496\n",
       "236       agent_2_feat_ODC    -0.263211\n",
       "\n",
       "[237 rows x 2 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2_df = pd.DataFrame({'feature' : corr2.index, 'correlation' : corr2.values})\n",
    "corr2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr1_df = corr1_df.drop(corr1_df[corr1_df.feature == 'category'].index)\n",
    "corr1_df = corr1_df.drop(corr1_df[corr1_df.feature == 'expected_target1'].index)\n",
    "corr1_df = corr1_df.drop(corr1_df[corr1_df.feature == 'expected_target2'].index)\n",
    "corr1_df = corr1_df.loc[(corr1_df['correlation'] > 0.1) | (corr1_df['correlation'] < -0.1)]\n",
    "len(corr1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2_df = corr2_df.drop(corr2_df[corr2_df.feature == 'category'].index)\n",
    "corr2_df = corr2_df.drop(corr2_df[corr2_df.feature == 'expected_target1'].index)\n",
    "corr2_df = corr2_df.drop(corr2_df[corr2_df.feature == 'expected_target2'].index)\n",
    "corr2_df = corr2_df.loc[(corr2_df['correlation'] > 0.1) | (corr2_df['correlation'] < -0.1)]\n",
    "len(corr2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6FEvgOH7tUX"
   },
   "source": [
    "## Split dataset on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "A3QmeYdOEhwI"
   },
   "outputs": [],
   "source": [
    "X = train_df.drop(['expected_target1', 'category', 'expected_target2'], axis=1)\n",
    "X1 = X[list(corr1_df.feature)]\n",
    "X2 = X[list(corr2_df.feature)]\n",
    "Y_category = train_df['category']\n",
    "Y_expected1 = train_df['expected_target1']\n",
    "Y_expected2 = train_df['expected_target2']\n",
    "test_df1 = test_df[list(corr1_df.feature)]\n",
    "test_df2 = test_df[list(corr2_df.feature)]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = (X1.iloc[0:int(len(X1)*0.8)], \n",
    "                                    X1.iloc[int(len(X1)*0.8):len(X1)], \n",
    "                                    Y_expected1.iloc[0:int(len(Y_expected1)*0.8)], \n",
    "                                    Y_expected1.iloc[int(len(Y_expected1)*0.8):len(Y_expected1)],)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = (X2.iloc[0:int(len(X2)*0.8)], \n",
    "                                    X2.iloc[int(len(X2)*0.8):len(X2)], \n",
    "                                    Y_expected2.iloc[0:int(len(Y_expected2)*0.8)], \n",
    "                                    Y_expected2.iloc[int(len(Y_expected2)*0.8):len(Y_expected2)],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1730, 87), (433, 87), (1730,), (433,))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1730, 84), (433, 84), (1730,), (433,))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCXvCiWHPn3F"
   },
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(batch_size, epochs, learning_rate, num_classes, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation=\"relu\", input_shape=(input_shape, ))) # Hidden Layer 1\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(128, activation=\"relu\")) # Hidden Layer 2\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64, activation=\"relu\")) # Hidden Layer 3\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64, activation=\"relu\")) # Hidden Layer 4\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(32, activation=\"relu\")) # Hidden Layer 5\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "        \n",
    "    model.add(Dense(num_classes, activation=\"softmax\")) # Outout Layer\n",
    "    \n",
    "    sgd = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "    model.compile(optimizer=sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_equal_dummies(y_train, y_test):\n",
    "    dif = len(y_train.columns) - len(y_test.columns)\n",
    "    if dif == 0:\n",
    "        pass\n",
    "    elif dif > 0:\n",
    "        while dif != 0:\n",
    "            y_test[int(y_test.columns[-1])+1] = 0\n",
    "            dif -= 1\n",
    "    else:\n",
    "        while dif != 0:\n",
    "            y_train[int(y_train.columns[-1])+1] = 0\n",
    "            dif += 1\n",
    "            \n",
    "    print(y_train.shape, y_test.shape)\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graphs(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_acc(model, expected_target, Y_expected, X_test):\n",
    "    tmp_real_value = train_df[expected_target][int(len(Y_expected)*0.8):len(Y_expected)]\n",
    "    y_pred = model.predict(X_test)\n",
    "    tmp_pred_value = []\n",
    "    for i in y_pred:\n",
    "        if i.argmax() != 0:\n",
    "            tmp_pred_value.append(1)\n",
    "        else:\n",
    "            tmp_pred_value.append(0)\n",
    "    \n",
    "#     print(len(tmp_real_value), len(tmp_pred_value))\n",
    "    num_matching = 0\n",
    "    if len(tmp_real_value) == len(tmp_pred_value):\n",
    "        for i, j in zip(tmp_real_value, tmp_pred_value):\n",
    "            if i != 0:\n",
    "                i = 1\n",
    "            if i == j:\n",
    "                num_matching += 1\n",
    "        print(\"ACC: \", np.round((num_matching / len(tmp_real_value)), 3))\n",
    "    else:\n",
    "        print('Not equal siae of predictions')\n",
    "        \n",
    "    return tmp_pred_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, test_df):\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    test_df = scaler.transform(test_df)\n",
    "    \n",
    "    return X_train, X_test, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_model(X_train, y_train, X_test, y_test):\n",
    "    error_rates = []\n",
    "\n",
    "    for i in np.arange(1, 100):\n",
    "        new_model = KNeighborsClassifier(n_neighbors = i)\n",
    "        new_model.fit(X_train, y_train)\n",
    "        model = KNeighborsClassifier(n_neighbors = 5)\n",
    "        model.fit(X_train, y_train)\n",
    "        new_predictions = new_model.predict(X_test)\n",
    "        error_rates.append(np.mean(new_predictions != y_test))\n",
    "\n",
    "    plt.plot(error_rates);\n",
    "    \n",
    "    return error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train, y_train, X_test, y_test):\n",
    "    feature_selection_model = KNeighborsClassifier(n_neighbors = np.argmin(KNN_model(X_train, y_train, X_test, y_test)))\n",
    "    \n",
    "    sfs = SFS(feature_selection_model,\n",
    "          k_features=X_train.shape[1],\n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='accuracy', \n",
    "          verbose=1,\n",
    "          cv=StratifiedKFold(n_splits=5),\n",
    "          n_jobs=-1\n",
    "          )\n",
    "\n",
    "    sfs = sfs.fit(X_train, y_train)\n",
    "    \n",
    "    sfs_data = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "    sfs_data['avg_score'] = pd.to_numeric(sfs_data['avg_score'])\n",
    "    fearues_names = (sfs_data.loc[sfs_data['avg_score'].idxmax(), 'feature_names'])\n",
    "    \n",
    "    return fearues_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, expected_target):\n",
    "    batch_size = [16, 32, 64, 128]\n",
    "    epochs = [50, 75, 125]\n",
    "    learning_rate = [0.001, 0.0001]\n",
    "    num_classes = [train_df[expected_target].nunique()]\n",
    "    input_shape = [X_train.shape[1]]\n",
    "    param_opt = dict(batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     learning_rate=learning_rate,\n",
    "                     num_classes=num_classes,\n",
    "                     input_shape=input_shape)\n",
    "\n",
    "\n",
    "    model_GridSearch = KerasClassifier(build_fn=create_model, \n",
    "                                       verbose=0)\n",
    "    grid = GridSearchCV(estimator=model_GridSearch, \n",
    "                        param_grid=param_opt, \n",
    "                        n_jobs=-1, \n",
    "                        cv=5, \n",
    "                        verbose = 0)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best parameters are: ')\n",
    "    print('batch_size: ' + str(grid_result.best_params_['batch_size']))\n",
    "    print('epochs: ' + str(grid_result.best_params_['epochs']))\n",
    "    print('learning_rate: ' + str(grid_result.best_params_['learning_rate']))\n",
    "    \n",
    "    return grid_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Agent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  87 out of  87 | elapsed:    7.4s finished\n",
      "Features: 1/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of  86 | elapsed:    1.4s finished\n",
      "Features: 2/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  85 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  85 out of  85 | elapsed:    1.4s finished\n",
      "Features: 3/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    1.4s finished\n",
      "Features: 4/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  83 | elapsed:    1.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of  83 | elapsed:    1.7s finished\n",
      "Features: 5/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of  82 | elapsed:    1.7s finished\n",
      "Features: 6/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  81 | elapsed:    2.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    2.2s finished\n",
      "Features: 7/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.2s finished\n",
      "Features: 8/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  79 | elapsed:    2.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of  79 | elapsed:    2.3s finished\n",
      "Features: 9/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of  78 | elapsed:    2.1s finished\n",
      "Features: 10/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of  77 | elapsed:    2.3s finished\n",
      "Features: 11/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  76 | elapsed:    2.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:    2.6s finished\n",
      "Features: 12/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  75 | elapsed:    2.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    2.4s finished\n",
      "Features: 13/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  74 | elapsed:    2.7s finished\n",
      "Features: 14/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  73 | elapsed:    2.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of  73 | elapsed:    2.6s finished\n",
      "Features: 15/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.0s finished\n",
      "Features: 16/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  71 | elapsed:    1.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of  71 | elapsed:    1.9s finished\n",
      "Features: 17/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.7s finished\n",
      "Features: 18/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  69 | elapsed:    1.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  69 | elapsed:    1.9s finished\n",
      "Features: 19/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  68 | elapsed:    1.9s finished\n",
      "Features: 20/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  67 | elapsed:    1.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of  67 | elapsed:    1.9s finished\n",
      "Features: 21/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:    1.9s finished\n",
      "Features: 22/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  65 | elapsed:    1.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:    1.8s finished\n",
      "Features: 23/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    1.8s finished\n",
      "Features: 24/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:    1.9s finished\n",
      "Features: 25/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    1.8s finished\n",
      "Features: 26/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  61 | elapsed:    1.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    1.8s finished\n",
      "Features: 27/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.8s finished\n",
      "Features: 28/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  59 | elapsed:    1.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    1.7s finished\n",
      "Features: 29/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    1.8s finished\n",
      "Features: 30/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  57 | elapsed:    1.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    1.6s finished\n",
      "Features: 31/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    1.6s finished\n",
      "Features: 32/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.7s finished\n",
      "Features: 33/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    1.7s finished\n",
      "Features: 34/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    1.6s finished\n",
      "Features: 35/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 36/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  51 | elapsed:    1.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    1.6s finished\n",
      "Features: 37/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "Features: 38/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    1.4s finished\n",
      "Features: 39/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.5s finished\n",
      "Features: 40/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    1.5s finished\n",
      "Features: 41/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    1.5s finished\n",
      "Features: 42/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.4s finished\n",
      "Features: 43/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    1.4s finished\n",
      "Features: 44/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    1.3s finished\n",
      "Features: 45/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    1.2s finished\n",
      "Features: 46/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    1.3s finished\n",
      "Features: 47/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.1s finished\n",
      "Features: 48/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    1.2s finished\n",
      "Features: 49/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    1.2s finished\n",
      "Features: 50/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    1.2s finished\n",
      "Features: 51/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    1.2s finished\n",
      "Features: 52/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    1.1s finished\n",
      "Features: 53/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    1.1s finished\n",
      "Features: 54/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    1.0s finished\n",
      "Features: 55/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    1.0s finished\n",
      "Features: 56/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    1.0s finished\n",
      "Features: 57/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.9s finished\n",
      "Features: 58/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.9s finished\n",
      "Features: 59/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.9s finished\n",
      "Features: 60/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.9s finished\n",
      "Features: 61/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.9s finished\n",
      "Features: 62/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.8s finished\n",
      "Features: 63/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.8s finished\n",
      "Features: 64/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.8s finished\n",
      "Features: 65/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.6s finished\n",
      "Features: 66/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.7s finished\n",
      "Features: 67/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.7s finished\n",
      "Features: 68/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.6s finished\n",
      "Features: 69/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.5s finished\n",
      "Features: 70/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.6s finished\n",
      "Features: 71/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.4s finished\n",
      "Features: 72/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished\n",
      "Features: 73/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.4s finished\n",
      "Features: 74/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.4s finished\n",
      "Features: 75/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.4s finished\n",
      "Features: 76/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.3s finished\n",
      "Features: 77/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "Features: 78/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.3s finished\n",
      "Features: 79/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
      "Features: 80/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
      "Features: 81/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
      "Features: 82/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "Features: 83/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s finished\n",
      "Features: 84/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "Features: 85/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "Features: 86/87[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "Features: 87/87"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fearues_names1 = feature_selection(X_train1, y_train1, X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_ScoredAv</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_2_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_xg_mean_3</th>\n",
       "      <th>agent_1_feat_scored_mean_3.1</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_scored_mean_3</th>\n",
       "      <th>agent_1_feat_xg_1</th>\n",
       "      <th>agent_1_feat_total_xg_mean</th>\n",
       "      <th>agent_2_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_total_xg_3.1</th>\n",
       "      <th>agent_2_feat_xga_mean_3</th>\n",
       "      <th>agent_1_feat_scheme_0</th>\n",
       "      <th>agent_2_feat_xg_mean_3</th>\n",
       "      <th>agent_2_feat_XgAv</th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>1.036053</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.048421</td>\n",
       "      <td>0.750198</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.711201</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.843331</td>\n",
       "      <td>2.129323</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>2.389219</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178134</td>\n",
       "      <td>1.426579</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.523421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.184211</td>\n",
       "      <td>1.995263</td>\n",
       "      <td>7.07</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>1.237632</td>\n",
       "      <td>1.596474</td>\n",
       "      <td>2.543860</td>\n",
       "      <td>1.094698</td>\n",
       "      <td>2.394737</td>\n",
       "      <td>1.313750</td>\n",
       "      <td>2.330876</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>3.181885</td>\n",
       "      <td>1.005866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.083304</td>\n",
       "      <td>1.217368</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.065789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.058421</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>1.196842</td>\n",
       "      <td>0.907779</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.994530</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.699295</td>\n",
       "      <td>1.826466</td>\n",
       "      <td>1.121372</td>\n",
       "      <td>2.461948</td>\n",
       "      <td>1.363546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651080</td>\n",
       "      <td>1.177895</td>\n",
       "      <td>1.236842</td>\n",
       "      <td>6.83</td>\n",
       "      <td>1.342368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.105263</td>\n",
       "      <td>1.203421</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>1.354211</td>\n",
       "      <td>1.393386</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1.076170</td>\n",
       "      <td>3.241675</td>\n",
       "      <td>1.029926</td>\n",
       "      <td>2.946534</td>\n",
       "      <td>1.326438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881272</td>\n",
       "      <td>0.985526</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.717368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.076316</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>1.414474</td>\n",
       "      <td>0.756213</td>\n",
       "      <td>1.280702</td>\n",
       "      <td>1.124694</td>\n",
       "      <td>1.403509</td>\n",
       "      <td>0.914215</td>\n",
       "      <td>1.600986</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>2.357624</td>\n",
       "      <td>1.024063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.121913</td>\n",
       "      <td>1.016579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.472105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.763158</td>\n",
       "      <td>1.884211</td>\n",
       "      <td>1.084952</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.698362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712129</td>\n",
       "      <td>3.176816</td>\n",
       "      <td>0.935754</td>\n",
       "      <td>3.016149</td>\n",
       "      <td>1.578853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344915</td>\n",
       "      <td>1.186579</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.884474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.277895</td>\n",
       "      <td>6.59</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.369474</td>\n",
       "      <td>1.414319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741351</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.066150</td>\n",
       "      <td>3.496250</td>\n",
       "      <td>0.749424</td>\n",
       "      <td>1.525538</td>\n",
       "      <td>1.602597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.186190</td>\n",
       "      <td>1.205526</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.566579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>1.289474</td>\n",
       "      <td>1.291316</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>1.510263</td>\n",
       "      <td>0.781500</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.295460</td>\n",
       "      <td>3.467103</td>\n",
       "      <td>0.871232</td>\n",
       "      <td>4.384070</td>\n",
       "      <td>1.172430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.122357</td>\n",
       "      <td>0.906579</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>6.68</td>\n",
       "      <td>1.797895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1.342105</td>\n",
       "      <td>1.486842</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>1.081316</td>\n",
       "      <td>1.639787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.162560</td>\n",
       "      <td>2.956257</td>\n",
       "      <td>1.314188</td>\n",
       "      <td>3.660690</td>\n",
       "      <td>1.046628</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.855210</td>\n",
       "      <td>2.006053</td>\n",
       "      <td>1.815789</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.489211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>1.473684</td>\n",
       "      <td>1.337368</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>1.665526</td>\n",
       "      <td>1.747413</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.101928</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.703990</td>\n",
       "      <td>3.235290</td>\n",
       "      <td>1.027018</td>\n",
       "      <td>2.556120</td>\n",
       "      <td>1.660693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.677573</td>\n",
       "      <td>1.175526</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.506579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_1_feat_ScoredAv  agent_1_feat_XgAv  agent_1_feat_Rating  \\\n",
       "20                 0.736842           1.036053                 6.79   \n",
       "21                 2.184211           1.995263                 7.07   \n",
       "22                 1.052632           1.058421                 6.74   \n",
       "23                 1.105263           1.203421                 6.77   \n",
       "24                 1.210526           1.076316                 6.86   \n",
       "...                     ...                ...                  ...   \n",
       "1973               0.684211           0.979737                 6.52   \n",
       "1974               0.947368           1.277895                 6.59   \n",
       "1975               1.289474           1.291316                 6.72   \n",
       "1977               1.342105           1.486842                 6.71   \n",
       "1978               1.473684           1.337368                 6.71   \n",
       "\n",
       "      agent_2_feat_MissedAv  agent_2_feat_XgaAv  agent_1_feat_xg_mean_3  \\\n",
       "20                 0.973684            1.048421                0.750198   \n",
       "21                 1.184211            1.237632                1.596474   \n",
       "22                 1.342105            1.196842                0.907779   \n",
       "23                 1.394737            1.354211                1.393386   \n",
       "24                 1.342105            1.414474                0.756213   \n",
       "...                     ...                 ...                     ...   \n",
       "1973               1.763158            1.884211                1.084952   \n",
       "1974               1.026316            1.369474                1.414319   \n",
       "1975               1.315789            1.510263                0.781500   \n",
       "1977               1.421053            1.081316                1.639787   \n",
       "1978               1.710526            1.665526                1.747413   \n",
       "\n",
       "      agent_1_feat_scored_mean_3.1  agent_1_feat_XGrealiz  \\\n",
       "20                        0.824561               0.711201   \n",
       "21                        2.543860               1.094698   \n",
       "22                        0.912281               0.994530   \n",
       "23                        0.807018               0.918434   \n",
       "24                        1.280702               1.124694   \n",
       "...                            ...                    ...   \n",
       "1973                      2.666667               0.698362   \n",
       "1974                      1.000000               0.741351   \n",
       "1975                      1.333333               0.998573   \n",
       "1977                      1.000000               0.902655   \n",
       "1978                      2.333333               1.101928   \n",
       "\n",
       "      agent_1_feat_scored_mean_3  agent_1_feat_xg_1  \\\n",
       "20                      0.578947           0.843331   \n",
       "21                      2.394737           1.313750   \n",
       "22                      0.350877           0.699295   \n",
       "23                      0.368421           1.076170   \n",
       "24                      1.403509           0.914215   \n",
       "...                          ...                ...   \n",
       "1973                    1.000000           0.712129   \n",
       "1974                    0.666667           1.066150   \n",
       "1975                    1.333333           1.295460   \n",
       "1977                    1.000000           1.162560   \n",
       "1978                    2.000000           1.703990   \n",
       "\n",
       "      agent_1_feat_total_xg_mean  agent_2_feat_XGArealiz  \\\n",
       "20                      2.129323                0.928715   \n",
       "21                      2.330876                0.956836   \n",
       "22                      1.826466                1.121372   \n",
       "23                      3.241675                1.029926   \n",
       "24                      1.600986                0.948837   \n",
       "...                          ...                     ...   \n",
       "1973                    3.176816                0.935754   \n",
       "1974                    3.496250                0.749424   \n",
       "1975                    3.467103                0.871232   \n",
       "1977                    2.956257                1.314188   \n",
       "1978                    3.235290                1.027018   \n",
       "\n",
       "      agent_1_feat_total_xg_3.1  agent_2_feat_xga_mean_3  \\\n",
       "20                     2.389219                 0.664349   \n",
       "21                     3.181885                 1.005866   \n",
       "22                     2.461948                 1.363546   \n",
       "23                     2.946534                 1.326438   \n",
       "24                     2.357624                 1.024063   \n",
       "...                         ...                      ...   \n",
       "1973                   3.016149                 1.578853   \n",
       "1974                   1.525538                 1.602597   \n",
       "1975                   4.384070                 1.172430   \n",
       "1977                   3.660690                 1.046628   \n",
       "1978                   2.556120                 1.660693   \n",
       "\n",
       "      agent_1_feat_scheme_0  agent_2_feat_xg_mean_3  agent_2_feat_XgAv  \\\n",
       "20                      0.0                1.178134           1.426579   \n",
       "21                      0.0                1.083304           1.217368   \n",
       "22                      0.0                0.651080           1.177895   \n",
       "23                      0.0                0.881272           0.985526   \n",
       "24                      0.0                1.121913           1.016579   \n",
       "...                     ...                     ...                ...   \n",
       "1973                    0.0                1.344915           1.186579   \n",
       "1974                    0.0                1.186190           1.205526   \n",
       "1975                    0.0                1.122357           0.906579   \n",
       "1977                    1.0                2.855210           2.006053   \n",
       "1978                    0.0                1.677573           1.175526   \n",
       "\n",
       "      agent_2_feat_ScoredAv  agent_2_feat_Rating  agent_1_feat_XgaAv  \n",
       "20                 1.631579                 6.99            1.523421  \n",
       "21                 1.263158                 6.87            1.065789  \n",
       "22                 1.236842                 6.83            1.342368  \n",
       "23                 0.815789                 6.75            1.717368  \n",
       "24                 1.000000                 6.77            1.472105  \n",
       "...                     ...                  ...                 ...  \n",
       "1973               1.078947                 6.62            1.884474  \n",
       "1974               1.026316                 6.72            1.566579  \n",
       "1975               0.815789                 6.68            1.797895  \n",
       "1977               1.815789                 6.86            1.489211  \n",
       "1978               1.052632                 6.60            1.506579  \n",
       "\n",
       "[1730 rows x 20 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train1 = X_train1[list(fearues_names1)]\n",
    "new_X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_ScoredAv</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_2_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_xg_mean_3</th>\n",
       "      <th>agent_1_feat_scored_mean_3.1</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_scored_mean_3</th>\n",
       "      <th>agent_1_feat_xg_1</th>\n",
       "      <th>agent_1_feat_total_xg_mean</th>\n",
       "      <th>agent_2_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_total_xg_3.1</th>\n",
       "      <th>agent_2_feat_xga_mean_3</th>\n",
       "      <th>agent_1_feat_scheme_0</th>\n",
       "      <th>agent_2_feat_xg_mean_3</th>\n",
       "      <th>agent_2_feat_XgAv</th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.001579</td>\n",
       "      <td>0.481092</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.041381</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.054134</td>\n",
       "      <td>2.266834</td>\n",
       "      <td>0.945875</td>\n",
       "      <td>1.513641</td>\n",
       "      <td>0.892297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.170650</td>\n",
       "      <td>1.741842</td>\n",
       "      <td>1.736842</td>\n",
       "      <td>6.83</td>\n",
       "      <td>1.763947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1.157895</td>\n",
       "      <td>1.413421</td>\n",
       "      <td>6.68</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.797895</td>\n",
       "      <td>1.642060</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.819214</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.307230</td>\n",
       "      <td>2.715972</td>\n",
       "      <td>0.907494</td>\n",
       "      <td>3.490140</td>\n",
       "      <td>1.888677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.014997</td>\n",
       "      <td>1.291316</td>\n",
       "      <td>1.289474</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1.078947</td>\n",
       "      <td>1.186579</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>2.102665</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.909293</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.678270</td>\n",
       "      <td>3.077340</td>\n",
       "      <td>0.893744</td>\n",
       "      <td>2.112606</td>\n",
       "      <td>1.947001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.477451</td>\n",
       "      <td>1.247895</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1.884211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.175526</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.973684</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>1.433756</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.895456</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.683967</td>\n",
       "      <td>3.246543</td>\n",
       "      <td>1.047340</td>\n",
       "      <td>5.022010</td>\n",
       "      <td>2.625453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.120646</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.665526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1.815789</td>\n",
       "      <td>2.006053</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.526316</td>\n",
       "      <td>1.763947</td>\n",
       "      <td>2.549883</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.905155</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.152010</td>\n",
       "      <td>3.387194</td>\n",
       "      <td>0.865284</td>\n",
       "      <td>3.352280</td>\n",
       "      <td>1.336501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600833</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.65</td>\n",
       "      <td>1.081316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.156842</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>1.658421</td>\n",
       "      <td>0.538870</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400364</td>\n",
       "      <td>2.517954</td>\n",
       "      <td>0.856871</td>\n",
       "      <td>2.373700</td>\n",
       "      <td>1.369450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981234</td>\n",
       "      <td>1.559474</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.579474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1.078947</td>\n",
       "      <td>0.928684</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.312105</td>\n",
       "      <td>0.453369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.051584</td>\n",
       "      <td>2.461299</td>\n",
       "      <td>0.942639</td>\n",
       "      <td>3.358338</td>\n",
       "      <td>0.410268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.702073</td>\n",
       "      <td>1.587895</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.628947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.805526</td>\n",
       "      <td>1.265762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.464091</td>\n",
       "      <td>2.782227</td>\n",
       "      <td>1.045410</td>\n",
       "      <td>2.658484</td>\n",
       "      <td>0.276812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.404496</td>\n",
       "      <td>2.045263</td>\n",
       "      <td>2.184211</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.948421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.191579</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.137632</td>\n",
       "      <td>0.516526</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.378147</td>\n",
       "      <td>2.248507</td>\n",
       "      <td>0.902151</td>\n",
       "      <td>1.742962</td>\n",
       "      <td>0.582768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.236761</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.447368</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1.540789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>0.868421</td>\n",
       "      <td>1.003421</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.401316</td>\n",
       "      <td>0.708280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.080590</td>\n",
       "      <td>2.286778</td>\n",
       "      <td>0.863850</td>\n",
       "      <td>2.661870</td>\n",
       "      <td>2.069648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.589569</td>\n",
       "      <td>1.492632</td>\n",
       "      <td>1.447368</td>\n",
       "      <td>6.84</td>\n",
       "      <td>1.554211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_1_feat_ScoredAv  agent_1_feat_XgAv  agent_1_feat_Rating  \\\n",
       "1979               1.000000           0.960263                 6.65   \n",
       "1980               1.157895           1.413421                 6.68   \n",
       "1981               1.078947           1.186579                 6.62   \n",
       "1982               1.052632           1.175526                 6.60   \n",
       "1983               1.815789           2.006053                 6.86   \n",
       "...                     ...                ...                  ...   \n",
       "2465               1.210526           1.156842                 6.62   \n",
       "2466               1.078947           0.928684                 6.61   \n",
       "2467               0.921053           0.920263                 6.51   \n",
       "2468               1.236842           1.191579                 6.62   \n",
       "2469               0.868421           1.003421                 6.64   \n",
       "\n",
       "      agent_2_feat_MissedAv  agent_2_feat_XgaAv  agent_1_feat_xg_mean_3  \\\n",
       "1979               0.947368            1.001579                0.481092   \n",
       "1980               1.631579            1.797895                1.642060   \n",
       "1981               1.421053            1.590000                2.102665   \n",
       "1982               1.973684            1.884474                1.433756   \n",
       "1983               1.526316            1.763947                2.549883   \n",
       "...                     ...                 ...                     ...   \n",
       "2465               1.421053            1.658421                0.538870   \n",
       "2466               1.236842            1.312105                0.453369   \n",
       "2467               0.842105            0.805526                1.265762   \n",
       "2468               1.026316            1.137632                0.516526   \n",
       "2469               1.210526            1.401316                0.708280   \n",
       "\n",
       "      agent_1_feat_scored_mean_3.1  agent_1_feat_XGrealiz  \\\n",
       "1979                      0.333333               1.041381   \n",
       "1980                      1.333333               0.819214   \n",
       "1981                      1.333333               0.909293   \n",
       "1982                      2.000000               0.895456   \n",
       "1983                      1.666667               0.905155   \n",
       "...                            ...                    ...   \n",
       "2465                      0.666667               1.046406   \n",
       "2466                      1.000000               1.161802   \n",
       "2467                      0.000000               1.000858   \n",
       "2468                      0.333333               1.037986   \n",
       "2469                      1.000000               0.865460   \n",
       "\n",
       "      agent_1_feat_scored_mean_3  agent_1_feat_xg_1  \\\n",
       "1979                    0.333333           0.054134   \n",
       "1980                    0.333333           1.307230   \n",
       "1981                    3.000000           3.678270   \n",
       "1982                    1.666667           0.683967   \n",
       "1983                    2.333333           2.152010   \n",
       "...                          ...                ...   \n",
       "2465                    0.000000           0.400364   \n",
       "2466                    0.666667           0.051584   \n",
       "2467                    1.333333           0.464091   \n",
       "2468                    0.333333           0.378147   \n",
       "2469                    0.333333           1.080590   \n",
       "\n",
       "      agent_1_feat_total_xg_mean  agent_2_feat_XGArealiz  \\\n",
       "1979                    2.266834                0.945875   \n",
       "1980                    2.715972                0.907494   \n",
       "1981                    3.077340                0.893744   \n",
       "1982                    3.246543                1.047340   \n",
       "1983                    3.387194                0.865284   \n",
       "...                          ...                     ...   \n",
       "2465                    2.517954                0.856871   \n",
       "2466                    2.461299                0.942639   \n",
       "2467                    2.782227                1.045410   \n",
       "2468                    2.248507                0.902151   \n",
       "2469                    2.286778                0.863850   \n",
       "\n",
       "      agent_1_feat_total_xg_3.1  agent_2_feat_xga_mean_3  \\\n",
       "1979                   1.513641                 0.892297   \n",
       "1980                   3.490140                 1.888677   \n",
       "1981                   2.112606                 1.947001   \n",
       "1982                   5.022010                 2.625453   \n",
       "1983                   3.352280                 1.336501   \n",
       "...                         ...                      ...   \n",
       "2465                   2.373700                 1.369450   \n",
       "2466                   3.358338                 0.410268   \n",
       "2467                   2.658484                 0.276812   \n",
       "2468                   1.742962                 0.582768   \n",
       "2469                   2.661870                 2.069648   \n",
       "\n",
       "      agent_1_feat_scheme_0  agent_2_feat_xg_mean_3  agent_2_feat_XgAv  \\\n",
       "1979                    0.0                1.170650           1.741842   \n",
       "1980                    0.0                1.014997           1.291316   \n",
       "1981                    1.0                1.477451           1.247895   \n",
       "1982                    0.0                1.120646           0.979737   \n",
       "1983                    1.0                0.600833           0.960263   \n",
       "...                     ...                     ...                ...   \n",
       "2465                    0.0                0.981234           1.559474   \n",
       "2466                    0.0                1.702073           1.587895   \n",
       "2467                    0.0                2.404496           2.045263   \n",
       "2468                    0.0                2.236761           1.375000   \n",
       "2469                    0.0                1.589569           1.492632   \n",
       "\n",
       "      agent_2_feat_ScoredAv  agent_2_feat_Rating  agent_1_feat_XgaAv  \n",
       "1979               1.736842                 6.83            1.763947  \n",
       "1980               1.289474                 6.72            1.295000  \n",
       "1981               1.026316                 6.63            1.884211  \n",
       "1982               0.684211                 6.52            1.665526  \n",
       "1983               1.000000                 6.65            1.081316  \n",
       "...                     ...                  ...                 ...  \n",
       "2465               1.631579                 6.77            1.579474  \n",
       "2466               1.631579                 6.77            1.628947  \n",
       "2467               2.184211                 7.01            1.948421  \n",
       "2468               1.447368                 6.69            1.540789  \n",
       "2469               1.447368                 6.84            1.554211  \n",
       "\n",
       "[433 rows x 20 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_test1 = X_test1[list(fearues_names1)]\n",
    "new_X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_ScoredAv</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_2_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_xg_mean_3</th>\n",
       "      <th>agent_1_feat_scored_mean_3.1</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_scored_mean_3</th>\n",
       "      <th>agent_1_feat_xg_1</th>\n",
       "      <th>agent_1_feat_total_xg_mean</th>\n",
       "      <th>agent_2_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_total_xg_3.1</th>\n",
       "      <th>agent_2_feat_xga_mean_3</th>\n",
       "      <th>agent_1_feat_scheme_0</th>\n",
       "      <th>agent_2_feat_xg_mean_3</th>\n",
       "      <th>agent_2_feat_XgAv</th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.526316</td>\n",
       "      <td>1.806842</td>\n",
       "      <td>6.83</td>\n",
       "      <td>1.368421</td>\n",
       "      <td>1.373421</td>\n",
       "      <td>0.895377</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.844742</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615727</td>\n",
       "      <td>2.721904</td>\n",
       "      <td>0.996359</td>\n",
       "      <td>2.689307</td>\n",
       "      <td>1.736522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.538212</td>\n",
       "      <td>1.016316</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.813158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.416316</td>\n",
       "      <td>6.65</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>1.516842</td>\n",
       "      <td>1.248041</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.144240</td>\n",
       "      <td>2.677899</td>\n",
       "      <td>0.919500</td>\n",
       "      <td>3.938100</td>\n",
       "      <td>2.069040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.756073</td>\n",
       "      <td>1.080526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1.050263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.295789</td>\n",
       "      <td>6.73</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>1.238684</td>\n",
       "      <td>0.421098</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.323445</td>\n",
       "      <td>2.711356</td>\n",
       "      <td>1.062248</td>\n",
       "      <td>2.227870</td>\n",
       "      <td>0.419486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.322390</td>\n",
       "      <td>1.547368</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.921053</td>\n",
       "      <td>1.662368</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1.657895</td>\n",
       "      <td>1.739737</td>\n",
       "      <td>1.371087</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.155612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.684010</td>\n",
       "      <td>2.962695</td>\n",
       "      <td>0.952957</td>\n",
       "      <td>6.412100</td>\n",
       "      <td>0.976729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.104814</td>\n",
       "      <td>0.872632</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>6.46</td>\n",
       "      <td>1.103158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.789474</td>\n",
       "      <td>1.491579</td>\n",
       "      <td>6.81</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>1.244737</td>\n",
       "      <td>2.318723</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.199718</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.283850</td>\n",
       "      <td>2.751690</td>\n",
       "      <td>0.887949</td>\n",
       "      <td>2.693652</td>\n",
       "      <td>0.923439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.407720</td>\n",
       "      <td>1.900263</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>6.82</td>\n",
       "      <td>1.382895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.228000</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>1.827937</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.814332</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.602300</td>\n",
       "      <td>2.406452</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>2.449060</td>\n",
       "      <td>1.992155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.130094</td>\n",
       "      <td>1.905000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.558000</td>\n",
       "      <td>1.628449</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.186944</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.041797</td>\n",
       "      <td>3.003332</td>\n",
       "      <td>0.770218</td>\n",
       "      <td>0.828837</td>\n",
       "      <td>1.876742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586779</td>\n",
       "      <td>1.162000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.736000</td>\n",
       "      <td>7.05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>1.331350</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.191780</td>\n",
       "      <td>3.282230</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>2.369897</td>\n",
       "      <td>2.248713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.031708</td>\n",
       "      <td>1.644000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>2.598000</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.018000</td>\n",
       "      <td>3.198800</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.846805</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.147230</td>\n",
       "      <td>3.109280</td>\n",
       "      <td>1.375246</td>\n",
       "      <td>1.645794</td>\n",
       "      <td>1.591810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.081035</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>6.42</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.777500</td>\n",
       "      <td>1.176910</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.532120</td>\n",
       "      <td>2.904359</td>\n",
       "      <td>0.421941</td>\n",
       "      <td>3.118820</td>\n",
       "      <td>0.688478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.267448</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.88</td>\n",
       "      <td>2.122000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent_1_feat_ScoredAv  agent_1_feat_XgAv  agent_1_feat_Rating  \\\n",
       "0                 1.526316           1.806842                 6.83   \n",
       "1                 1.052632           1.416316                 6.65   \n",
       "2                 1.236842           1.295789                 6.73   \n",
       "3                 1.921053           1.662368                 6.85   \n",
       "4                 1.789474           1.491579                 6.81   \n",
       "..                     ...                ...                  ...   \n",
       "565               1.000000           1.228000                 6.72   \n",
       "566               1.000000           0.842500                 6.69   \n",
       "567               2.400000           2.736000                 7.05   \n",
       "568               2.200000           2.598000                 7.11   \n",
       "569               0.400000           0.832000                 6.42   \n",
       "\n",
       "     agent_2_feat_MissedAv  agent_2_feat_XgaAv  agent_1_feat_xg_mean_3  \\\n",
       "0                 1.368421            1.373421                0.895377   \n",
       "1                 1.394737            1.516842                1.248041   \n",
       "2                 1.315789            1.238684                0.421098   \n",
       "3                 1.657895            1.739737                1.371087   \n",
       "4                 1.105263            1.244737                2.318723   \n",
       "..                     ...                 ...                     ...   \n",
       "565               0.750000            0.892500                1.827937   \n",
       "566               1.200000            1.558000                1.628449   \n",
       "567               1.000000            1.170000                1.331350   \n",
       "568               1.400000            1.018000                3.198800   \n",
       "569               0.750000            1.777500                1.176910   \n",
       "\n",
       "     agent_1_feat_scored_mean_3.1  agent_1_feat_XGrealiz  \\\n",
       "0                        1.666667               0.844742   \n",
       "1                        1.333333               0.743218   \n",
       "2                        1.000000               0.954509   \n",
       "3                        3.000000               1.155612   \n",
       "4                        1.333333               1.199718   \n",
       "..                            ...                    ...   \n",
       "565                      1.333333               0.814332   \n",
       "566                      1.333333               1.186944   \n",
       "567                      2.333333               0.877193   \n",
       "568                      4.333333               0.846805   \n",
       "569                      0.666667               0.480769   \n",
       "\n",
       "     agent_1_feat_scored_mean_3  agent_1_feat_xg_1  \\\n",
       "0                      0.666667           0.615727   \n",
       "1                      1.333333           1.144240   \n",
       "2                      1.000000           0.323445   \n",
       "3                      1.000000           1.684010   \n",
       "4                      2.333333           1.283850   \n",
       "..                          ...                ...   \n",
       "565                    1.333333           1.602300   \n",
       "566                    3.000000           0.041797   \n",
       "567                    1.666667           1.191780   \n",
       "568                    4.000000           2.147230   \n",
       "569                    0.333333           1.532120   \n",
       "\n",
       "     agent_1_feat_total_xg_mean  agent_2_feat_XGArealiz  \\\n",
       "0                      2.721904                0.996359   \n",
       "1                      2.677899                0.919500   \n",
       "2                      2.711356                1.062248   \n",
       "3                      2.962695                0.952957   \n",
       "4                      2.751690                0.887949   \n",
       "..                          ...                     ...   \n",
       "565                    2.406452                0.840336   \n",
       "566                    3.003332                0.770218   \n",
       "567                    3.282230                0.854701   \n",
       "568                    3.109280                1.375246   \n",
       "569                    2.904359                0.421941   \n",
       "\n",
       "     agent_1_feat_total_xg_3.1  agent_2_feat_xga_mean_3  \\\n",
       "0                     2.689307                 1.736522   \n",
       "1                     3.938100                 2.069040   \n",
       "2                     2.227870                 0.419486   \n",
       "3                     6.412100                 0.976729   \n",
       "4                     2.693652                 0.923439   \n",
       "..                         ...                      ...   \n",
       "565                   2.449060                 1.992155   \n",
       "566                   0.828837                 1.876742   \n",
       "567                   2.369897                 2.248713   \n",
       "568                   1.645794                 1.591810   \n",
       "569                   3.118820                 0.688478   \n",
       "\n",
       "     agent_1_feat_scheme_0  agent_2_feat_xg_mean_3  agent_2_feat_XgAv  \\\n",
       "0                      0.0                1.538212           1.016316   \n",
       "1                      0.0                0.756073           1.080526   \n",
       "2                      0.0                1.322390           1.547368   \n",
       "3                      0.0                1.104814           0.872632   \n",
       "4                      0.0                1.407720           1.900263   \n",
       "..                     ...                     ...                ...   \n",
       "565                    0.0                1.130094           1.905000   \n",
       "566                    0.0                0.586779           1.162000   \n",
       "567                    1.0                1.031708           1.644000   \n",
       "568                    1.0                1.081035           0.940000   \n",
       "569                    0.0                2.267448           0.947500   \n",
       "\n",
       "     agent_2_feat_ScoredAv  agent_2_feat_Rating  agent_1_feat_XgaAv  \n",
       "0                 0.947368                 6.67            0.813158  \n",
       "1                 0.710526                 6.63            1.050263  \n",
       "2                 1.789474                 6.80            1.320000  \n",
       "3                 0.526316                 6.46            1.103158  \n",
       "4                 1.789474                 6.82            1.382895  \n",
       "..                     ...                  ...                 ...  \n",
       "565               2.750000                 6.71            1.238000  \n",
       "566               0.800000                 6.63            1.950000  \n",
       "567               0.400000                 6.69            0.778000  \n",
       "568               1.600000                 6.68            0.498000  \n",
       "569               0.750000                 6.88            2.122000  \n",
       "\n",
       "[570 rows x 20 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df1 = test_df1[list(fearues_names1)]\n",
    "new_test_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train1, new_X_test1, new_test_df1 = scale_data(new_X_train1, new_X_test1, new_test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1730, 9) (433, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train1 = pd.get_dummies(y_train1)\n",
    "y_test1 = pd.get_dummies(y_test1)\n",
    "y_train1, y_test1 = make_equal_dummies(y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_results1 = grid_search(new_X_train1, y_train1, 'expected_target1')\n",
    "batch_size1 = grid_results1.best_params_['batch_size']\n",
    "epochs1 = grid_results1.best_params_['epochs']\n",
    "learning_rate1 = grid_results1.best_params_['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size1 = 32\n",
    "# epochs1 = 100\n",
    "# learning_rate1 = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 2s 24ms/step - loss: 2.8558 - accuracy: 0.1058 - val_loss: 2.1698 - val_accuracy: 0.1085\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.7625 - accuracy: 0.1069 - val_loss: 2.1198 - val_accuracy: 0.2356\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.6957 - accuracy: 0.1179 - val_loss: 2.0685 - val_accuracy: 0.2910\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.4883 - accuracy: 0.1595 - val_loss: 2.0244 - val_accuracy: 0.2841\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.4411 - accuracy: 0.1613 - val_loss: 1.9862 - val_accuracy: 0.2956\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.3645 - accuracy: 0.1815 - val_loss: 1.9539 - val_accuracy: 0.3095\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.2971 - accuracy: 0.1861 - val_loss: 1.9262 - val_accuracy: 0.3095\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.2054 - accuracy: 0.2092 - val_loss: 1.8988 - val_accuracy: 0.3141\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.2085 - accuracy: 0.2087 - val_loss: 1.8738 - val_accuracy: 0.3141\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.1501 - accuracy: 0.2145 - val_loss: 1.8512 - val_accuracy: 0.3118\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.1075 - accuracy: 0.2254 - val_loss: 1.8291 - val_accuracy: 0.3095\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.0352 - accuracy: 0.2491 - val_loss: 1.8096 - val_accuracy: 0.3210\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.0064 - accuracy: 0.2769 - val_loss: 1.7930 - val_accuracy: 0.3210\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.9926 - accuracy: 0.2694 - val_loss: 1.7760 - val_accuracy: 0.3118\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.9469 - accuracy: 0.2908 - val_loss: 1.7605 - val_accuracy: 0.3095\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.9291 - accuracy: 0.2954 - val_loss: 1.7475 - val_accuracy: 0.3072\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.8849 - accuracy: 0.3104 - val_loss: 1.7336 - val_accuracy: 0.3025\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.8843 - accuracy: 0.3029 - val_loss: 1.7219 - val_accuracy: 0.3072\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.8609 - accuracy: 0.3069 - val_loss: 1.7092 - val_accuracy: 0.3233\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.8429 - accuracy: 0.2960 - val_loss: 1.6992 - val_accuracy: 0.3141\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7993 - accuracy: 0.3260 - val_loss: 1.6936 - val_accuracy: 0.3164\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7764 - accuracy: 0.3295 - val_loss: 1.6902 - val_accuracy: 0.3210\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7845 - accuracy: 0.3266 - val_loss: 1.6858 - val_accuracy: 0.3187\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7559 - accuracy: 0.3457 - val_loss: 1.6811 - val_accuracy: 0.3210\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7008 - accuracy: 0.3555 - val_loss: 1.6753 - val_accuracy: 0.3187\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7277 - accuracy: 0.3428 - val_loss: 1.6692 - val_accuracy: 0.3233\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7223 - accuracy: 0.3272 - val_loss: 1.6641 - val_accuracy: 0.3279\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7120 - accuracy: 0.3382 - val_loss: 1.6561 - val_accuracy: 0.3372\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6721 - accuracy: 0.3682 - val_loss: 1.6501 - val_accuracy: 0.3372\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6602 - accuracy: 0.3578 - val_loss: 1.6459 - val_accuracy: 0.3326\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6739 - accuracy: 0.3613 - val_loss: 1.6413 - val_accuracy: 0.3395\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6316 - accuracy: 0.3792 - val_loss: 1.6382 - val_accuracy: 0.3256\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6451 - accuracy: 0.3549 - val_loss: 1.6331 - val_accuracy: 0.3279\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.6466 - accuracy: 0.3590 - val_loss: 1.6319 - val_accuracy: 0.3349\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6350 - accuracy: 0.3723 - val_loss: 1.6280 - val_accuracy: 0.3303\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6260 - accuracy: 0.3832 - val_loss: 1.6208 - val_accuracy: 0.3372\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5918 - accuracy: 0.3798 - val_loss: 1.6139 - val_accuracy: 0.3372\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5911 - accuracy: 0.3803 - val_loss: 1.6071 - val_accuracy: 0.3510\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6008 - accuracy: 0.3624 - val_loss: 1.6016 - val_accuracy: 0.3557\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6063 - accuracy: 0.3757 - val_loss: 1.5975 - val_accuracy: 0.3603\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5790 - accuracy: 0.3665 - val_loss: 1.5941 - val_accuracy: 0.3557\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5725 - accuracy: 0.3908 - val_loss: 1.5875 - val_accuracy: 0.3580\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5443 - accuracy: 0.3780 - val_loss: 1.5848 - val_accuracy: 0.3626\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5379 - accuracy: 0.3769 - val_loss: 1.5824 - val_accuracy: 0.3672\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5700 - accuracy: 0.3590 - val_loss: 1.5811 - val_accuracy: 0.3603\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5367 - accuracy: 0.3757 - val_loss: 1.5798 - val_accuracy: 0.3603\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5063 - accuracy: 0.4046 - val_loss: 1.5775 - val_accuracy: 0.3580\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5306 - accuracy: 0.3694 - val_loss: 1.5734 - val_accuracy: 0.3510\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5415 - accuracy: 0.3775 - val_loss: 1.5705 - val_accuracy: 0.3533\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5208 - accuracy: 0.3855 - val_loss: 1.5679 - val_accuracy: 0.3557\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_df['expected_target1'].nunique()\n",
    "model1 = create_model(batch_size1, epochs1, learning_rate1, num_classes, new_X_train1.shape[1])\n",
    "history1 = model1.fit(new_X_train1, y_train1, \n",
    "                      batch_size = batch_size1, \n",
    "                      epochs = epochs1,\n",
    "                      validation_data = (new_X_test1, y_test1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_graphs(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "ACC:  0.746\n"
     ]
    }
   ],
   "source": [
    "tmp_pred_value1 = calc_train_acc(model1, 'expected_target1', Y_expected1, new_X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for agent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    1.8s finished\n",
      "Features: 1/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  83 | elapsed:    1.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  83 out of  83 | elapsed:    1.9s finished\n",
      "Features: 2/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of  82 | elapsed:    2.0s finished\n",
      "Features: 3/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  81 | elapsed:    1.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    2.0s finished\n",
      "Features: 4/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    2.1s finished\n",
      "Features: 5/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of  79 | elapsed:    2.2s finished\n",
      "Features: 6/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  78 | elapsed:    1.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  78 out of  78 | elapsed:    2.3s finished\n",
      "Features: 7/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  77 | elapsed:    2.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of  77 | elapsed:    2.4s finished\n",
      "Features: 8/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  76 | elapsed:    2.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:    2.4s finished\n",
      "Features: 9/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  75 | elapsed:    2.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    2.5s finished\n",
      "Features: 10/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  74 out of  74 | elapsed:    2.4s finished\n",
      "Features: 11/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  73 | elapsed:    2.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  73 out of  73 | elapsed:    2.7s finished\n",
      "Features: 12/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    2.8s finished\n",
      "Features: 13/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  71 | elapsed:    2.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  71 out of  71 | elapsed:    2.5s finished\n",
      "Features: 14/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    2.8s finished\n",
      "Features: 15/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  69 | elapsed:    1.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  69 out of  69 | elapsed:    1.9s finished\n",
      "Features: 16/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  68 | elapsed:    1.8s finished\n",
      "Features: 17/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  67 | elapsed:    1.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  67 out of  67 | elapsed:    1.9s finished\n",
      "Features: 18/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:    1.7s finished\n",
      "Features: 19/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  65 | elapsed:    1.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:    1.8s finished\n",
      "Features: 20/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    1.8s finished\n",
      "Features: 21/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:    1.8s finished\n",
      "Features: 22/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    1.6s finished\n",
      "Features: 23/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  61 | elapsed:    1.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    1.7s finished\n",
      "Features: 24/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.6s finished\n",
      "Features: 25/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    1.7s finished\n",
      "Features: 26/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    1.6s finished\n",
      "Features: 27/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  57 | elapsed:    1.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    1.7s finished\n",
      "Features: 28/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    1.6s finished\n",
      "Features: 29/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  55 | elapsed:    1.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.4s finished\n",
      "Features: 30/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    1.6s finished\n",
      "Features: 31/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  53 | elapsed:    1.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    1.5s finished\n",
      "Features: 32/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    1.5s finished\n",
      "Features: 33/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  51 | elapsed:    1.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    1.3s finished\n",
      "Features: 34/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.5s finished\n",
      "Features: 35/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  49 | elapsed:    1.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    1.4s finished\n",
      "Features: 36/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 37/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    1.2s finished\n",
      "Features: 38/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  46 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    1.4s finished\n",
      "Features: 39/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.2s finished\n",
      "Features: 40/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    1.3s finished\n",
      "Features: 41/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    1.3s finished\n",
      "Features: 42/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    1.1s finished\n",
      "Features: 43/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  41 | elapsed:    0.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    1.1s finished\n",
      "Features: 44/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.2s finished\n",
      "Features: 45/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    1.5s finished\n",
      "Features: 46/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    1.3s finished\n",
      "Features: 47/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    1.2s finished\n",
      "Features: 48/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    1.1s finished\n",
      "Features: 49/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    1.1s finished\n",
      "Features: 50/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    1.0s finished\n",
      "Features: 51/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    1.0s finished\n",
      "Features: 52/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    1.0s finished\n",
      "Features: 53/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.9s finished\n",
      "Features: 54/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.9s finished\n",
      "Features: 55/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.9s finished\n",
      "Features: 56/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.9s finished\n",
      "Features: 57/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.8s finished\n",
      "Features: 58/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.8s finished\n",
      "Features: 59/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.8s finished\n",
      "Features: 60/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.7s finished\n",
      "Features: 61/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.7s finished\n",
      "Features: 62/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.7s finished\n",
      "Features: 63/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.6s finished\n",
      "Features: 64/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.6s finished\n",
      "Features: 65/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.6s finished\n",
      "Features: 66/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.6s finished\n",
      "Features: 67/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.5s finished\n",
      "Features: 68/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.4s finished\n",
      "Features: 69/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.4s finished\n",
      "Features: 70/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.4s finished\n",
      "Features: 71/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.3s finished\n",
      "Features: 72/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.4s finished\n",
      "Features: 73/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  11 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.3s finished\n",
      "Features: 74/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "Features: 75/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.3s finished\n",
      "Features: 76/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.1s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
      "Features: 77/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
      "Features: 78/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
      "Features: 79/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "Features: 80/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s finished\n",
      "Features: 81/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 82/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "Features: 83/84[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "Features: 84/84"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fearues_names2 = feature_selection(X_train2, y_train2, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_XgAv</th>\n",
       "      <th>agent_2_feat_pl_mean</th>\n",
       "      <th>agent_1_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_xg_mean_3</th>\n",
       "      <th>agent_2_feat_scored_mean_3</th>\n",
       "      <th>agent_2_feat_form_mean_3</th>\n",
       "      <th>agent_2_feat_scored_3</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_1_feat_scored_1.1</th>\n",
       "      <th>agent_1_feat_xg_2</th>\n",
       "      <th>agent_2_feat_xga_mean_3</th>\n",
       "      <th>agent_1_feat_form_mean_3</th>\n",
       "      <th>agent_1_feat_scored_mean_3.1</th>\n",
       "      <th>agent_1_feat_xg_mean_3</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_2_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.426579</td>\n",
       "      <td>80.272727</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.523421</td>\n",
       "      <td>1.178134</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>-0.228070</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.371141</td>\n",
       "      <td>0.664349</td>\n",
       "      <td>-0.771930</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.750198</td>\n",
       "      <td>1.036053</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>1.048421</td>\n",
       "      <td>6.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.217368</td>\n",
       "      <td>76.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.065789</td>\n",
       "      <td>1.083304</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>-0.324561</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.480530</td>\n",
       "      <td>1.005866</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>2.543860</td>\n",
       "      <td>1.596474</td>\n",
       "      <td>1.995263</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>1.237632</td>\n",
       "      <td>7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.177895</td>\n",
       "      <td>74.727273</td>\n",
       "      <td>1.657895</td>\n",
       "      <td>6.83</td>\n",
       "      <td>1.342368</td>\n",
       "      <td>0.651080</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>-0.692982</td>\n",
       "      <td>1.236842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.965583</td>\n",
       "      <td>1.363546</td>\n",
       "      <td>-0.412281</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.907779</td>\n",
       "      <td>1.058421</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>1.196842</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.985526</td>\n",
       "      <td>75.090909</td>\n",
       "      <td>1.921053</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.717368</td>\n",
       "      <td>0.881272</td>\n",
       "      <td>1.271930</td>\n",
       "      <td>-0.061404</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.900670</td>\n",
       "      <td>1.326438</td>\n",
       "      <td>-0.807018</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>1.393386</td>\n",
       "      <td>1.203421</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>1.354211</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.016579</td>\n",
       "      <td>73.818182</td>\n",
       "      <td>1.289474</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.472105</td>\n",
       "      <td>1.121913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.278076</td>\n",
       "      <td>1.024063</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.280702</td>\n",
       "      <td>0.756213</td>\n",
       "      <td>1.076316</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>1.414474</td>\n",
       "      <td>6.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>1.078947</td>\n",
       "      <td>1.186579</td>\n",
       "      <td>75.727273</td>\n",
       "      <td>1.973684</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>1.344915</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.801428</td>\n",
       "      <td>1.578853</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.084952</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>1.763158</td>\n",
       "      <td>1.884211</td>\n",
       "      <td>6.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.205526</td>\n",
       "      <td>72.818182</td>\n",
       "      <td>1.684211</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.566579</td>\n",
       "      <td>1.186190</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.344718</td>\n",
       "      <td>1.602597</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414319</td>\n",
       "      <td>1.277895</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.369474</td>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.906579</td>\n",
       "      <td>76.272727</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>6.68</td>\n",
       "      <td>1.797895</td>\n",
       "      <td>1.122357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.513760</td>\n",
       "      <td>1.172430</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.781500</td>\n",
       "      <td>1.291316</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>1.510263</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1.815789</td>\n",
       "      <td>2.006053</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.489211</td>\n",
       "      <td>2.855210</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.180210</td>\n",
       "      <td>1.046628</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.639787</td>\n",
       "      <td>1.486842</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>1.081316</td>\n",
       "      <td>6.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.175526</td>\n",
       "      <td>75.181818</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>6.60</td>\n",
       "      <td>1.506579</td>\n",
       "      <td>1.677573</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.532090</td>\n",
       "      <td>1.660693</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.747413</td>\n",
       "      <td>1.337368</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>1.665526</td>\n",
       "      <td>6.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_2_feat_ScoredAv  agent_2_feat_XgAv  agent_2_feat_pl_mean  \\\n",
       "20                 1.631579           1.426579             80.272727   \n",
       "21                 1.263158           1.217368             76.090909   \n",
       "22                 1.236842           1.177895             74.727273   \n",
       "23                 0.815789           0.985526             75.090909   \n",
       "24                 1.000000           1.016579             73.818182   \n",
       "...                     ...                ...                   ...   \n",
       "1973               1.078947           1.186579             75.727273   \n",
       "1974               1.026316           1.205526             72.818182   \n",
       "1975               0.815789           0.906579             76.272727   \n",
       "1977               1.815789           2.006053             80.000000   \n",
       "1978               1.052632           1.175526             75.181818   \n",
       "\n",
       "      agent_1_feat_MissedAv  agent_2_feat_Rating  agent_1_feat_XgaAv  \\\n",
       "20                 1.394737                 6.99            1.523421   \n",
       "21                 1.000000                 6.87            1.065789   \n",
       "22                 1.657895                 6.83            1.342368   \n",
       "23                 1.921053                 6.75            1.717368   \n",
       "24                 1.289474                 6.77            1.472105   \n",
       "...                     ...                  ...                 ...   \n",
       "1973               1.973684                 6.62            1.884474   \n",
       "1974               1.684211                 6.72            1.566579   \n",
       "1975               1.631579                 6.68            1.797895   \n",
       "1977               1.578947                 6.86            1.489211   \n",
       "1978               1.263158                 6.60            1.506579   \n",
       "\n",
       "      agent_2_feat_xg_mean_3  agent_2_feat_scored_mean_3  \\\n",
       "20                  1.178134                    1.210526   \n",
       "21                  1.083304                    0.754386   \n",
       "22                  0.651080                    1.078947   \n",
       "23                  0.881272                    1.271930   \n",
       "24                  1.121913                    1.000000   \n",
       "...                      ...                         ...   \n",
       "1973                1.344915                    1.333333   \n",
       "1974                1.186190                    0.666667   \n",
       "1975                1.122357                    1.000000   \n",
       "1977                2.855210                    2.666667   \n",
       "1978                1.677573                    2.666667   \n",
       "\n",
       "      agent_2_feat_form_mean_3  agent_2_feat_scored_3  ...  \\\n",
       "20                   -0.228070               1.631579  ...   \n",
       "21                   -0.324561               1.263158  ...   \n",
       "22                   -0.692982               1.236842  ...   \n",
       "23                   -0.061404               0.815789  ...   \n",
       "24                   -0.043860               1.000000  ...   \n",
       "...                        ...                    ...  ...   \n",
       "1973                 -0.333333               0.000000  ...   \n",
       "1974                 -0.333333               0.000000  ...   \n",
       "1975                  0.000000               0.000000  ...   \n",
       "1977                  0.333333               5.000000  ...   \n",
       "1978                  0.666667               3.000000  ...   \n",
       "\n",
       "      agent_1_feat_scored_1.1  agent_1_feat_xg_2  agent_2_feat_xga_mean_3  \\\n",
       "20                        1.0           0.371141                 0.664349   \n",
       "21                        3.0           1.480530                 1.005866   \n",
       "22                        0.0           0.965583                 1.363546   \n",
       "23                        0.0           1.900670                 1.326438   \n",
       "24                        1.0           0.278076                 1.024063   \n",
       "...                       ...                ...                      ...   \n",
       "1973                      3.0           0.801428                 1.578853   \n",
       "1974                      2.0           0.344718                 1.602597   \n",
       "1975                      2.0           0.513760                 1.172430   \n",
       "1977                      1.0           2.180210                 1.046628   \n",
       "1978                      3.0           2.532090                 1.660693   \n",
       "\n",
       "      agent_1_feat_form_mean_3  agent_1_feat_scored_mean_3.1  \\\n",
       "20                   -0.771930                      0.824561   \n",
       "21                    0.815789                      2.543860   \n",
       "22                   -0.412281                      0.912281   \n",
       "23                   -0.807018                      0.807018   \n",
       "24                    0.684211                      1.280702   \n",
       "...                        ...                           ...   \n",
       "1973                 -0.333333                      2.666667   \n",
       "1974                 -0.666667                      1.000000   \n",
       "1975                  0.333333                      1.333333   \n",
       "1977                 -0.333333                      1.000000   \n",
       "1978                  0.333333                      2.333333   \n",
       "\n",
       "      agent_1_feat_xg_mean_3  agent_1_feat_XgAv  agent_2_feat_MissedAv  \\\n",
       "20                  0.750198           1.036053               0.973684   \n",
       "21                  1.596474           1.995263               1.184211   \n",
       "22                  0.907779           1.058421               1.342105   \n",
       "23                  1.393386           1.203421               1.394737   \n",
       "24                  0.756213           1.076316               1.342105   \n",
       "...                      ...                ...                    ...   \n",
       "1973                1.084952           0.979737               1.763158   \n",
       "1974                1.414319           1.277895               1.026316   \n",
       "1975                0.781500           1.291316               1.315789   \n",
       "1977                1.639787           1.486842               1.421053   \n",
       "1978                1.747413           1.337368               1.710526   \n",
       "\n",
       "      agent_2_feat_XgaAv  agent_1_feat_Rating  \n",
       "20              1.048421                 6.79  \n",
       "21              1.237632                 7.07  \n",
       "22              1.196842                 6.74  \n",
       "23              1.354211                 6.77  \n",
       "24              1.414474                 6.86  \n",
       "...                  ...                  ...  \n",
       "1973            1.884211                 6.52  \n",
       "1974            1.369474                 6.59  \n",
       "1975            1.510263                 6.72  \n",
       "1977            1.081316                 6.71  \n",
       "1978            1.665526                 6.71  \n",
       "\n",
       "[1730 rows x 33 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train2 = X_train2[list(fearues_names2)]\n",
    "new_X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_XgAv</th>\n",
       "      <th>agent_2_feat_pl_mean</th>\n",
       "      <th>agent_1_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_xg_mean_3</th>\n",
       "      <th>agent_2_feat_scored_mean_3</th>\n",
       "      <th>agent_2_feat_form_mean_3</th>\n",
       "      <th>agent_2_feat_scored_3</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_1_feat_scored_1.1</th>\n",
       "      <th>agent_1_feat_xg_2</th>\n",
       "      <th>agent_2_feat_xga_mean_3</th>\n",
       "      <th>agent_1_feat_form_mean_3</th>\n",
       "      <th>agent_1_feat_scored_mean_3.1</th>\n",
       "      <th>agent_1_feat_xg_mean_3</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_2_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1.736842</td>\n",
       "      <td>1.741842</td>\n",
       "      <td>78.727273</td>\n",
       "      <td>1.526316</td>\n",
       "      <td>6.83</td>\n",
       "      <td>1.763947</td>\n",
       "      <td>1.170650</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098070</td>\n",
       "      <td>0.892297</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.481092</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.001579</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1.289474</td>\n",
       "      <td>1.291316</td>\n",
       "      <td>78.818182</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>6.72</td>\n",
       "      <td>1.295000</td>\n",
       "      <td>1.014997</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.358540</td>\n",
       "      <td>1.888677</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.642060</td>\n",
       "      <td>1.413421</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.797895</td>\n",
       "      <td>6.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.247895</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.763158</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1.884211</td>\n",
       "      <td>1.477451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.914266</td>\n",
       "      <td>1.947001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.102665</td>\n",
       "      <td>1.186579</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>72.818182</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>6.52</td>\n",
       "      <td>1.665526</td>\n",
       "      <td>1.120646</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.319570</td>\n",
       "      <td>2.625453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.433756</td>\n",
       "      <td>1.175526</td>\n",
       "      <td>1.973684</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>76.727273</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>6.65</td>\n",
       "      <td>1.081316</td>\n",
       "      <td>0.600833</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.264430</td>\n",
       "      <td>1.336501</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.549883</td>\n",
       "      <td>2.006053</td>\n",
       "      <td>1.526316</td>\n",
       "      <td>1.763947</td>\n",
       "      <td>6.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.559474</td>\n",
       "      <td>74.727273</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.579474</td>\n",
       "      <td>0.981234</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.168796</td>\n",
       "      <td>1.369450</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.538870</td>\n",
       "      <td>1.156842</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>1.658421</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.587895</td>\n",
       "      <td>77.909091</td>\n",
       "      <td>1.736842</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.628947</td>\n",
       "      <td>1.702073</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.709634</td>\n",
       "      <td>0.410268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453369</td>\n",
       "      <td>0.928684</td>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.312105</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>2.184211</td>\n",
       "      <td>2.045263</td>\n",
       "      <td>83.545455</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.948421</td>\n",
       "      <td>2.404496</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.463320</td>\n",
       "      <td>0.276812</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.265762</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.805526</td>\n",
       "      <td>6.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1.447368</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>80.090909</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1.540789</td>\n",
       "      <td>2.236761</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500436</td>\n",
       "      <td>0.582768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.516526</td>\n",
       "      <td>1.191579</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.137632</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1.447368</td>\n",
       "      <td>1.492632</td>\n",
       "      <td>76.090909</td>\n",
       "      <td>1.447368</td>\n",
       "      <td>6.84</td>\n",
       "      <td>1.554211</td>\n",
       "      <td>1.589569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395668</td>\n",
       "      <td>2.069648</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708280</td>\n",
       "      <td>1.003421</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.401316</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_2_feat_ScoredAv  agent_2_feat_XgAv  agent_2_feat_pl_mean  \\\n",
       "1979               1.736842           1.741842             78.727273   \n",
       "1980               1.289474           1.291316             78.818182   \n",
       "1981               1.026316           1.247895             75.000000   \n",
       "1982               0.684211           0.979737             72.818182   \n",
       "1983               1.000000           0.960263             76.727273   \n",
       "...                     ...                ...                   ...   \n",
       "2465               1.631579           1.559474             74.727273   \n",
       "2466               1.631579           1.587895             77.909091   \n",
       "2467               2.184211           2.045263             83.545455   \n",
       "2468               1.447368           1.375000             80.090909   \n",
       "2469               1.447368           1.492632             76.090909   \n",
       "\n",
       "      agent_1_feat_MissedAv  agent_2_feat_Rating  agent_1_feat_XgaAv  \\\n",
       "1979               1.526316                 6.83            1.763947   \n",
       "1980               1.473684                 6.72            1.295000   \n",
       "1981               1.763158                 6.63            1.884211   \n",
       "1982               1.710526                 6.52            1.665526   \n",
       "1983               1.421053                 6.65            1.081316   \n",
       "...                     ...                  ...                 ...   \n",
       "2465               1.631579                 6.77            1.579474   \n",
       "2466               1.736842                 6.77            1.628947   \n",
       "2467               2.000000                 7.01            1.948421   \n",
       "2468               1.789474                 6.69            1.540789   \n",
       "2469               1.447368                 6.84            1.554211   \n",
       "\n",
       "      agent_2_feat_xg_mean_3  agent_2_feat_scored_mean_3  \\\n",
       "1979                1.170650                    0.666667   \n",
       "1980                1.014997                    1.666667   \n",
       "1981                1.477451                    1.000000   \n",
       "1982                1.120646                    0.333333   \n",
       "1983                0.600833                    0.333333   \n",
       "...                      ...                         ...   \n",
       "2465                0.981234                    1.666667   \n",
       "2466                1.702073                    1.333333   \n",
       "2467                2.404496                    2.333333   \n",
       "2468                2.236761                    2.333333   \n",
       "2469                1.589569                    1.000000   \n",
       "\n",
       "      agent_2_feat_form_mean_3  agent_2_feat_scored_3  ...  \\\n",
       "1979                  0.000000                    1.0  ...   \n",
       "1980                  0.000000                    2.0  ...   \n",
       "1981                  0.000000                    0.0  ...   \n",
       "1982                 -1.000000                    0.0  ...   \n",
       "1983                  0.000000                    0.0  ...   \n",
       "...                        ...                    ...  ...   \n",
       "2465                 -0.333333                    5.0  ...   \n",
       "2466                  1.000000                    1.0  ...   \n",
       "2467                  1.000000                    1.0  ...   \n",
       "2468                  0.666667                    4.0  ...   \n",
       "2469                 -0.333333                    1.0  ...   \n",
       "\n",
       "      agent_1_feat_scored_1.1  agent_1_feat_xg_2  agent_2_feat_xga_mean_3  \\\n",
       "1979                      0.0           1.098070                 0.892297   \n",
       "1980                      1.0           2.358540                 1.888677   \n",
       "1981                      2.0           0.914266                 1.947001   \n",
       "1982                      2.0           2.319570                 2.625453   \n",
       "1983                      2.0           4.264430                 1.336501   \n",
       "...                       ...                ...                      ...   \n",
       "2465                      1.0           0.168796                 1.369450   \n",
       "2466                      2.0           0.709634                 0.410268   \n",
       "2467                      0.0           2.463320                 0.276812   \n",
       "2468                      1.0           0.500436                 0.582768   \n",
       "2469                      0.0           0.395668                 2.069648   \n",
       "\n",
       "      agent_1_feat_form_mean_3  agent_1_feat_scored_mean_3.1  \\\n",
       "1979                 -0.666667                      0.333333   \n",
       "1980                 -1.000000                      1.333333   \n",
       "1981                  0.000000                      1.333333   \n",
       "1982                  0.000000                      2.000000   \n",
       "1983                  0.333333                      1.666667   \n",
       "...                        ...                           ...   \n",
       "2465                 -1.000000                      0.666667   \n",
       "2466                  0.000000                      1.000000   \n",
       "2467                 -0.333333                      0.000000   \n",
       "2468                  0.000000                      0.333333   \n",
       "2469                 -0.333333                      1.000000   \n",
       "\n",
       "      agent_1_feat_xg_mean_3  agent_1_feat_XgAv  agent_2_feat_MissedAv  \\\n",
       "1979                0.481092           0.960263               0.947368   \n",
       "1980                1.642060           1.413421               1.631579   \n",
       "1981                2.102665           1.186579               1.421053   \n",
       "1982                1.433756           1.175526               1.973684   \n",
       "1983                2.549883           2.006053               1.526316   \n",
       "...                      ...                ...                    ...   \n",
       "2465                0.538870           1.156842               1.421053   \n",
       "2466                0.453369           0.928684               1.236842   \n",
       "2467                1.265762           0.920263               0.842105   \n",
       "2468                0.516526           1.191579               1.026316   \n",
       "2469                0.708280           1.003421               1.210526   \n",
       "\n",
       "      agent_2_feat_XgaAv  agent_1_feat_Rating  \n",
       "1979            1.001579                 6.65  \n",
       "1980            1.797895                 6.68  \n",
       "1981            1.590000                 6.62  \n",
       "1982            1.884474                 6.60  \n",
       "1983            1.763947                 6.86  \n",
       "...                  ...                  ...  \n",
       "2465            1.658421                 6.62  \n",
       "2466            1.312105                 6.61  \n",
       "2467            0.805526                 6.51  \n",
       "2468            1.137632                 6.62  \n",
       "2469            1.401316                 6.64  \n",
       "\n",
       "[433 rows x 33 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_test2 = X_test2[list(fearues_names2)]\n",
    "new_X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_XgAv</th>\n",
       "      <th>agent_2_feat_pl_mean</th>\n",
       "      <th>agent_1_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_xg_mean_3</th>\n",
       "      <th>agent_2_feat_scored_mean_3</th>\n",
       "      <th>agent_2_feat_form_mean_3</th>\n",
       "      <th>agent_2_feat_scored_3</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_1_feat_scored_1.1</th>\n",
       "      <th>agent_1_feat_xg_2</th>\n",
       "      <th>agent_2_feat_xga_mean_3</th>\n",
       "      <th>agent_1_feat_form_mean_3</th>\n",
       "      <th>agent_1_feat_scored_mean_3.1</th>\n",
       "      <th>agent_1_feat_xg_mean_3</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_2_feat_MissedAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.016316</td>\n",
       "      <td>76.909091</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>1.538212</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.379390</td>\n",
       "      <td>1.736522</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.895377</td>\n",
       "      <td>1.806842</td>\n",
       "      <td>1.368421</td>\n",
       "      <td>1.373421</td>\n",
       "      <td>6.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.710526</td>\n",
       "      <td>1.080526</td>\n",
       "      <td>75.181818</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1.050263</td>\n",
       "      <td>0.756073</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.177084</td>\n",
       "      <td>2.069040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.248041</td>\n",
       "      <td>1.416316</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>1.516842</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.789474</td>\n",
       "      <td>1.547368</td>\n",
       "      <td>77.727273</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.322390</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371045</td>\n",
       "      <td>0.419486</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421098</td>\n",
       "      <td>1.295789</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>1.238684</td>\n",
       "      <td>6.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.872632</td>\n",
       "      <td>74.909091</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>6.46</td>\n",
       "      <td>1.103158</td>\n",
       "      <td>1.104814</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.189290</td>\n",
       "      <td>0.976729</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.371087</td>\n",
       "      <td>1.662368</td>\n",
       "      <td>1.657895</td>\n",
       "      <td>1.739737</td>\n",
       "      <td>6.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.789474</td>\n",
       "      <td>1.900263</td>\n",
       "      <td>86.181818</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>6.82</td>\n",
       "      <td>1.382895</td>\n",
       "      <td>1.407720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.143720</td>\n",
       "      <td>0.923439</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.318723</td>\n",
       "      <td>1.491579</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>1.244737</td>\n",
       "      <td>6.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.905000</td>\n",
       "      <td>81.090909</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1.238000</td>\n",
       "      <td>1.130094</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.390090</td>\n",
       "      <td>1.992155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.827937</td>\n",
       "      <td>1.228000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>6.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.162000</td>\n",
       "      <td>76.181818</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.63</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>0.586779</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.272970</td>\n",
       "      <td>1.876742</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.628449</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.558000</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.644000</td>\n",
       "      <td>78.727273</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>1.031708</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.754170</td>\n",
       "      <td>2.248713</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.331350</td>\n",
       "      <td>2.736000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>7.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>75.363636</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>1.081035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.393040</td>\n",
       "      <td>1.591810</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.198800</td>\n",
       "      <td>2.598000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.018000</td>\n",
       "      <td>7.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>81.363636</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>6.88</td>\n",
       "      <td>2.122000</td>\n",
       "      <td>2.267448</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.219660</td>\n",
       "      <td>0.688478</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.176910</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.777500</td>\n",
       "      <td>6.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent_2_feat_ScoredAv  agent_2_feat_XgAv  agent_2_feat_pl_mean  \\\n",
       "0                 0.947368           1.016316             76.909091   \n",
       "1                 0.710526           1.080526             75.181818   \n",
       "2                 1.789474           1.547368             77.727273   \n",
       "3                 0.526316           0.872632             74.909091   \n",
       "4                 1.789474           1.900263             86.181818   \n",
       "..                     ...                ...                   ...   \n",
       "565               2.750000           1.905000             81.090909   \n",
       "566               0.800000           1.162000             76.181818   \n",
       "567               0.400000           1.644000             78.727273   \n",
       "568               1.600000           0.940000             75.363636   \n",
       "569               0.750000           0.947500             81.363636   \n",
       "\n",
       "     agent_1_feat_MissedAv  agent_2_feat_Rating  agent_1_feat_XgaAv  \\\n",
       "0                 0.947368                 6.67            0.813158   \n",
       "1                 1.210526                 6.63            1.050263   \n",
       "2                 1.263158                 6.80            1.320000   \n",
       "3                 1.157895                 6.46            1.103158   \n",
       "4                 1.184211                 6.82            1.382895   \n",
       "..                     ...                  ...                 ...   \n",
       "565               1.600000                 6.71            1.238000   \n",
       "566               1.500000                 6.63            1.950000   \n",
       "567               0.200000                 6.69            0.778000   \n",
       "568               0.200000                 6.68            0.498000   \n",
       "569               2.800000                 6.88            2.122000   \n",
       "\n",
       "     agent_2_feat_xg_mean_3  agent_2_feat_scored_mean_3  \\\n",
       "0                  1.538212                    2.000000   \n",
       "1                  0.756073                    0.666667   \n",
       "2                  1.322390                    2.000000   \n",
       "3                  1.104814                    0.666667   \n",
       "4                  1.407720                    0.000000   \n",
       "..                      ...                         ...   \n",
       "565                1.130094                    1.333333   \n",
       "566                0.586779                    0.666667   \n",
       "567                1.031708                    1.333333   \n",
       "568                1.081035                    1.000000   \n",
       "569                2.267448                    1.666667   \n",
       "\n",
       "     agent_2_feat_form_mean_3  agent_2_feat_scored_3  ...  \\\n",
       "0                   -0.666667                    3.0  ...   \n",
       "1                   -0.666667                    1.0  ...   \n",
       "2                    1.000000                    2.0  ...   \n",
       "3                   -0.333333                    0.0  ...   \n",
       "4                   -0.666667                    0.0  ...   \n",
       "..                        ...                    ...  ...   \n",
       "565                  0.000000                    1.0  ...   \n",
       "566                 -1.000000                    1.0  ...   \n",
       "567                 -0.333333                    2.0  ...   \n",
       "568                 -0.333333                    1.0  ...   \n",
       "569                  0.666667                    1.0  ...   \n",
       "\n",
       "     agent_1_feat_scored_1.1  agent_1_feat_xg_2  agent_2_feat_xga_mean_3  \\\n",
       "0                        1.0           1.379390                 1.736522   \n",
       "1                        3.0           0.177084                 2.069040   \n",
       "2                        0.0           0.371045                 0.419486   \n",
       "3                        2.0           1.189290                 0.976729   \n",
       "4                        1.0           3.143720                 0.923439   \n",
       "..                       ...                ...                      ...   \n",
       "565                      1.0           1.390090                 1.992155   \n",
       "566                      3.0           2.272970                 1.876742   \n",
       "567                      1.0           1.754170                 2.248713   \n",
       "568                      5.0           3.393040                 1.591810   \n",
       "569                      0.0           1.219660                 0.688478   \n",
       "\n",
       "     agent_1_feat_form_mean_3  agent_1_feat_scored_mean_3.1  \\\n",
       "0                   -0.333333                      1.666667   \n",
       "1                    0.000000                      1.333333   \n",
       "2                    0.333333                      1.000000   \n",
       "3                    0.666667                      3.000000   \n",
       "4                    0.666667                      1.333333   \n",
       "..                        ...                           ...   \n",
       "565                  0.000000                      1.333333   \n",
       "566                  0.666667                      1.333333   \n",
       "567                  0.666667                      2.333333   \n",
       "568                  0.666667                      4.333333   \n",
       "569                 -0.666667                      0.666667   \n",
       "\n",
       "     agent_1_feat_xg_mean_3  agent_1_feat_XgAv  agent_2_feat_MissedAv  \\\n",
       "0                  0.895377           1.806842               1.368421   \n",
       "1                  1.248041           1.416316               1.394737   \n",
       "2                  0.421098           1.295789               1.315789   \n",
       "3                  1.371087           1.662368               1.657895   \n",
       "4                  2.318723           1.491579               1.105263   \n",
       "..                      ...                ...                    ...   \n",
       "565                1.827937           1.228000               0.750000   \n",
       "566                1.628449           0.842500               1.200000   \n",
       "567                1.331350           2.736000               1.000000   \n",
       "568                3.198800           2.598000               1.400000   \n",
       "569                1.176910           0.832000               0.750000   \n",
       "\n",
       "     agent_2_feat_XgaAv  agent_1_feat_Rating  \n",
       "0              1.373421                 6.83  \n",
       "1              1.516842                 6.65  \n",
       "2              1.238684                 6.73  \n",
       "3              1.739737                 6.85  \n",
       "4              1.244737                 6.81  \n",
       "..                  ...                  ...  \n",
       "565            0.892500                 6.72  \n",
       "566            1.558000                 6.69  \n",
       "567            1.170000                 7.05  \n",
       "568            1.018000                 7.11  \n",
       "569            1.777500                 6.42  \n",
       "\n",
       "[570 rows x 33 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df2 = test_df2[list(fearues_names2)]\n",
    "new_test_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train2, new_X_test2, new_test_df2 = scale_data(new_X_train2, new_X_test2, new_test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1730, 9) (433, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train2 = pd.get_dummies(y_train2)\n",
    "y_test2 = pd.get_dummies(y_test2)\n",
    "y_train2, y_test2 = make_equal_dummies(y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_results2 = grid_search(new_X_train2, y_train2, 'expected_target2')\n",
    "batch_size2 = grid_results2.best_params_['batch_size']\n",
    "epochs2 = grid_results2.best_params_['epochs']\n",
    "learning_rate2 = grid_results2.best_params_['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size2 = 32\n",
    "# epochs2 = 100\n",
    "# learning_rate2 = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "14/14 [==============================] - 2s 23ms/step - loss: 2.9266 - accuracy: 0.1116 - val_loss: 2.1918 - val_accuracy: 0.1524\n",
      "Epoch 2/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.7972 - accuracy: 0.1347 - val_loss: 2.1496 - val_accuracy: 0.2702\n",
      "Epoch 3/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.6324 - accuracy: 0.1474 - val_loss: 2.1099 - val_accuracy: 0.3118\n",
      "Epoch 4/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.5117 - accuracy: 0.1642 - val_loss: 2.0722 - val_accuracy: 0.3187\n",
      "Epoch 5/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.4728 - accuracy: 0.1855 - val_loss: 2.0368 - val_accuracy: 0.3441\n",
      "Epoch 6/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.3881 - accuracy: 0.1908 - val_loss: 2.0027 - val_accuracy: 0.3510\n",
      "Epoch 7/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.2280 - accuracy: 0.2439 - val_loss: 1.9728 - val_accuracy: 0.3326\n",
      "Epoch 8/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.1960 - accuracy: 0.2306 - val_loss: 1.9439 - val_accuracy: 0.3372\n",
      "Epoch 9/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.1237 - accuracy: 0.2630 - val_loss: 1.9179 - val_accuracy: 0.3372\n",
      "Epoch 10/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 2.0944 - accuracy: 0.2757 - val_loss: 1.8947 - val_accuracy: 0.3441\n",
      "Epoch 11/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.0214 - accuracy: 0.2977 - val_loss: 1.8711 - val_accuracy: 0.3487\n",
      "Epoch 12/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 2.0230 - accuracy: 0.2931 - val_loss: 1.8501 - val_accuracy: 0.3418\n",
      "Epoch 13/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.9384 - accuracy: 0.3191 - val_loss: 1.8318 - val_accuracy: 0.3557\n",
      "Epoch 14/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.9092 - accuracy: 0.3237 - val_loss: 1.8171 - val_accuracy: 0.3510\n",
      "Epoch 15/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.9148 - accuracy: 0.3254 - val_loss: 1.8017 - val_accuracy: 0.3649\n",
      "Epoch 16/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.8640 - accuracy: 0.3185 - val_loss: 1.7855 - val_accuracy: 0.3603\n",
      "Epoch 17/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.8118 - accuracy: 0.3497 - val_loss: 1.7729 - val_accuracy: 0.3626\n",
      "Epoch 18/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7773 - accuracy: 0.3486 - val_loss: 1.7621 - val_accuracy: 0.3580\n",
      "Epoch 19/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7727 - accuracy: 0.3676 - val_loss: 1.7505 - val_accuracy: 0.3510\n",
      "Epoch 20/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7328 - accuracy: 0.3734 - val_loss: 1.7409 - val_accuracy: 0.3533\n",
      "Epoch 21/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7196 - accuracy: 0.3688 - val_loss: 1.7276 - val_accuracy: 0.3580\n",
      "Epoch 22/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.7044 - accuracy: 0.3896 - val_loss: 1.7179 - val_accuracy: 0.3557\n",
      "Epoch 23/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6998 - accuracy: 0.3803 - val_loss: 1.7071 - val_accuracy: 0.3626\n",
      "Epoch 24/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.6590 - accuracy: 0.3988 - val_loss: 1.6994 - val_accuracy: 0.3510\n",
      "Epoch 25/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6402 - accuracy: 0.3879 - val_loss: 1.6939 - val_accuracy: 0.3510\n",
      "Epoch 26/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6188 - accuracy: 0.4133 - val_loss: 1.6877 - val_accuracy: 0.3441\n",
      "Epoch 27/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.6101 - accuracy: 0.4104 - val_loss: 1.6792 - val_accuracy: 0.3441\n",
      "Epoch 28/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.6238 - accuracy: 0.3960 - val_loss: 1.6723 - val_accuracy: 0.3487\n",
      "Epoch 29/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5780 - accuracy: 0.4214 - val_loss: 1.6667 - val_accuracy: 0.3464\n",
      "Epoch 30/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5666 - accuracy: 0.4150 - val_loss: 1.6615 - val_accuracy: 0.3441\n",
      "Epoch 31/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.5701 - accuracy: 0.4162 - val_loss: 1.6532 - val_accuracy: 0.3418\n",
      "Epoch 32/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5239 - accuracy: 0.4220 - val_loss: 1.6451 - val_accuracy: 0.3441\n",
      "Epoch 33/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5544 - accuracy: 0.4040 - val_loss: 1.6381 - val_accuracy: 0.3487\n",
      "Epoch 34/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.5313 - accuracy: 0.4185 - val_loss: 1.6325 - val_accuracy: 0.3441\n",
      "Epoch 35/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4833 - accuracy: 0.4480 - val_loss: 1.6284 - val_accuracy: 0.3464\n",
      "Epoch 36/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.4995 - accuracy: 0.4370 - val_loss: 1.6264 - val_accuracy: 0.3372\n",
      "Epoch 37/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4938 - accuracy: 0.4179 - val_loss: 1.6232 - val_accuracy: 0.3372\n",
      "Epoch 38/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4793 - accuracy: 0.4353 - val_loss: 1.6196 - val_accuracy: 0.3418\n",
      "Epoch 39/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4810 - accuracy: 0.4289 - val_loss: 1.6146 - val_accuracy: 0.3372\n",
      "Epoch 40/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4460 - accuracy: 0.4636 - val_loss: 1.6116 - val_accuracy: 0.3349\n",
      "Epoch 41/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4539 - accuracy: 0.4410 - val_loss: 1.6088 - val_accuracy: 0.3326\n",
      "Epoch 42/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4571 - accuracy: 0.4376 - val_loss: 1.6036 - val_accuracy: 0.3326\n",
      "Epoch 43/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4436 - accuracy: 0.4555 - val_loss: 1.5970 - val_accuracy: 0.3418\n",
      "Epoch 44/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4260 - accuracy: 0.4272 - val_loss: 1.5911 - val_accuracy: 0.3441\n",
      "Epoch 45/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4087 - accuracy: 0.4457 - val_loss: 1.5864 - val_accuracy: 0.3441\n",
      "Epoch 46/75\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 1.4052 - accuracy: 0.4526 - val_loss: 1.5819 - val_accuracy: 0.3395\n",
      "Epoch 47/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4163 - accuracy: 0.4526 - val_loss: 1.5772 - val_accuracy: 0.3372\n",
      "Epoch 48/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3878 - accuracy: 0.4815 - val_loss: 1.5722 - val_accuracy: 0.3395\n",
      "Epoch 49/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4110 - accuracy: 0.4590 - val_loss: 1.5675 - val_accuracy: 0.3487\n",
      "Epoch 50/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3733 - accuracy: 0.4462 - val_loss: 1.5646 - val_accuracy: 0.3464\n",
      "Epoch 51/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4025 - accuracy: 0.4468 - val_loss: 1.5605 - val_accuracy: 0.3487\n",
      "Epoch 52/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.4032 - accuracy: 0.4474 - val_loss: 1.5562 - val_accuracy: 0.3464\n",
      "Epoch 53/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3887 - accuracy: 0.4590 - val_loss: 1.5549 - val_accuracy: 0.3464\n",
      "Epoch 54/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3608 - accuracy: 0.4566 - val_loss: 1.5543 - val_accuracy: 0.3418\n",
      "Epoch 55/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3712 - accuracy: 0.4682 - val_loss: 1.5522 - val_accuracy: 0.3487\n",
      "Epoch 56/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3599 - accuracy: 0.4653 - val_loss: 1.5515 - val_accuracy: 0.3464\n",
      "Epoch 57/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3436 - accuracy: 0.4636 - val_loss: 1.5481 - val_accuracy: 0.3418\n",
      "Epoch 58/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3482 - accuracy: 0.4613 - val_loss: 1.5476 - val_accuracy: 0.3464\n",
      "Epoch 59/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3473 - accuracy: 0.4607 - val_loss: 1.5453 - val_accuracy: 0.3510\n",
      "Epoch 60/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3453 - accuracy: 0.4671 - val_loss: 1.5432 - val_accuracy: 0.3603\n",
      "Epoch 61/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3213 - accuracy: 0.4902 - val_loss: 1.5428 - val_accuracy: 0.3603\n",
      "Epoch 62/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3216 - accuracy: 0.4671 - val_loss: 1.5424 - val_accuracy: 0.3418\n",
      "Epoch 63/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3158 - accuracy: 0.4613 - val_loss: 1.5435 - val_accuracy: 0.3510\n",
      "Epoch 64/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3379 - accuracy: 0.4584 - val_loss: 1.5462 - val_accuracy: 0.3441\n",
      "Epoch 65/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3429 - accuracy: 0.4595 - val_loss: 1.5483 - val_accuracy: 0.3395\n",
      "Epoch 66/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3094 - accuracy: 0.4792 - val_loss: 1.5455 - val_accuracy: 0.3395\n",
      "Epoch 67/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.2920 - accuracy: 0.4832 - val_loss: 1.5441 - val_accuracy: 0.3441\n",
      "Epoch 68/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3092 - accuracy: 0.4879 - val_loss: 1.5442 - val_accuracy: 0.3418\n",
      "Epoch 69/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3048 - accuracy: 0.4913 - val_loss: 1.5443 - val_accuracy: 0.3464\n",
      "Epoch 70/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3095 - accuracy: 0.4624 - val_loss: 1.5426 - val_accuracy: 0.3487\n",
      "Epoch 71/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.3137 - accuracy: 0.4855 - val_loss: 1.5401 - val_accuracy: 0.3580\n",
      "Epoch 72/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.2733 - accuracy: 0.4855 - val_loss: 1.5400 - val_accuracy: 0.3487\n",
      "Epoch 73/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.2916 - accuracy: 0.4815 - val_loss: 1.5373 - val_accuracy: 0.3557\n",
      "Epoch 74/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.2822 - accuracy: 0.4671 - val_loss: 1.5350 - val_accuracy: 0.3510\n",
      "Epoch 75/75\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 1.2921 - accuracy: 0.4792 - val_loss: 1.5323 - val_accuracy: 0.3557\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_df['expected_target2'].nunique()\n",
    "model2 = create_model(batch_size2, epochs2, learning_rate2, num_classes, new_X_train2.shape[1])\n",
    "history2 = model2.fit(new_X_train2, y_train2, \n",
    "                      batch_size = batch_size2, \n",
    "                      epochs = epochs2,\n",
    "                      validation_data = (new_X_test2, y_test2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_graphs(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n",
      "ACC:  0.672\n"
     ]
    }
   ],
   "source": [
    "tmp_pred_value2 = calc_train_acc(model2, 'expected_target2', Y_expected2, new_X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.logical_and(tmp_pred_value1, tmp_pred_value2)\n",
    "test_pred = [0 if x==False else x for x in test_pred]\n",
    "test_pred = [1 if x==True else x for x in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1979    0\n",
       "1980    0\n",
       "1981    1\n",
       "1982    0\n",
       "1983    0\n",
       "       ..\n",
       "2465    1\n",
       "2466    1\n",
       "2467    0\n",
       "2468    1\n",
       "2469    1\n",
       "Name: category, Length: 433, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_real_value = train_df['category'][int(len(Y_expected1)*0.8):len(Y_expected1)]\n",
    "test_real_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.536\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for elem1, elem2 in zip(test_pred, test_real_value):\n",
    "    if elem1 == elem2:\n",
    "        acc += 1\n",
    "print(\"ACC: \", np.round((acc / len(test_real_value)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKm-keClFa1Q"
   },
   "source": [
    "# Make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "fin_pred1 = model1.predict(new_test_df1)\n",
    "tmp1 = []\n",
    "for i in fin_pred1:\n",
    "    if i.argmax() != 0:\n",
    "        tmp1.append(1)\n",
    "    else:\n",
    "        tmp1.append(0)\n",
    "\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "fin_pred2 = model2.predict(new_test_df2)\n",
    "tmp2 = []\n",
    "for i in fin_pred2:\n",
    "    if i.argmax() != 0:\n",
    "        tmp2.append(1)\n",
    "    else:\n",
    "        tmp2.append(0)\n",
    "\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer = np.logical_and(tmp1, tmp2)\n",
    "Answer = [0 if x==False else x for x in Answer]\n",
    "Answer = [1 if x==True else x for x in Answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "_b27gGlzPE2w"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['tmp'] = Answer\n",
    "sample_submission.drop(['category'], axis = 1, inplace= True)\n",
    "sample_submission = sample_submission.rename(columns={\"tmp\": \"category\"})\n",
    "sample_submission.to_csv('Answer.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  category\n",
       "0      0         1\n",
       "1      1         1\n",
       "2      2         1\n",
       "3      3         0\n",
       "4      4         1\n",
       "..   ...       ...\n",
       "565  565         1\n",
       "566  566         1\n",
       "567  567         1\n",
       "568  568         1\n",
       "569  569         0\n",
       "\n",
       "[570 rows x 2 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 33% acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv('released_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5638297872340425\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for i, j in zip(sample_submission.iloc[0:len(answers)]['category'], answers['category']):\n",
    "    if i == j:\n",
    "        num +=1\n",
    "print(num / len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
