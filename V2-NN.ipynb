{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erc2A41DMzku"
   },
   "source": [
    "# DSBA 22/23 HSE & University of London\n",
    "\n",
    "# Practical assignment 1. DL in classification.\n",
    "\n",
    "## General info\n",
    "Release data: 26.09.2022\n",
    "\n",
    "Soft deadline: 10.10.2022 23:59 MSK\n",
    "\n",
    "Hard deadline: 13.10.2021 23:59 MSK\n",
    "\n",
    "In this task, you are to build a NN for a binary classification task. We suggest using Google Colab for access to GPU. Competition invite link: https://www.kaggle.com/t/1917e22edb71437ca24d790ab1d57695\n",
    "\n",
    "## Evaluation and fines\n",
    "\n",
    "Each section has a defined \"value\" (in brackets near the section). Maximum grade for the task - 10 points, other points can be assigned to your tests.\n",
    "\n",
    "**Your notebook with the best solution must be reproducible should be sent to the dropbox!** If the assessor cannot reproduce your results, you may be assigned score = 0, so make all your computations fixed!\n",
    "\n",
    "**You can only use neural networks / linear / nearest neighbors models for this task - tree-based models are forbidden!**\n",
    "\n",
    "All the parts must be done independently.\n",
    "\n",
    "After the hard deadline is passed, the hometask is not accepted. If you send the hometask after the soft deadline, you will be excluded from competition among your mates and the homework will only be scored by the \"Beating the baseline\" part.\n",
    "\n",
    "Feel free to ask questions both the teacher and your mates, but __do not copy the code or do it together__. \"Similar\" solutions are considered a plagiarism and all the involved students (the ones who gave & the ones who did) cannot get more than 0.01 points for the task. If you found a solution in some open source, you __must__ reference it in a special block at the end of your work (to exclude the suspicions in plagiarism).\n",
    "\n",
    "\n",
    "## Format of handing over\n",
    "\n",
    "The tasks are sent to the dropbox: https://www.dropbox.com/request/Y6TJouxNbm3r0RgcBL35. Don't forget to attach your name, surname & your group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwMZDBm4S9o3"
   },
   "source": [
    "## 1. Model training\n",
    "\n",
    "**Important!** Public Leaderboard contains only 33% of the test data. Your points will be measured wrt to the whole test set, therefore your position on the LB after the end of the competition may change.\n",
    "\n",
    "* test_accuracy > weak baseline (public LB): 3 points\n",
    "\n",
    "* test_accuracy > medium baseline (public LB): + 3 points\n",
    "\n",
    "* test_accuracy > strong baseline (public LB): + 2 points\n",
    "\n",
    "* You are among 25% most successful students (private LB): + 2 point\n",
    "\n",
    "* You are among top-3 most successful students (private LB): + 1 point\n",
    "\n",
    "* You are among top-2 most successful students (private LB): + 1 point\n",
    "\n",
    "* You are among top-1 most successful students (private LB): + 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VnJmCRD8S9o3"
   },
   "outputs": [],
   "source": [
    "# Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "WLBmP2zTFmnB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "c6tn9gN7ohs9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "3Tj4gkZnWENb"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "LudqW7xct2rH"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9PHJ1f-gPTm"
   },
   "source": [
    "# **Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "P3YAH9EgS9o3"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "target_df = pd.read_csv('train_target.csv')\n",
    "train_expected_target1 = pd.read_csv('train_expected_target_agent_1.csv')\n",
    "train_expected_target2 = pd.read_csv('train_expected_target_agent_2.csv')\n",
    "train_target_agent_1 = pd.read_csv('train_target_agent_1.csv')\n",
    "train_target_agent_2 = pd.read_csv('train_target_agent_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_agent_1 = train_target_agent_1.rename(columns={\"0\": \"expected_target1\"})\n",
    "train_target_agent_2 = train_target_agent_2.rename(columns={\"0\": \"expected_target2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_target_agent_1, train_target_agent_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "XtxGrhyjVEee",
    "outputId": "d81db566-83f9-47d1-c8e8-4c9333b09d31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>agent_1_feat_ODC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>14.16</td>\n",
       "      <td>267.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>7.66</td>\n",
       "      <td>191.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.53</td>\n",
       "      <td>195.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>8.76</td>\n",
       "      <td>161.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.8                85.1                     15.8   \n",
       "1                      44.8                71.1                     23.4   \n",
       "2                      46.3                70.8                     21.7   \n",
       "3                      50.2                77.5                     24.4   \n",
       "4                      44.9                75.0                     17.2   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.99               1.143700                0.928715   \n",
       "1                 6.84               0.954159                0.975350   \n",
       "2                 6.77               0.918434                1.118603   \n",
       "3                 6.87               1.037613                0.956836   \n",
       "4                 6.77               0.983691                0.948837   \n",
       "\n",
       "   agent_1_feat_PPDA  agent_1_feat_OPPDA  agent_1_feat_DC  agent_1_feat_ODC  \\\n",
       "0               7.13               14.16            267.0             194.0   \n",
       "1               9.99                7.66            191.0             287.0   \n",
       "2               9.56                7.34            179.0             298.0   \n",
       "3               9.60                9.53            195.0             239.0   \n",
       "4              12.24                8.76            161.0             283.0   \n",
       "\n",
       "   ...  agent_2_feattotal_xg_1  agent_2_feattotal_xg_mean_3  \\\n",
       "0  ...                2.739439                     2.739439   \n",
       "1  ...                2.336756                     2.336756   \n",
       "2  ...                2.120322                     2.120322   \n",
       "3  ...                2.216415                     2.216415   \n",
       "4  ...                2.604025                     2.604025   \n",
       "\n",
       "   agent_2_feattotal_xg_mean  agent_2_featboth_scored_3  \\\n",
       "0                        NaN                   0.473684   \n",
       "1                        NaN                   0.578947   \n",
       "2                        NaN                   0.368421   \n",
       "3                        NaN                   0.210526   \n",
       "4                        NaN                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_2  agent_2_featboth_scored_1  \\\n",
       "0                   0.473684                   0.473684   \n",
       "1                   0.578947                   0.578947   \n",
       "2                   0.368421                   0.368421   \n",
       "3                   0.210526                   0.210526   \n",
       "4                   0.421053                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_mean_3  agent_2_featboth_scored_mean  \\\n",
       "0                        0.473684                           NaN   \n",
       "1                        0.578947                           NaN   \n",
       "2                        0.368421                           NaN   \n",
       "3                        0.210526                           NaN   \n",
       "4                        0.421053                           NaN   \n",
       "\n",
       "   expected_target1  expected_target2  \n",
       "0                 1                 2  \n",
       "1                 2                 2  \n",
       "2                 0                 1  \n",
       "3                 0                 1  \n",
       "4                 2                 2  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "fi9w8WcKVID2",
    "outputId": "3acc7dd6-6503-4c25-ccee-9bbc933f764b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>agent_1_feat_ODC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_3</th>\n",
       "      <th>agent_2_feattotal_xg_2</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.844742</td>\n",
       "      <td>1.165049</td>\n",
       "      <td>9.19</td>\n",
       "      <td>16.50</td>\n",
       "      <td>337.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.661870</td>\n",
       "      <td>1.893116</td>\n",
       "      <td>4.241360</td>\n",
       "      <td>2.932115</td>\n",
       "      <td>2.690442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.7</td>\n",
       "      <td>81.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>1.152593</td>\n",
       "      <td>10.31</td>\n",
       "      <td>13.63</td>\n",
       "      <td>311.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.550724</td>\n",
       "      <td>2.373700</td>\n",
       "      <td>4.197010</td>\n",
       "      <td>3.373811</td>\n",
       "      <td>3.075302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.3</td>\n",
       "      <td>81.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.954509</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>14.21</td>\n",
       "      <td>11.82</td>\n",
       "      <td>207.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.693652</td>\n",
       "      <td>2.042668</td>\n",
       "      <td>0.966665</td>\n",
       "      <td>1.900995</td>\n",
       "      <td>3.007033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.5</td>\n",
       "      <td>84.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1.155612</td>\n",
       "      <td>1.049618</td>\n",
       "      <td>10.95</td>\n",
       "      <td>12.46</td>\n",
       "      <td>339.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.938100</td>\n",
       "      <td>1.466409</td>\n",
       "      <td>0.922046</td>\n",
       "      <td>2.108852</td>\n",
       "      <td>2.643923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>6.81</td>\n",
       "      <td>1.199718</td>\n",
       "      <td>0.856327</td>\n",
       "      <td>11.27</td>\n",
       "      <td>11.52</td>\n",
       "      <td>193.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.358338</td>\n",
       "      <td>2.138405</td>\n",
       "      <td>1.872476</td>\n",
       "      <td>2.456406</td>\n",
       "      <td>3.113815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.6                87.0                     15.2   \n",
       "1                      50.7                81.3                     14.2   \n",
       "2                      47.3                81.4                     17.7   \n",
       "3                      54.5                84.8                     14.5   \n",
       "4                      51.3                81.8                     16.4   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.83               0.844742                1.165049   \n",
       "1                 6.65               0.743218                1.152593   \n",
       "2                 6.73               0.954509                0.956938   \n",
       "3                 6.85               1.155612                1.049618   \n",
       "4                 6.81               1.199718                0.856327   \n",
       "\n",
       "   agent_1_feat_PPDA  agent_1_feat_OPPDA  agent_1_feat_DC  agent_1_feat_ODC  \\\n",
       "0               9.19               16.50            337.0             179.0   \n",
       "1              10.31               13.63            311.0             208.0   \n",
       "2              14.21               11.82            207.0             270.0   \n",
       "3              10.95               12.46            339.0             186.0   \n",
       "4              11.27               11.52            193.0             293.0   \n",
       "\n",
       "   ...  agent_2_feattotal_xg_3  agent_2_feattotal_xg_2  \\\n",
       "0  ...                2.661870                1.893116   \n",
       "1  ...                3.550724                2.373700   \n",
       "2  ...                2.693652                2.042668   \n",
       "3  ...                3.938100                1.466409   \n",
       "4  ...                3.358338                2.138405   \n",
       "\n",
       "   agent_2_feattotal_xg_1  agent_2_feattotal_xg_mean_3  \\\n",
       "0                4.241360                     2.932115   \n",
       "1                4.197010                     3.373811   \n",
       "2                0.966665                     1.900995   \n",
       "3                0.922046                     2.108852   \n",
       "4                1.872476                     2.456406   \n",
       "\n",
       "   agent_2_feattotal_xg_mean  agent_2_featboth_scored_3  \\\n",
       "0                   2.690442                        1.0   \n",
       "1                   3.075302                        0.0   \n",
       "2                   3.007033                        0.0   \n",
       "3                   2.643923                        1.0   \n",
       "4                   3.113815                        0.0   \n",
       "\n",
       "   agent_2_featboth_scored_2  agent_2_featboth_scored_1  \\\n",
       "0                        0.0                        1.0   \n",
       "1                        1.0                        1.0   \n",
       "2                        1.0                        1.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   agent_2_featboth_scored_mean_3  agent_2_featboth_scored_mean  \n",
       "0                        0.666667                      0.333333  \n",
       "1                        0.666667                      0.625000  \n",
       "2                        0.666667                      0.555556  \n",
       "3                        0.333333                      0.444444  \n",
       "4                        0.000000                      0.555556  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WlvCdFqVUSf",
    "outputId": "95181e8f-d145-49d6-8c1f-7520814b665c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2470, 236)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjIbnhiPVYT-",
    "outputId": "8c96af8c-bf60-401c-b737-9294f66f3cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2470 entries, 0 to 2469\n",
      "Columns: 236 entries, agent_1_feat_Possession% to expected_target2\n",
      "dtypes: float64(212), int64(24)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "ceY_OeBgqdO8"
   },
   "outputs": [],
   "source": [
    "target_df.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "p0N_mUFAqMIj"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([target_df, train_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "1TZbR6awq_C9",
    "outputId": "12ad58c1-8a7b-4bb0-dff6-5aac2487450b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>14.16</td>\n",
       "      <td>267.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>7.66</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.53</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>8.76</td>\n",
       "      <td>161.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.032989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.684860</td>\n",
       "      <td>4.024907</td>\n",
       "      <td>3.872622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1</td>\n",
       "      <td>42.9</td>\n",
       "      <td>76.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.066236</td>\n",
       "      <td>16.14</td>\n",
       "      <td>7.60</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568175</td>\n",
       "      <td>2.000313</td>\n",
       "      <td>2.572016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.026472</td>\n",
       "      <td>15.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.871643</td>\n",
       "      <td>2.496854</td>\n",
       "      <td>2.555157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1</td>\n",
       "      <td>51.4</td>\n",
       "      <td>79.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.161401</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.47</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.904164</td>\n",
       "      <td>2.977092</td>\n",
       "      <td>2.495116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>13.16</td>\n",
       "      <td>9.72</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.945618</td>\n",
       "      <td>3.414186</td>\n",
       "      <td>2.861741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2470 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  agent_1_feat_Possession%  agent_1_feat_Pass%  \\\n",
       "0            1                      58.8                85.1   \n",
       "1            1                      44.8                71.1   \n",
       "2            0                      46.3                70.8   \n",
       "3            0                      50.2                77.5   \n",
       "4            1                      44.9                75.0   \n",
       "...        ...                       ...                 ...   \n",
       "2465         1                      41.6                76.0   \n",
       "2466         1                      42.9                76.1   \n",
       "2467         0                      41.0                72.2   \n",
       "2468         1                      51.4                79.3   \n",
       "2469         1                      43.5                71.6   \n",
       "\n",
       "      agent_1_feat_AerialsWon  agent_1_feat_Rating  agent_1_feat_XGrealiz  \\\n",
       "0                        15.8                 6.99               1.143700   \n",
       "1                        23.4                 6.84               0.954159   \n",
       "2                        21.7                 6.77               0.918434   \n",
       "3                        24.4                 6.87               1.037613   \n",
       "4                        17.2                 6.77               0.983691   \n",
       "...                       ...                  ...                    ...   \n",
       "2465                     17.1                 6.62               1.046406   \n",
       "2466                     18.3                 6.61               1.161802   \n",
       "2467                     19.1                 6.51               1.000858   \n",
       "2468                     14.1                 6.62               1.037986   \n",
       "2469                     23.4                 6.64               0.865460   \n",
       "\n",
       "      agent_1_feat_XGArealiz  agent_1_feat_PPDA  agent_1_feat_OPPDA  \\\n",
       "0                   0.928715               7.13               14.16   \n",
       "1                   0.975350               9.99                7.66   \n",
       "2                   1.118603               9.56                7.34   \n",
       "3                   0.956836               9.60                9.53   \n",
       "4                   0.948837              12.24                8.76   \n",
       "...                      ...                ...                 ...   \n",
       "2465                1.032989              18.00                8.27   \n",
       "2466                1.066236              16.14                7.60   \n",
       "2467                1.026472              15.99                7.99   \n",
       "2468                1.161401               9.73               10.47   \n",
       "2469                0.931256              13.16                9.72   \n",
       "\n",
       "      agent_1_feat_DC  ...  agent_2_feattotal_xg_1  \\\n",
       "0               267.0  ...                2.739439   \n",
       "1               191.0  ...                2.336756   \n",
       "2               179.0  ...                2.120322   \n",
       "3               195.0  ...                2.216415   \n",
       "4               161.0  ...                2.604025   \n",
       "...               ...  ...                     ...   \n",
       "2465            138.0  ...                3.684860   \n",
       "2466            201.0  ...                1.568175   \n",
       "2467            164.0  ...                3.871643   \n",
       "2468            222.0  ...                4.904164   \n",
       "2469            233.0  ...                3.945618   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "0                        2.739439                        NaN   \n",
       "1                        2.336756                        NaN   \n",
       "2                        2.120322                        NaN   \n",
       "3                        2.216415                        NaN   \n",
       "4                        2.604025                        NaN   \n",
       "...                           ...                        ...   \n",
       "2465                     4.024907                   3.872622   \n",
       "2466                     2.000313                   2.572016   \n",
       "2467                     2.496854                   2.555157   \n",
       "2468                     2.977092                   2.495116   \n",
       "2469                     3.414186                   2.861741   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "0                      0.473684                   0.473684   \n",
       "1                      0.578947                   0.578947   \n",
       "2                      0.368421                   0.368421   \n",
       "3                      0.210526                   0.210526   \n",
       "4                      0.421053                   0.421053   \n",
       "...                         ...                        ...   \n",
       "2465                   1.000000                   0.000000   \n",
       "2466                   0.000000                   0.000000   \n",
       "2467                   0.000000                   0.000000   \n",
       "2468                   1.000000                   0.000000   \n",
       "2469                   1.000000                   1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "0                      0.473684                        0.473684   \n",
       "1                      0.578947                        0.578947   \n",
       "2                      0.368421                        0.368421   \n",
       "3                      0.210526                        0.210526   \n",
       "4                      0.421053                        0.421053   \n",
       "...                         ...                             ...   \n",
       "2465                   0.000000                        0.333333   \n",
       "2466                   0.000000                        0.000000   \n",
       "2467                   1.000000                        0.333333   \n",
       "2468                   0.000000                        0.333333   \n",
       "2469                   0.000000                        0.666667   \n",
       "\n",
       "      agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "0                              NaN                 1                 2  \n",
       "1                              NaN                 2                 2  \n",
       "2                              NaN                 0                 1  \n",
       "3                              NaN                 0                 1  \n",
       "4                              NaN                 2                 2  \n",
       "...                            ...               ...               ...  \n",
       "2465                      0.444444                 1                 2  \n",
       "2466                      0.444444                 2                 3  \n",
       "2467                      0.500000                 0                 5  \n",
       "2468                      0.222222                 1                 3  \n",
       "2469                      0.333333                 3                 2  \n",
       "\n",
       "[2470 rows x 237 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VaUeSE29_6w"
   },
   "source": [
    "## Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "CkheOAfn_zOK",
    "outputId": "000d0384-64b4-4d66-f341-0a872abe165e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_expected_target2</th>\n",
       "      <th>train_expected_target1</th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278076</td>\n",
       "      <td>1.166350</td>\n",
       "      <td>1</td>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613273</td>\n",
       "      <td>1.278300</td>\n",
       "      <td>1</td>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.117570</td>\n",
       "      <td>1.900670</td>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991901</td>\n",
       "      <td>1.683430</td>\n",
       "      <td>1</td>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_expected_target2  train_expected_target1  category  \\\n",
       "0                0.278076                1.166350         1   \n",
       "1                0.613273                1.278300         1   \n",
       "2                1.117570                1.900670         0   \n",
       "3                0.909774                0.423368         0   \n",
       "4                0.991901                1.683430         1   \n",
       "\n",
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.8                85.1                     15.8   \n",
       "1                      44.8                71.1                     23.4   \n",
       "2                      46.3                70.8                     21.7   \n",
       "3                      50.2                77.5                     24.4   \n",
       "4                      44.9                75.0                     17.2   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.99               1.143700                0.928715   \n",
       "1                 6.84               0.954159                0.975350   \n",
       "2                 6.77               0.918434                1.118603   \n",
       "3                 6.87               1.037613                0.956836   \n",
       "4                 6.77               0.983691                0.948837   \n",
       "\n",
       "   agent_1_feat_PPDA  ...  agent_2_feattotal_xg_1  \\\n",
       "0               7.13  ...                2.739439   \n",
       "1               9.99  ...                2.336756   \n",
       "2               9.56  ...                2.120322   \n",
       "3               9.60  ...                2.216415   \n",
       "4              12.24  ...                2.604025   \n",
       "\n",
       "   agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "0                     2.739439                        NaN   \n",
       "1                     2.336756                        NaN   \n",
       "2                     2.120322                        NaN   \n",
       "3                     2.216415                        NaN   \n",
       "4                     2.604025                        NaN   \n",
       "\n",
       "   agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "0                   0.473684                   0.473684   \n",
       "1                   0.578947                   0.578947   \n",
       "2                   0.368421                   0.368421   \n",
       "3                   0.210526                   0.210526   \n",
       "4                   0.421053                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "0                   0.473684                        0.473684   \n",
       "1                   0.578947                        0.578947   \n",
       "2                   0.368421                        0.368421   \n",
       "3                   0.210526                        0.210526   \n",
       "4                   0.421053                        0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "0                           NaN                 1                 2  \n",
       "1                           NaN                 2                 2  \n",
       "2                           NaN                 0                 1  \n",
       "3                           NaN                 0                 1  \n",
       "4                           NaN                 2                 2  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_expected_target1 = train_expected_target1.rename(columns={\"0\": \"train_expected_target1\"})\n",
    "train_expected_target2 = train_expected_target2.rename(columns={\"0\": \"train_expected_target2\"})\n",
    "train_df = pd.concat([train_expected_target1, train_df], axis = 1)\n",
    "train_df = pd.concat([train_expected_target2, train_df], axis = 1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJHCElVu-906",
    "outputId": "df35fdc8-6e8d-4af7-9ecf-e96d0c76a9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deleting:  2470\n",
      "Rows after deleting:  2295\n"
     ]
    }
   ],
   "source": [
    "print('Rows before deleting: ', train_df.shape[0])\n",
    "train_df = train_df.drop(train_df[(train_df.train_expected_target2 > 1) &\n",
    "                                  (train_df.train_expected_target1 > 1) &\n",
    "                                  (train_df.category == 0)].index)\n",
    "train_df.drop(['train_expected_target1', 'train_expected_target2'], axis = 1, inplace = True)\n",
    "print('Rows after deleting: ', train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ruuBsKl75SR"
   },
   "source": [
    "## Work with missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc2PbEGDRIjw",
    "outputId": "3042e755-cbf8-4661-ac14-71b4a75e601c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deleting:  2295\n",
      "Rows after deleting:  2163\n"
     ]
    }
   ],
   "source": [
    "print('Rows before deleting: ', train_df.shape[0])\n",
    "train_df = train_df.dropna()  \n",
    "print('Rows after deleting: ', train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>25.1</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.711201</td>\n",
       "      <td>0.915529</td>\n",
       "      <td>10.74</td>\n",
       "      <td>9.43</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.608046</td>\n",
       "      <td>2.112304</td>\n",
       "      <td>1.608046</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>15.9</td>\n",
       "      <td>7.07</td>\n",
       "      <td>1.094698</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>7.57</td>\n",
       "      <td>13.92</td>\n",
       "      <td>575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479335</td>\n",
       "      <td>2.214160</td>\n",
       "      <td>2.479335</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>48.1</td>\n",
       "      <td>76.9</td>\n",
       "      <td>17.7</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.994530</td>\n",
       "      <td>1.235052</td>\n",
       "      <td>9.77</td>\n",
       "      <td>8.24</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.712261</td>\n",
       "      <td>2.183093</td>\n",
       "      <td>1.712261</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.675331</td>\n",
       "      <td>2.627794</td>\n",
       "      <td>2.675331</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>50.7</td>\n",
       "      <td>82.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.124694</td>\n",
       "      <td>0.875939</td>\n",
       "      <td>11.79</td>\n",
       "      <td>10.66</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>2.260683</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.032989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.684860</td>\n",
       "      <td>4.024907</td>\n",
       "      <td>3.872622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1</td>\n",
       "      <td>42.9</td>\n",
       "      <td>76.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.066236</td>\n",
       "      <td>16.14</td>\n",
       "      <td>7.60</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568175</td>\n",
       "      <td>2.000313</td>\n",
       "      <td>2.572016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.026472</td>\n",
       "      <td>15.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.871643</td>\n",
       "      <td>2.496854</td>\n",
       "      <td>2.555157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1</td>\n",
       "      <td>51.4</td>\n",
       "      <td>79.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.161401</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.47</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.904164</td>\n",
       "      <td>2.977092</td>\n",
       "      <td>2.495116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>13.16</td>\n",
       "      <td>9.72</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.945618</td>\n",
       "      <td>3.414186</td>\n",
       "      <td>2.861741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2163 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  agent_1_feat_Possession%  agent_1_feat_Pass%  \\\n",
       "20           0                      44.0                70.3   \n",
       "21           0                      57.0                84.6   \n",
       "22           1                      48.1                76.9   \n",
       "23           0                      46.3                70.8   \n",
       "24           0                      50.7                82.1   \n",
       "...        ...                       ...                 ...   \n",
       "2465         1                      41.6                76.0   \n",
       "2466         1                      42.9                76.1   \n",
       "2467         0                      41.0                72.2   \n",
       "2468         1                      51.4                79.3   \n",
       "2469         1                      43.5                71.6   \n",
       "\n",
       "      agent_1_feat_AerialsWon  agent_1_feat_Rating  agent_1_feat_XGrealiz  \\\n",
       "20                       25.1                 6.79               0.711201   \n",
       "21                       15.9                 7.07               1.094698   \n",
       "22                       17.7                 6.74               0.994530   \n",
       "23                       21.7                 6.77               0.918434   \n",
       "24                       14.4                 6.86               1.124694   \n",
       "...                       ...                  ...                    ...   \n",
       "2465                     17.1                 6.62               1.046406   \n",
       "2466                     18.3                 6.61               1.161802   \n",
       "2467                     19.1                 6.51               1.000858   \n",
       "2468                     14.1                 6.62               1.037986   \n",
       "2469                     23.4                 6.64               0.865460   \n",
       "\n",
       "      agent_1_feat_XGArealiz  agent_1_feat_PPDA  agent_1_feat_OPPDA  \\\n",
       "20                  0.915529              10.74                9.43   \n",
       "21                  0.938272               7.57               13.92   \n",
       "22                  1.235052               9.77                8.24   \n",
       "23                  1.118603               9.56                7.34   \n",
       "24                  0.875939              11.79               10.66   \n",
       "...                      ...                ...                 ...   \n",
       "2465                1.032989              18.00                8.27   \n",
       "2466                1.066236              16.14                7.60   \n",
       "2467                1.026472              15.99                7.99   \n",
       "2468                1.161401               9.73               10.47   \n",
       "2469                0.931256              13.16                9.72   \n",
       "\n",
       "      agent_1_feat_DC  ...  agent_2_feattotal_xg_1  \\\n",
       "20              218.0  ...                1.608046   \n",
       "21              575.0  ...                2.479335   \n",
       "22              175.0  ...                1.712261   \n",
       "23              179.0  ...                2.675331   \n",
       "24              156.0  ...                1.331644   \n",
       "...               ...  ...                     ...   \n",
       "2465            138.0  ...                3.684860   \n",
       "2466            201.0  ...                1.568175   \n",
       "2467            164.0  ...                3.871643   \n",
       "2468            222.0  ...                4.904164   \n",
       "2469            233.0  ...                3.945618   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "20                       2.112304                   1.608046   \n",
       "21                       2.214160                   2.479335   \n",
       "22                       2.183093                   1.712261   \n",
       "23                       2.627794                   2.675331   \n",
       "24                       2.260683                   1.331644   \n",
       "...                           ...                        ...   \n",
       "2465                     4.024907                   3.872622   \n",
       "2466                     2.000313                   2.572016   \n",
       "2467                     2.496854                   2.555157   \n",
       "2468                     2.977092                   2.495116   \n",
       "2469                     3.414186                   2.861741   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "20                     0.578947                   0.578947   \n",
       "21                     0.526316                   0.526316   \n",
       "22                     0.526316                   0.526316   \n",
       "23                     0.421053                   0.421053   \n",
       "24                     0.368421                   0.368421   \n",
       "...                         ...                        ...   \n",
       "2465                   1.000000                   0.000000   \n",
       "2466                   0.000000                   0.000000   \n",
       "2467                   0.000000                   0.000000   \n",
       "2468                   1.000000                   0.000000   \n",
       "2469                   1.000000                   1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "20                          1.0                        0.719298   \n",
       "21                          1.0                        0.684211   \n",
       "22                          1.0                        0.684211   \n",
       "23                          1.0                        0.614035   \n",
       "24                          0.0                        0.245614   \n",
       "...                         ...                             ...   \n",
       "2465                        0.0                        0.333333   \n",
       "2466                        0.0                        0.000000   \n",
       "2467                        1.0                        0.333333   \n",
       "2468                        0.0                        0.333333   \n",
       "2469                        0.0                        0.666667   \n",
       "\n",
       "      agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "20                        1.000000                 0                 0  \n",
       "21                        1.000000                 0                 1  \n",
       "22                        1.000000                 3                 3  \n",
       "23                        1.000000                 1                 0  \n",
       "24                        0.000000                 3                 0  \n",
       "...                            ...               ...               ...  \n",
       "2465                      0.444444                 1                 2  \n",
       "2466                      0.444444                 2                 3  \n",
       "2467                      0.500000                 0                 5  \n",
       "2468                      0.222222                 1                 3  \n",
       "2469                      0.333333                 3                 2  \n",
       "\n",
       "[2163 rows x 237 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_target1          1.000000\n",
      "agent_1_feat_ScoredAv     0.385431\n",
      "agent_1_feat_XgAv         0.360820\n",
      "agent_1_feat_DC           0.341588\n",
      "agent_1_feat_pl_median    0.328869\n",
      "                            ...   \n",
      "agent_1_feat_PPDA        -0.213783\n",
      "agent_2_feat_Rating      -0.215384\n",
      "agent_1_feat_MissedAv    -0.260551\n",
      "agent_1_feat_XgaAv       -0.267009\n",
      "agent_1_feat_ODC         -0.290223\n",
      "Name: expected_target1, Length: 237, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix1 = train_df.corr()\n",
    "print(corr_matrix1[\"expected_target1\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_target2         1.000000\n",
      "category                 0.471964\n",
      "agent_2_feat_ScoredAv    0.335948\n",
      "agent_2_feat_XgAv        0.324758\n",
      "agent_2_feat_pl_mean     0.294398\n",
      "                           ...   \n",
      "agent_2_feat_MissedAv   -0.225085\n",
      "agent_1_feat_pl_mean    -0.225340\n",
      "agent_2_feat_XgaAv      -0.241378\n",
      "agent_1_feat_Rating     -0.250496\n",
      "agent_2_feat_ODC        -0.263211\n",
      "Name: expected_target2, Length: 237, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix2 = train_df.corr()\n",
    "print(corr_matrix2[\"expected_target2\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6FEvgOH7tUX"
   },
   "source": [
    "## Split dataset on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "A3QmeYdOEhwI"
   },
   "outputs": [],
   "source": [
    "X = train_df.drop(['expected_target1','category','expected_target2'], axis=1)\n",
    "Y_category = train_df['category']\n",
    "Y_expected1 = train_df['expected_target1']\n",
    "Y_expected2 = train_df['expected_target2']\n",
    "X_train, X_test, y_train1, y_test1, y_train2, y_test2 = (X.iloc[0:int(len(X)*0.8)], \n",
    "                                    X.iloc[int(len(X)*0.8):len(X)], \n",
    "                                    Y_expected1.iloc[0:int(len(Y_expected1)*0.8)], \n",
    "                                    Y_expected1.iloc[int(len(Y_expected1)*0.8):len(Y_expected1)],\n",
    "                                    Y_expected2.iloc[0:int(len(Y_expected2)*0.8)], \n",
    "                                    Y_expected2.iloc[int(len(Y_expected2)*0.8):len(Y_expected2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1730, 234), (433, 234), (1730,), (433,), (1730,), (433,))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train1.shape, y_test1.shape, y_train2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCXvCiWHPn3F"
   },
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(batch_size, epochs, learning_rate, num_classes, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation=\"relu\", input_shape=(input_shape, ))) # Hidden Layer 1\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Dense(128, activation=\"relu\")) # Hidden Layer 2\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64, activation=\"relu\")) # Hidden Layer 3\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(64, activation=\"relu\")) # Hidden Layer 4\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(32, activation=\"relu\")) # Hidden Layer 5\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(16, activation=\"relu\")) # Hidden Layer 6\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "        \n",
    "    model.add(Dense(num_classes, activation=\"softmax\")) # Outout Layer\n",
    "    \n",
    "    sgd = SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "\n",
    "    model.compile(optimizer=sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_equal_dummies(y_train, y_test):\n",
    "    dif = len(y_train.columns) - len(y_test.columns)\n",
    "    if dif == 0:\n",
    "        pass\n",
    "    elif dif > 0:\n",
    "        while dif != 0:\n",
    "            y_test[int(y_test.columns[-1])+1] = 0\n",
    "            dif -= 1\n",
    "    else:\n",
    "        while dif != 0:\n",
    "            y_train[int(y_train.columns[-1])+1] = 0\n",
    "            dif += 1\n",
    "            \n",
    "    print(y_train.shape, y_test.shape)\n",
    "    return y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graphs(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_train_acc(model, expected_target, Y_expected, X_test):\n",
    "    tmp_real_value = train_df[expected_target][int(len(Y_expected)*0.8):len(Y_expected)]\n",
    "    y_pred = model.predict(X_test)\n",
    "    tmp_pred_value = []\n",
    "    for i in y_pred:\n",
    "        if i.argmax() != 0:\n",
    "            tmp_pred_value.append(1)\n",
    "        else:\n",
    "            tmp_pred_value.append(0)\n",
    "    \n",
    "#     print(len(tmp_real_value), len(tmp_pred_value))\n",
    "    num_matching = 0\n",
    "    if len(tmp_real_value) == len(tmp_pred_value):\n",
    "        for i, j in zip(tmp_real_value, tmp_pred_value):\n",
    "            if i != 0:\n",
    "                i = 1\n",
    "            if i == j:\n",
    "                num_matching += 1\n",
    "        print(\"ACC: \", np.round((num_matching / len(tmp_real_value)), 3))\n",
    "    else:\n",
    "        print('Not equal siae of predictions')\n",
    "        \n",
    "    return tmp_pred_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, test_df):\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    test_df = scaler.transform(test_df)\n",
    "    \n",
    "    return X_train, X_test, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_model(X_train, y_train, X_test):\n",
    "    error_rates = []\n",
    "\n",
    "    for i in np.arange(1, 100):\n",
    "        new_model = KNeighborsClassifier(n_neighbors = i)\n",
    "        new_model.fit(X_train, y_train)\n",
    "        model1 = KNeighborsClassifier(n_neighbors = 5)\n",
    "        model1.fit(X_train, y_train)\n",
    "        new_predictions = new_model.predict(X_test)\n",
    "        error_rates.append(np.mean(new_predictions != y_test))\n",
    "\n",
    "    plt.plot(error_rates);\n",
    "    \n",
    "    return error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X_train, y_train, X_test):\n",
    "    feature_selection_model = KNeighborsClassifier(n_neighbors = np.argmin(KNN_model(X_train, y_train, X_test)))\n",
    "    \n",
    "    sfs1 = SFS(feature_selection_model1,\n",
    "          k_features=X_train.shape[1],\n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='accuracy', \n",
    "          verbose=1,\n",
    "          cv=StratifiedKFold(n_splits=5),\n",
    "          n_jobs=-1\n",
    "          )\n",
    "\n",
    "    sfs = sfs.fit(X_train, y_train)\n",
    "    \n",
    "    sfs_data = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "\n",
    "    sfs_data['avg_score'] = pd.to_numeric(sfs_data['avg_score'])\n",
    "    fearues_names = (sfs_data.loc[sfs_data['avg_score'].idxmax(), 'feature_names'])\n",
    "    \n",
    "    return fearues_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X_train, y_train, expected_target):\n",
    "    batch_size = [32, 64, 128, 256]\n",
    "    epochs = [50, 75, 125, 150]\n",
    "    learning_rate = [0.001, 0.0001, 0.00001]\n",
    "    num_classes = [train_df[expected_target].nunique()]\n",
    "    input_shape = [X_train.shape[1]]\n",
    "    param_opt = dict(batch_size=batch_size,\n",
    "                     epochs=epochs,\n",
    "                     learning_rate=learning_rate,\n",
    "                     num_classes=num_classes,\n",
    "                     input_shape=input_shape)\n",
    "\n",
    "\n",
    "    model_GridSearch = KerasClassifier(build_fn=create_model, \n",
    "                                       verbose=0)\n",
    "    grid = GridSearchCV(estimator=model_GridSearch, \n",
    "                        param_grid=param_opt, \n",
    "                        n_jobs=1, \n",
    "                        cv=5, \n",
    "                        verbose = 0)\n",
    "    grid_result = grid.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best parameters are: ')\n",
    "    print('batch_size: ' + str(grid_result.best_params_['batch_size']))\n",
    "    print('epochs: ' + str(grid_result.best_params_['epochs']))\n",
    "    print('learning_rate: ' + str(grid_result.best_params_['learning_rate']))\n",
    "    \n",
    "    return grid_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Agent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fearues_names1 = feature_selection(X_train, y_train1, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_ScoredAv</th>\n",
       "      <th>agent_1_feat_MissedAv</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_Long key passes</th>\n",
       "      <th>agent_1_feat_scored_mean_3</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feat_both_scored_mean</th>\n",
       "      <th>agent_2_feattotal_scored_1</th>\n",
       "      <th>agent_2_feattotal_scored_mean</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.79</td>\n",
       "      <td>0.711201</td>\n",
       "      <td>0.915529</td>\n",
       "      <td>9.43</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>1.036053</td>\n",
       "      <td>1.523421</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.112304</td>\n",
       "      <td>1.608046</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.07</td>\n",
       "      <td>1.094698</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>13.92</td>\n",
       "      <td>2.184211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.995263</td>\n",
       "      <td>1.065789</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.394737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.214160</td>\n",
       "      <td>2.479335</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.74</td>\n",
       "      <td>0.994530</td>\n",
       "      <td>1.235052</td>\n",
       "      <td>8.24</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.657895</td>\n",
       "      <td>1.058421</td>\n",
       "      <td>1.342368</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.183093</td>\n",
       "      <td>1.712261</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>7.34</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>1.921053</td>\n",
       "      <td>1.203421</td>\n",
       "      <td>1.717368</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.627794</td>\n",
       "      <td>2.675331</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.86</td>\n",
       "      <td>1.124694</td>\n",
       "      <td>0.875939</td>\n",
       "      <td>10.66</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.289474</td>\n",
       "      <td>1.076316</td>\n",
       "      <td>1.472105</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.403509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.260683</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>6.52</td>\n",
       "      <td>0.698362</td>\n",
       "      <td>1.047340</td>\n",
       "      <td>9.65</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.973684</td>\n",
       "      <td>0.979737</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.059083</td>\n",
       "      <td>3.059083</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>6.59</td>\n",
       "      <td>0.741351</td>\n",
       "      <td>1.075088</td>\n",
       "      <td>9.64</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.684211</td>\n",
       "      <td>1.277895</td>\n",
       "      <td>1.566579</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.686777</td>\n",
       "      <td>2.686777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>6.72</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>0.907494</td>\n",
       "      <td>9.50</td>\n",
       "      <td>1.289474</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.291316</td>\n",
       "      <td>1.797895</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.209686</td>\n",
       "      <td>2.209686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>6.71</td>\n",
       "      <td>0.902655</td>\n",
       "      <td>1.060258</td>\n",
       "      <td>9.97</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>1.486842</td>\n",
       "      <td>1.489211</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>3.668220</td>\n",
       "      <td>3.668220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>6.71</td>\n",
       "      <td>1.101928</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>11.45</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.337368</td>\n",
       "      <td>1.506579</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.182929</td>\n",
       "      <td>3.182929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "20                   6.79               0.711201                0.915529   \n",
       "21                   7.07               1.094698                0.938272   \n",
       "22                   6.74               0.994530                1.235052   \n",
       "23                   6.77               0.918434                1.118603   \n",
       "24                   6.86               1.124694                0.875939   \n",
       "...                   ...                    ...                     ...   \n",
       "1973                 6.52               0.698362                1.047340   \n",
       "1974                 6.59               0.741351                1.075088   \n",
       "1975                 6.72               0.998573                0.907494   \n",
       "1977                 6.71               0.902655                1.060258   \n",
       "1978                 6.71               1.101928                0.838428   \n",
       "\n",
       "      agent_1_feat_OPPDA  agent_1_feat_ScoredAv  agent_1_feat_MissedAv  \\\n",
       "20                  9.43               0.736842               1.394737   \n",
       "21                 13.92               2.184211               1.000000   \n",
       "22                  8.24               1.052632               1.657895   \n",
       "23                  7.34               1.105263               1.921053   \n",
       "24                 10.66               1.210526               1.289474   \n",
       "...                  ...                    ...                    ...   \n",
       "1973                9.65               0.684211               1.973684   \n",
       "1974                9.64               0.947368               1.684211   \n",
       "1975                9.50               1.289474               1.631579   \n",
       "1977                9.97               1.342105               1.578947   \n",
       "1978               11.45               1.473684               1.263158   \n",
       "\n",
       "      agent_1_feat_XgAv  agent_1_feat_XgaAv  agent_1_feat_Long key passes  \\\n",
       "20             1.036053            1.523421                           1.9   \n",
       "21             1.995263            1.065789                           1.4   \n",
       "22             1.058421            1.342368                           1.1   \n",
       "23             1.203421            1.717368                           2.1   \n",
       "24             1.076316            1.472105                           0.9   \n",
       "...                 ...                 ...                           ...   \n",
       "1973           0.979737            1.884474                           0.9   \n",
       "1974           1.277895            1.566579                           1.3   \n",
       "1975           1.291316            1.797895                           1.8   \n",
       "1977           1.486842            1.489211                           1.4   \n",
       "1978           1.337368            1.506579                           0.9   \n",
       "\n",
       "      agent_1_feat_scored_mean_3  ...  agent_2_feat_both_scored_mean  \\\n",
       "20                      0.578947  ...                       1.000000   \n",
       "21                      2.394737  ...                       0.500000   \n",
       "22                      0.350877  ...                       1.000000   \n",
       "23                      0.368421  ...                       1.000000   \n",
       "24                      1.403509  ...                       0.500000   \n",
       "...                          ...  ...                            ...   \n",
       "1973                    1.000000  ...                       0.571429   \n",
       "1974                    0.666667  ...                       0.428571   \n",
       "1975                    1.333333  ...                       0.285714   \n",
       "1977                    1.000000  ...                       0.714286   \n",
       "1978                    2.000000  ...                       1.000000   \n",
       "\n",
       "      agent_2_feattotal_scored_1  agent_2_feattotal_scored_mean  \\\n",
       "20                           2.0                       2.000000   \n",
       "21                           2.0                       2.000000   \n",
       "22                           3.0                       3.000000   \n",
       "23                           4.0                       4.000000   \n",
       "24                           0.0                       0.000000   \n",
       "...                          ...                            ...   \n",
       "1973                         5.0                       3.333333   \n",
       "1974                         2.0                       2.666667   \n",
       "1975                         4.0                       2.666667   \n",
       "1977                         7.0                       5.333333   \n",
       "1978                         4.0                       3.666667   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "20                       2.112304                   1.608046   \n",
       "21                       2.214160                   2.479335   \n",
       "22                       2.183093                   1.712261   \n",
       "23                       2.627794                   2.675331   \n",
       "24                       2.260683                   1.331644   \n",
       "...                           ...                        ...   \n",
       "1973                     3.059083                   3.059083   \n",
       "1974                     2.686777                   2.686777   \n",
       "1975                     2.209686                   2.209686   \n",
       "1977                     3.668220                   3.668220   \n",
       "1978                     3.182929                   3.182929   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "20                     0.578947                   0.578947   \n",
       "21                     0.526316                   0.526316   \n",
       "22                     0.526316                   0.526316   \n",
       "23                     0.421053                   0.421053   \n",
       "24                     0.368421                   0.368421   \n",
       "...                         ...                        ...   \n",
       "1973                   1.000000                   0.000000   \n",
       "1974                   1.000000                   1.000000   \n",
       "1975                   0.000000                   1.000000   \n",
       "1977                   0.000000                   1.000000   \n",
       "1978                   1.000000                   1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "20                          1.0                        0.719298   \n",
       "21                          1.0                        0.684211   \n",
       "22                          1.0                        0.684211   \n",
       "23                          1.0                        0.614035   \n",
       "24                          0.0                        0.245614   \n",
       "...                         ...                             ...   \n",
       "1973                        1.0                        0.666667   \n",
       "1974                        0.0                        0.666667   \n",
       "1975                        0.0                        0.333333   \n",
       "1977                        1.0                        0.666667   \n",
       "1978                        1.0                        1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_mean  \n",
       "20                        1.000000  \n",
       "21                        1.000000  \n",
       "22                        1.000000  \n",
       "23                        1.000000  \n",
       "24                        0.000000  \n",
       "...                            ...  \n",
       "1973                      0.666667  \n",
       "1974                      0.666667  \n",
       "1975                      0.333333  \n",
       "1977                      0.666667  \n",
       "1978                      1.000000  \n",
       "\n",
       "[1730 rows x 108 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train1 = X_train[list(fearues_names1)]\n",
    "new_X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_ScoredAv</th>\n",
       "      <th>agent_1_feat_MissedAv</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_Long key passes</th>\n",
       "      <th>agent_1_feat_scored_mean_3</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feat_both_scored_mean</th>\n",
       "      <th>agent_2_feattotal_scored_1</th>\n",
       "      <th>agent_2_feattotal_scored_mean</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>6.65</td>\n",
       "      <td>1.041381</td>\n",
       "      <td>0.865284</td>\n",
       "      <td>7.55</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.526316</td>\n",
       "      <td>0.960263</td>\n",
       "      <td>1.763947</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.971957</td>\n",
       "      <td>1.971957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>6.68</td>\n",
       "      <td>0.819214</td>\n",
       "      <td>1.137980</td>\n",
       "      <td>10.38</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>1.473684</td>\n",
       "      <td>1.413421</td>\n",
       "      <td>1.295000</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.768830</td>\n",
       "      <td>3.679915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>6.62</td>\n",
       "      <td>0.909293</td>\n",
       "      <td>0.935754</td>\n",
       "      <td>7.89</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>1.763158</td>\n",
       "      <td>1.186579</td>\n",
       "      <td>1.884211</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.454633</td>\n",
       "      <td>2.972359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>6.60</td>\n",
       "      <td>0.895456</td>\n",
       "      <td>1.027018</td>\n",
       "      <td>9.15</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.710526</td>\n",
       "      <td>1.175526</td>\n",
       "      <td>1.665526</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.028539</td>\n",
       "      <td>3.040646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>6.86</td>\n",
       "      <td>0.905155</td>\n",
       "      <td>1.314188</td>\n",
       "      <td>14.66</td>\n",
       "      <td>1.815789</td>\n",
       "      <td>1.421053</td>\n",
       "      <td>2.006053</td>\n",
       "      <td>1.081316</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.291982</td>\n",
       "      <td>2.473024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.032989</td>\n",
       "      <td>8.27</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.156842</td>\n",
       "      <td>1.579474</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>4.024907</td>\n",
       "      <td>3.872622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.066236</td>\n",
       "      <td>7.60</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>1.736842</td>\n",
       "      <td>0.928684</td>\n",
       "      <td>1.628947</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>2.000313</td>\n",
       "      <td>2.572016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.026472</td>\n",
       "      <td>7.99</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.920263</td>\n",
       "      <td>1.948421</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.496854</td>\n",
       "      <td>2.555157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.161401</td>\n",
       "      <td>10.47</td>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>1.191579</td>\n",
       "      <td>1.540789</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>2.977092</td>\n",
       "      <td>2.495116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>9.72</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>1.447368</td>\n",
       "      <td>1.003421</td>\n",
       "      <td>1.554211</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.414186</td>\n",
       "      <td>2.861741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "1979                 6.65               1.041381                0.865284   \n",
       "1980                 6.68               0.819214                1.137980   \n",
       "1981                 6.62               0.909293                0.935754   \n",
       "1982                 6.60               0.895456                1.027018   \n",
       "1983                 6.86               0.905155                1.314188   \n",
       "...                   ...                    ...                     ...   \n",
       "2465                 6.62               1.046406                1.032989   \n",
       "2466                 6.61               1.161802                1.066236   \n",
       "2467                 6.51               1.000858                1.026472   \n",
       "2468                 6.62               1.037986                1.161401   \n",
       "2469                 6.64               0.865460                0.931256   \n",
       "\n",
       "      agent_1_feat_OPPDA  agent_1_feat_ScoredAv  agent_1_feat_MissedAv  \\\n",
       "1979                7.55               1.000000               1.526316   \n",
       "1980               10.38               1.157895               1.473684   \n",
       "1981                7.89               1.078947               1.763158   \n",
       "1982                9.15               1.052632               1.710526   \n",
       "1983               14.66               1.815789               1.421053   \n",
       "...                  ...                    ...                    ...   \n",
       "2465                8.27               1.210526               1.631579   \n",
       "2466                7.60               1.078947               1.736842   \n",
       "2467                7.99               0.921053               2.000000   \n",
       "2468               10.47               1.236842               1.789474   \n",
       "2469                9.72               0.868421               1.447368   \n",
       "\n",
       "      agent_1_feat_XgAv  agent_1_feat_XgaAv  agent_1_feat_Long key passes  \\\n",
       "1979           0.960263            1.763947                           1.7   \n",
       "1980           1.413421            1.295000                           1.7   \n",
       "1981           1.186579            1.884211                           1.8   \n",
       "1982           1.175526            1.665526                           1.5   \n",
       "1983           2.006053            1.081316                           2.2   \n",
       "...                 ...                 ...                           ...   \n",
       "2465           1.156842            1.579474                           1.8   \n",
       "2466           0.928684            1.628947                           1.1   \n",
       "2467           0.920263            1.948421                           1.1   \n",
       "2468           1.191579            1.540789                           1.1   \n",
       "2469           1.003421            1.554211                           2.0   \n",
       "\n",
       "      agent_1_feat_scored_mean_3  ...  agent_2_feat_both_scored_mean  \\\n",
       "1979                    0.333333  ...                       0.571429   \n",
       "1980                    0.333333  ...                       0.500000   \n",
       "1981                    3.000000  ...                       0.250000   \n",
       "1982                    1.666667  ...                       0.625000   \n",
       "1983                    2.333333  ...                       0.375000   \n",
       "...                          ...  ...                            ...   \n",
       "2465                    0.000000  ...                       0.500000   \n",
       "2466                    0.666667  ...                       0.526316   \n",
       "2467                    1.333333  ...                       0.388889   \n",
       "2468                    0.333333  ...                       0.368421   \n",
       "2469                    0.333333  ...                       0.352941   \n",
       "\n",
       "      agent_2_feattotal_scored_1  agent_2_feattotal_scored_mean  \\\n",
       "1979                         2.0                       2.000000   \n",
       "1980                         4.0                       2.500000   \n",
       "1981                         2.0                       2.250000   \n",
       "1982                         2.0                       2.750000   \n",
       "1983                         5.0                       3.500000   \n",
       "...                          ...                            ...   \n",
       "2465                         3.0                       4.111111   \n",
       "2466                         1.0                       2.555556   \n",
       "2467                         4.0                       2.000000   \n",
       "2468                         4.0                       2.111111   \n",
       "2469                         2.0                       2.333333   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "1979                     1.971957                   1.971957   \n",
       "1980                     3.768830                   3.679915   \n",
       "1981                     3.454633                   2.972359   \n",
       "1982                     3.028539                   3.040646   \n",
       "1983                     2.291982                   2.473024   \n",
       "...                           ...                        ...   \n",
       "2465                     4.024907                   3.872622   \n",
       "2466                     2.000313                   2.572016   \n",
       "2467                     2.496854                   2.555157   \n",
       "2468                     2.977092                   2.495116   \n",
       "2469                     3.414186                   2.861741   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "1979                        1.0                        1.0   \n",
       "1980                        1.0                        0.0   \n",
       "1981                        0.0                        0.0   \n",
       "1982                        0.0                        0.0   \n",
       "1983                        0.0                        1.0   \n",
       "...                         ...                        ...   \n",
       "2465                        1.0                        0.0   \n",
       "2466                        0.0                        0.0   \n",
       "2467                        0.0                        0.0   \n",
       "2468                        1.0                        0.0   \n",
       "2469                        1.0                        1.0   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "1979                        0.0                        0.666667   \n",
       "1980                        1.0                        0.666667   \n",
       "1981                        0.0                        0.000000   \n",
       "1982                        0.0                        0.000000   \n",
       "1983                        0.0                        0.333333   \n",
       "...                         ...                             ...   \n",
       "2465                        0.0                        0.333333   \n",
       "2466                        0.0                        0.000000   \n",
       "2467                        1.0                        0.333333   \n",
       "2468                        0.0                        0.333333   \n",
       "2469                        0.0                        0.666667   \n",
       "\n",
       "      agent_2_featboth_scored_mean  \n",
       "1979                      0.666667  \n",
       "1980                      0.750000  \n",
       "1981                      0.000000  \n",
       "1982                      0.250000  \n",
       "1983                      0.500000  \n",
       "...                            ...  \n",
       "2465                      0.444444  \n",
       "2466                      0.444444  \n",
       "2467                      0.500000  \n",
       "2468                      0.222222  \n",
       "2469                      0.333333  \n",
       "\n",
       "[433 rows x 108 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_test1 = X_test[list(fearues_names1)]\n",
    "new_X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_ScoredAv</th>\n",
       "      <th>agent_1_feat_MissedAv</th>\n",
       "      <th>agent_1_feat_XgAv</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_1_feat_Long key passes</th>\n",
       "      <th>agent_1_feat_scored_mean_3</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feat_both_scored_mean</th>\n",
       "      <th>agent_2_feattotal_scored_1</th>\n",
       "      <th>agent_2_feattotal_scored_mean</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.83</td>\n",
       "      <td>0.844742</td>\n",
       "      <td>1.165049</td>\n",
       "      <td>16.50</td>\n",
       "      <td>1.526316</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.806842</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>2.932115</td>\n",
       "      <td>2.690442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.65</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>1.152593</td>\n",
       "      <td>13.63</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.210526</td>\n",
       "      <td>1.416316</td>\n",
       "      <td>1.050263</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.373811</td>\n",
       "      <td>3.075302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.73</td>\n",
       "      <td>0.954509</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>11.82</td>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.295789</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>1.900995</td>\n",
       "      <td>3.007033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.85</td>\n",
       "      <td>1.155612</td>\n",
       "      <td>1.049618</td>\n",
       "      <td>12.46</td>\n",
       "      <td>1.921053</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>1.662368</td>\n",
       "      <td>1.103158</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.108852</td>\n",
       "      <td>2.643923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.81</td>\n",
       "      <td>1.199718</td>\n",
       "      <td>0.856327</td>\n",
       "      <td>11.52</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>1.491579</td>\n",
       "      <td>1.382895</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>2.456406</td>\n",
       "      <td>3.113815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>6.72</td>\n",
       "      <td>0.814332</td>\n",
       "      <td>1.292407</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.228000</td>\n",
       "      <td>1.238000</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.277778</td>\n",
       "      <td>3.570381</td>\n",
       "      <td>3.240205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>6.69</td>\n",
       "      <td>1.186944</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>14.67</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>3.645599</td>\n",
       "      <td>3.315186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>7.05</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.257069</td>\n",
       "      <td>22.23</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.736000</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>2.372236</td>\n",
       "      <td>2.343328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.11</td>\n",
       "      <td>0.846805</td>\n",
       "      <td>0.401606</td>\n",
       "      <td>26.84</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.598000</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.388889</td>\n",
       "      <td>2.495249</td>\n",
       "      <td>2.364201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>6.42</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1.319510</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>2.122000</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.611111</td>\n",
       "      <td>2.111504</td>\n",
       "      <td>2.811747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                   6.83               0.844742                1.165049   \n",
       "1                   6.65               0.743218                1.152593   \n",
       "2                   6.73               0.954509                0.956938   \n",
       "3                   6.85               1.155612                1.049618   \n",
       "4                   6.81               1.199718                0.856327   \n",
       "..                   ...                    ...                     ...   \n",
       "565                 6.72               0.814332                1.292407   \n",
       "566                 6.69               1.186944                0.769231   \n",
       "567                 7.05               0.877193                0.257069   \n",
       "568                 7.11               0.846805                0.401606   \n",
       "569                 6.42               0.480769                1.319510   \n",
       "\n",
       "     agent_1_feat_OPPDA  agent_1_feat_ScoredAv  agent_1_feat_MissedAv  \\\n",
       "0                 16.50               1.526316               0.947368   \n",
       "1                 13.63               1.052632               1.210526   \n",
       "2                 11.82               1.236842               1.263158   \n",
       "3                 12.46               1.921053               1.157895   \n",
       "4                 11.52               1.789474               1.184211   \n",
       "..                  ...                    ...                    ...   \n",
       "565                8.32               1.000000               1.600000   \n",
       "566               14.67               1.000000               1.500000   \n",
       "567               22.23               2.400000               0.200000   \n",
       "568               26.84               2.200000               0.200000   \n",
       "569                9.95               0.400000               2.800000   \n",
       "\n",
       "     agent_1_feat_XgAv  agent_1_feat_XgaAv  agent_1_feat_Long key passes  \\\n",
       "0             1.806842            0.813158                           2.5   \n",
       "1             1.416316            1.050263                           1.4   \n",
       "2             1.295789            1.320000                           1.6   \n",
       "3             1.662368            1.103158                           2.0   \n",
       "4             1.491579            1.382895                           1.4   \n",
       "..                 ...                 ...                           ...   \n",
       "565           1.228000            1.238000                           1.3   \n",
       "566           0.842500            1.950000                           0.9   \n",
       "567           2.736000            0.778000                           2.7   \n",
       "568           2.598000            0.498000                           1.9   \n",
       "569           0.832000            2.122000                           1.1   \n",
       "\n",
       "     agent_1_feat_scored_mean_3  ...  agent_2_feat_both_scored_mean  \\\n",
       "0                      0.666667  ...                       0.526316   \n",
       "1                      1.333333  ...                       0.500000   \n",
       "2                      1.000000  ...                       0.421053   \n",
       "3                      1.000000  ...                       0.421053   \n",
       "4                      2.333333  ...                       0.578947   \n",
       "..                          ...  ...                            ...   \n",
       "565                    1.333333  ...                       0.594595   \n",
       "566                    3.000000  ...                       0.594595   \n",
       "567                    1.666667  ...                       0.351351   \n",
       "568                    4.000000  ...                       0.513514   \n",
       "569                    0.333333  ...                       0.378378   \n",
       "\n",
       "     agent_2_feattotal_scored_1  agent_2_feattotal_scored_mean  \\\n",
       "0                           6.0                       2.777778   \n",
       "1                           2.0                       2.500000   \n",
       "2                           3.0                       3.222222   \n",
       "3                           2.0                       2.333333   \n",
       "4                           1.0                       3.222222   \n",
       "..                          ...                            ...   \n",
       "565                         4.0                       3.277778   \n",
       "566                         3.0                       3.222222   \n",
       "567                         4.0                       1.777778   \n",
       "568                         4.0                       2.388889   \n",
       "569                         2.0                       2.611111   \n",
       "\n",
       "     agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "0                       2.932115                   2.690442   \n",
       "1                       3.373811                   3.075302   \n",
       "2                       1.900995                   3.007033   \n",
       "3                       2.108852                   2.643923   \n",
       "4                       2.456406                   3.113815   \n",
       "..                           ...                        ...   \n",
       "565                     3.570381                   3.240205   \n",
       "566                     3.645599                   3.315186   \n",
       "567                     2.372236                   2.343328   \n",
       "568                     2.495249                   2.364201   \n",
       "569                     2.111504                   2.811747   \n",
       "\n",
       "     agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "0                          1.0                        0.0   \n",
       "1                          0.0                        1.0   \n",
       "2                          0.0                        1.0   \n",
       "3                          1.0                        0.0   \n",
       "4                          0.0                        0.0   \n",
       "..                         ...                        ...   \n",
       "565                        0.0                        1.0   \n",
       "566                        0.0                        1.0   \n",
       "567                        0.0                        0.0   \n",
       "568                        1.0                        0.0   \n",
       "569                        0.0                        0.0   \n",
       "\n",
       "     agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "0                          1.0                        0.666667   \n",
       "1                          1.0                        0.666667   \n",
       "2                          1.0                        0.666667   \n",
       "3                          0.0                        0.333333   \n",
       "4                          0.0                        0.000000   \n",
       "..                         ...                             ...   \n",
       "565                        0.0                        0.333333   \n",
       "566                        0.0                        0.333333   \n",
       "567                        1.0                        0.333333   \n",
       "568                        1.0                        0.666667   \n",
       "569                        1.0                        0.333333   \n",
       "\n",
       "     agent_2_featboth_scored_mean  \n",
       "0                        0.333333  \n",
       "1                        0.625000  \n",
       "2                        0.555556  \n",
       "3                        0.444444  \n",
       "4                        0.555556  \n",
       "..                            ...  \n",
       "565                      0.666667  \n",
       "566                      0.611111  \n",
       "567                      0.277778  \n",
       "568                      0.444444  \n",
       "569                      0.388889  \n",
       "\n",
       "[570 rows x 108 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df1 = test_df[list(fearues_names1)]\n",
    "new_test_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train1, new_X_test1, new_test_df1 = scale_data(new_X_train1, new_X_test1, new_test_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1730, 9) (433, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train1 = pd.get_dummies(y_train1)\n",
    "y_test1 = pd.get_dummies(y_test1)\n",
    "y_train1, y_test1 = make_equal_dummies(y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_results1 = grid_search(new_X_train1, y_train1, 'expected_target1')\n",
    "# batch_size1 = grid_results1.best_params_['batch_size']\n",
    "# epochs1 = grid_results1.best_params_['epochs']\n",
    "# learning_rate1 = grid_results1.best_params_['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size1 = 32\n",
    "epochs1 = 100\n",
    "learning_rate1 = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 2s 7ms/step - loss: 2.8651 - accuracy: 0.1069 - val_loss: 2.1774 - val_accuracy: 0.0716\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.8626 - accuracy: 0.1116 - val_loss: 2.1961 - val_accuracy: 0.0878\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.8166 - accuracy: 0.1064 - val_loss: 2.2256 - val_accuracy: 0.1016\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.7695 - accuracy: 0.1110 - val_loss: 2.2409 - val_accuracy: 0.1109\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.7353 - accuracy: 0.1168 - val_loss: 2.2428 - val_accuracy: 0.1293\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.7186 - accuracy: 0.1191 - val_loss: 2.2563 - val_accuracy: 0.1386\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.6364 - accuracy: 0.1266 - val_loss: 2.2546 - val_accuracy: 0.1432\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.6482 - accuracy: 0.1318 - val_loss: 2.2469 - val_accuracy: 0.1594\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.5751 - accuracy: 0.1422 - val_loss: 2.2344 - val_accuracy: 0.1640\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.5429 - accuracy: 0.1457 - val_loss: 2.2345 - val_accuracy: 0.1778\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.5718 - accuracy: 0.1150 - val_loss: 2.2084 - val_accuracy: 0.1940\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4582 - accuracy: 0.1659 - val_loss: 2.1798 - val_accuracy: 0.2055\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4828 - accuracy: 0.1491 - val_loss: 2.1613 - val_accuracy: 0.2055\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4587 - accuracy: 0.1671 - val_loss: 2.1391 - val_accuracy: 0.2079\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4042 - accuracy: 0.1694 - val_loss: 2.1164 - val_accuracy: 0.2102\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4406 - accuracy: 0.1659 - val_loss: 2.0886 - val_accuracy: 0.2102\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3972 - accuracy: 0.1711 - val_loss: 2.0745 - val_accuracy: 0.2217\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3226 - accuracy: 0.1705 - val_loss: 2.0651 - val_accuracy: 0.2286\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3416 - accuracy: 0.1769 - val_loss: 2.0541 - val_accuracy: 0.2309\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3205 - accuracy: 0.1855 - val_loss: 2.0866 - val_accuracy: 0.2217\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3472 - accuracy: 0.1792 - val_loss: 2.0908 - val_accuracy: 0.1963\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2924 - accuracy: 0.1780 - val_loss: 2.0317 - val_accuracy: 0.2009\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3066 - accuracy: 0.1798 - val_loss: 2.0059 - val_accuracy: 0.2379\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2854 - accuracy: 0.1879 - val_loss: 1.9790 - val_accuracy: 0.2356\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2532 - accuracy: 0.1867 - val_loss: 1.9638 - val_accuracy: 0.2309\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2162 - accuracy: 0.2012 - val_loss: 1.9502 - val_accuracy: 0.2356\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2106 - accuracy: 0.1908 - val_loss: 1.9370 - val_accuracy: 0.2471\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1902 - accuracy: 0.2046 - val_loss: 1.9223 - val_accuracy: 0.2517\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1940 - accuracy: 0.1954 - val_loss: 1.9145 - val_accuracy: 0.2564\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1684 - accuracy: 0.2220 - val_loss: 1.9028 - val_accuracy: 0.2564\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1457 - accuracy: 0.2220 - val_loss: 1.9035 - val_accuracy: 0.2748\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1456 - accuracy: 0.2220 - val_loss: 1.9462 - val_accuracy: 0.2540\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 2.1554 - accuracy: 0.2121 - val_loss: 1.9098 - val_accuracy: 0.2309\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 2.1420 - accuracy: 0.2127 - val_loss: 1.8913 - val_accuracy: 0.2517\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0948 - accuracy: 0.2451 - val_loss: 1.8737 - val_accuracy: 0.2610\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0772 - accuracy: 0.2439 - val_loss: 1.8663 - val_accuracy: 0.2771\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1006 - accuracy: 0.2220 - val_loss: 1.8541 - val_accuracy: 0.2794\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0716 - accuracy: 0.2358 - val_loss: 1.8385 - val_accuracy: 0.2725\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0935 - accuracy: 0.2283 - val_loss: 1.8291 - val_accuracy: 0.2679\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0530 - accuracy: 0.2249 - val_loss: 1.8230 - val_accuracy: 0.2725\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0476 - accuracy: 0.2289 - val_loss: 1.8226 - val_accuracy: 0.2818\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0414 - accuracy: 0.2486 - val_loss: 1.8137 - val_accuracy: 0.2887\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0210 - accuracy: 0.2405 - val_loss: 1.8078 - val_accuracy: 0.2979\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0198 - accuracy: 0.2301 - val_loss: 1.7987 - val_accuracy: 0.2794\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0131 - accuracy: 0.2439 - val_loss: 1.7941 - val_accuracy: 0.2841\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0035 - accuracy: 0.2451 - val_loss: 1.7933 - val_accuracy: 0.2771\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9686 - accuracy: 0.2584 - val_loss: 1.7856 - val_accuracy: 0.2818\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9831 - accuracy: 0.2532 - val_loss: 1.7809 - val_accuracy: 0.2887\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9633 - accuracy: 0.2572 - val_loss: 1.7761 - val_accuracy: 0.2887\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.9746 - accuracy: 0.2382 - val_loss: 1.7702 - val_accuracy: 0.2841\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9539 - accuracy: 0.2630 - val_loss: 1.7623 - val_accuracy: 0.2910\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9302 - accuracy: 0.2607 - val_loss: 1.7348 - val_accuracy: 0.2818\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9437 - accuracy: 0.2740 - val_loss: 1.7083 - val_accuracy: 0.3464\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9265 - accuracy: 0.2647 - val_loss: 1.7135 - val_accuracy: 0.3418\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9135 - accuracy: 0.2728 - val_loss: 1.7100 - val_accuracy: 0.3349\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9182 - accuracy: 0.2699 - val_loss: 1.7065 - val_accuracy: 0.3164\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9224 - accuracy: 0.2572 - val_loss: 1.7129 - val_accuracy: 0.3372\n",
      "Epoch 58/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9065 - accuracy: 0.2786 - val_loss: 1.7358 - val_accuracy: 0.2956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9072 - accuracy: 0.2740 - val_loss: 1.7288 - val_accuracy: 0.3279\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9110 - accuracy: 0.2717 - val_loss: 1.7341 - val_accuracy: 0.3233\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8924 - accuracy: 0.2682 - val_loss: 1.7190 - val_accuracy: 0.3256\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9007 - accuracy: 0.2665 - val_loss: 1.7133 - val_accuracy: 0.3141\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8947 - accuracy: 0.2532 - val_loss: 1.7078 - val_accuracy: 0.3256\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9039 - accuracy: 0.2757 - val_loss: 1.7040 - val_accuracy: 0.3233\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8673 - accuracy: 0.2723 - val_loss: 1.7088 - val_accuracy: 0.3210\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8952 - accuracy: 0.2653 - val_loss: 1.7063 - val_accuracy: 0.3187\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8550 - accuracy: 0.2936 - val_loss: 1.7038 - val_accuracy: 0.3164\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8599 - accuracy: 0.2717 - val_loss: 1.7033 - val_accuracy: 0.3256\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8576 - accuracy: 0.2775 - val_loss: 1.7013 - val_accuracy: 0.3187\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8669 - accuracy: 0.2723 - val_loss: 1.6975 - val_accuracy: 0.3210\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8486 - accuracy: 0.2763 - val_loss: 1.6900 - val_accuracy: 0.3164\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8243 - accuracy: 0.2653 - val_loss: 1.6947 - val_accuracy: 0.3048\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8362 - accuracy: 0.2896 - val_loss: 1.6876 - val_accuracy: 0.3118\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8555 - accuracy: 0.2671 - val_loss: 1.6825 - val_accuracy: 0.3141\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8247 - accuracy: 0.2890 - val_loss: 1.6815 - val_accuracy: 0.3072\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8311 - accuracy: 0.2775 - val_loss: 1.6819 - val_accuracy: 0.3095\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8096 - accuracy: 0.2954 - val_loss: 1.6802 - val_accuracy: 0.3048\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8079 - accuracy: 0.2861 - val_loss: 1.6792 - val_accuracy: 0.3118\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7965 - accuracy: 0.2948 - val_loss: 1.6779 - val_accuracy: 0.3095\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8070 - accuracy: 0.2809 - val_loss: 1.6719 - val_accuracy: 0.3141\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7997 - accuracy: 0.2832 - val_loss: 1.6670 - val_accuracy: 0.3141\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7957 - accuracy: 0.2855 - val_loss: 1.6626 - val_accuracy: 0.3141\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7941 - accuracy: 0.2775 - val_loss: 1.6593 - val_accuracy: 0.3095\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7990 - accuracy: 0.2717 - val_loss: 1.6557 - val_accuracy: 0.3187\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7880 - accuracy: 0.2971 - val_loss: 1.6549 - val_accuracy: 0.3141\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7689 - accuracy: 0.3098 - val_loss: 1.6550 - val_accuracy: 0.3072\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7854 - accuracy: 0.2884 - val_loss: 1.6503 - val_accuracy: 0.3141\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7830 - accuracy: 0.3012 - val_loss: 1.6489 - val_accuracy: 0.3141\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7641 - accuracy: 0.3035 - val_loss: 1.6422 - val_accuracy: 0.3256\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7878 - accuracy: 0.2919 - val_loss: 1.6368 - val_accuracy: 0.3303\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7483 - accuracy: 0.3040 - val_loss: 1.6424 - val_accuracy: 0.3210\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7711 - accuracy: 0.2890 - val_loss: 1.6407 - val_accuracy: 0.3326\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7585 - accuracy: 0.2838 - val_loss: 1.6405 - val_accuracy: 0.3303\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7536 - accuracy: 0.3035 - val_loss: 1.6384 - val_accuracy: 0.3210\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.7611 - accuracy: 0.3052 - val_loss: 1.6362 - val_accuracy: 0.3210\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7467 - accuracy: 0.2827 - val_loss: 1.6321 - val_accuracy: 0.3326\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7675 - accuracy: 0.2803 - val_loss: 1.6319 - val_accuracy: 0.3418\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7432 - accuracy: 0.3040 - val_loss: 1.6323 - val_accuracy: 0.3326\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7437 - accuracy: 0.2896 - val_loss: 1.6369 - val_accuracy: 0.3187\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7690 - accuracy: 0.2873 - val_loss: 1.6291 - val_accuracy: 0.3210\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_df['expected_target1'].nunique()\n",
    "model1 = create_model(batch_size1, epochs1, learning_rate1, num_classes, new_X_train1.shape[1])\n",
    "history1 = model1.fit(new_X_train1, y_train1, \n",
    "                      batch_size = batch_size1, \n",
    "                      epochs = epochs1,\n",
    "                      validation_data = (new_X_test1, y_test1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_graphs(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.714\n"
     ]
    }
   ],
   "source": [
    "tmp_pred_value1 = calc_train_acc(model1, 'expected_target1', Y_expected1, new_X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for agent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fearues_names2 = feature_selection(X_train, y_train2, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_2_feat_XGrealiz</th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_missed_3</th>\n",
       "      <th>agent_2_feat_pl_mean</th>\n",
       "      <th>agent_1_feat_scheme_1</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feat_scheme_10</th>\n",
       "      <th>agent_2_feat_scheme_12</th>\n",
       "      <th>agent_2_feat_scheme_13</th>\n",
       "      <th>agent_2_feat_scheme_14</th>\n",
       "      <th>agent_2_feat_scheme_15</th>\n",
       "      <th>agent_2_feat_scheme_16</th>\n",
       "      <th>agent_2_feat_scheme_18</th>\n",
       "      <th>agent_2_feat_scheme_19</th>\n",
       "      <th>agent_1_feat_both_scored_mean</th>\n",
       "      <th>agent_2_feat_both_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.79</td>\n",
       "      <td>0.711201</td>\n",
       "      <td>1.523421</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.048421</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>80.272727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.07</td>\n",
       "      <td>1.094698</td>\n",
       "      <td>1.065789</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.237632</td>\n",
       "      <td>1.184211</td>\n",
       "      <td>76.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.74</td>\n",
       "      <td>0.994530</td>\n",
       "      <td>1.342368</td>\n",
       "      <td>6.83</td>\n",
       "      <td>1.050045</td>\n",
       "      <td>1.236842</td>\n",
       "      <td>1.196842</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>74.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.717368</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.827770</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>1.354211</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>75.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.86</td>\n",
       "      <td>1.124694</td>\n",
       "      <td>1.472105</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.414474</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>73.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>6.52</td>\n",
       "      <td>0.698362</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>6.62</td>\n",
       "      <td>0.909293</td>\n",
       "      <td>1.078947</td>\n",
       "      <td>1.884211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>6.59</td>\n",
       "      <td>0.741351</td>\n",
       "      <td>1.566579</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.851343</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.369474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>6.72</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>1.797895</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.899855</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>1.510263</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>76.272727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>6.71</td>\n",
       "      <td>0.902655</td>\n",
       "      <td>1.489211</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.905155</td>\n",
       "      <td>1.815789</td>\n",
       "      <td>1.081316</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>6.71</td>\n",
       "      <td>1.101928</td>\n",
       "      <td>1.506579</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.895456</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.665526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1730 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XgaAv  \\\n",
       "20                   6.79               0.711201            1.523421   \n",
       "21                   7.07               1.094698            1.065789   \n",
       "22                   6.74               0.994530            1.342368   \n",
       "23                   6.77               0.918434            1.717368   \n",
       "24                   6.86               1.124694            1.472105   \n",
       "...                   ...                    ...                 ...   \n",
       "1973                 6.52               0.698362            1.884474   \n",
       "1974                 6.59               0.741351            1.566579   \n",
       "1975                 6.72               0.998573            1.797895   \n",
       "1977                 6.71               0.902655            1.489211   \n",
       "1978                 6.71               1.101928            1.506579   \n",
       "\n",
       "      agent_2_feat_Rating  agent_2_feat_XGrealiz  agent_2_feat_ScoredAv  \\\n",
       "20                   6.99               1.143700               1.631579   \n",
       "21                   6.87               1.037613               1.263158   \n",
       "22                   6.83               1.050045               1.236842   \n",
       "23                   6.75               0.827770               0.815789   \n",
       "24                   6.77               0.983691               1.000000   \n",
       "...                   ...                    ...                    ...   \n",
       "1973                 6.62               0.909293               1.078947   \n",
       "1974                 6.72               0.851343               1.026316   \n",
       "1975                 6.68               0.899855               0.815789   \n",
       "1977                 6.86               0.905155               1.815789   \n",
       "1978                 6.60               0.895456               1.052632   \n",
       "\n",
       "      agent_2_feat_XgaAv  agent_2_feat_missed_3  agent_2_feat_pl_mean  \\\n",
       "20              1.048421               0.973684             80.272727   \n",
       "21              1.237632               1.184211             76.090909   \n",
       "22              1.196842               1.342105             74.727273   \n",
       "23              1.354211               1.394737             75.090909   \n",
       "24              1.414474               1.342105             73.818182   \n",
       "...                  ...                    ...                   ...   \n",
       "1973            1.884211               0.000000             75.727273   \n",
       "1974            1.369474               1.000000             72.818182   \n",
       "1975            1.510263               4.000000             76.272727   \n",
       "1977            1.081316               2.000000             80.000000   \n",
       "1978            1.665526               1.000000             75.181818   \n",
       "\n",
       "      agent_1_feat_scheme_1  ...  agent_2_feat_scheme_10  \\\n",
       "20                      1.0  ...                     0.0   \n",
       "21                      0.0  ...                     0.0   \n",
       "22                      0.0  ...                     0.0   \n",
       "23                      0.0  ...                     0.0   \n",
       "24                      0.0  ...                     0.0   \n",
       "...                     ...  ...                     ...   \n",
       "1973                    0.0  ...                     0.0   \n",
       "1974                    0.0  ...                     0.0   \n",
       "1975                    0.0  ...                     0.0   \n",
       "1977                    0.0  ...                     0.0   \n",
       "1978                    0.0  ...                     0.0   \n",
       "\n",
       "      agent_2_feat_scheme_12  agent_2_feat_scheme_13  agent_2_feat_scheme_14  \\\n",
       "20                       0.0                     1.0                     0.0   \n",
       "21                       0.0                     0.0                     0.0   \n",
       "22                       0.0                     0.0                     0.0   \n",
       "23                       0.0                     0.0                     0.0   \n",
       "24                       0.0                     0.0                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "1973                     0.0                     0.0                     0.0   \n",
       "1974                     0.0                     0.0                     0.0   \n",
       "1975                     1.0                     0.0                     0.0   \n",
       "1977                     0.0                     0.0                     0.0   \n",
       "1978                     0.0                     0.0                     0.0   \n",
       "\n",
       "      agent_2_feat_scheme_15  agent_2_feat_scheme_16  agent_2_feat_scheme_18  \\\n",
       "20                       0.0                     0.0                     0.0   \n",
       "21                       0.0                     0.0                     0.0   \n",
       "22                       0.0                     0.0                     0.0   \n",
       "23                       0.0                     0.0                     0.0   \n",
       "24                       0.0                     0.0                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "1973                     0.0                     0.0                     0.0   \n",
       "1974                     0.0                     0.0                     0.0   \n",
       "1975                     0.0                     0.0                     0.0   \n",
       "1977                     0.0                     0.0                     0.0   \n",
       "1978                     0.0                     0.0                     0.0   \n",
       "\n",
       "      agent_2_feat_scheme_19  agent_1_feat_both_scored_mean  \\\n",
       "20                       0.0                       0.500000   \n",
       "21                       0.0                       0.500000   \n",
       "22                       0.0                       0.000000   \n",
       "23                       0.0                       0.000000   \n",
       "24                       0.0                       0.500000   \n",
       "...                      ...                            ...   \n",
       "1973                     0.0                       0.571429   \n",
       "1974                     0.0                       0.428571   \n",
       "1975                     0.0                       0.428571   \n",
       "1977                     0.0                       0.571429   \n",
       "1978                     0.0                       0.857143   \n",
       "\n",
       "      agent_2_feat_both_scored_mean  \n",
       "20                         1.000000  \n",
       "21                         0.500000  \n",
       "22                         1.000000  \n",
       "23                         1.000000  \n",
       "24                         0.500000  \n",
       "...                             ...  \n",
       "1973                       0.571429  \n",
       "1974                       0.428571  \n",
       "1975                       0.285714  \n",
       "1977                       0.714286  \n",
       "1978                       1.000000  \n",
       "\n",
       "[1730 rows x 38 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train2 = X_train[list(fearues_names2)]\n",
    "new_X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_2_feat_XGrealiz</th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_missed_3</th>\n",
       "      <th>agent_2_feat_pl_mean</th>\n",
       "      <th>agent_1_feat_scheme_1</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feat_scheme_10</th>\n",
       "      <th>agent_2_feat_scheme_12</th>\n",
       "      <th>agent_2_feat_scheme_13</th>\n",
       "      <th>agent_2_feat_scheme_14</th>\n",
       "      <th>agent_2_feat_scheme_15</th>\n",
       "      <th>agent_2_feat_scheme_16</th>\n",
       "      <th>agent_2_feat_scheme_18</th>\n",
       "      <th>agent_2_feat_scheme_19</th>\n",
       "      <th>agent_1_feat_both_scored_mean</th>\n",
       "      <th>agent_2_feat_both_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>6.65</td>\n",
       "      <td>1.041381</td>\n",
       "      <td>1.763947</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.997129</td>\n",
       "      <td>1.736842</td>\n",
       "      <td>1.001579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>6.68</td>\n",
       "      <td>0.819214</td>\n",
       "      <td>1.295000</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.998573</td>\n",
       "      <td>1.289474</td>\n",
       "      <td>1.797895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>6.62</td>\n",
       "      <td>0.909293</td>\n",
       "      <td>1.884211</td>\n",
       "      <td>6.63</td>\n",
       "      <td>0.822438</td>\n",
       "      <td>1.026316</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>6.60</td>\n",
       "      <td>0.895456</td>\n",
       "      <td>1.665526</td>\n",
       "      <td>6.52</td>\n",
       "      <td>0.698362</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.884474</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.818182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>6.86</td>\n",
       "      <td>0.905155</td>\n",
       "      <td>1.081316</td>\n",
       "      <td>6.65</td>\n",
       "      <td>1.041381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.763947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.579474</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.046237</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.658421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.628947</td>\n",
       "      <td>6.77</td>\n",
       "      <td>1.027511</td>\n",
       "      <td>1.631579</td>\n",
       "      <td>1.312105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.948421</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.067936</td>\n",
       "      <td>2.184211</td>\n",
       "      <td>0.805526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.545455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.540789</td>\n",
       "      <td>6.69</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>1.447368</td>\n",
       "      <td>1.137632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>1.554211</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.969676</td>\n",
       "      <td>1.447368</td>\n",
       "      <td>1.401316</td>\n",
       "      <td>2.0</td>\n",
       "      <td>76.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XgaAv  \\\n",
       "1979                 6.65               1.041381            1.763947   \n",
       "1980                 6.68               0.819214            1.295000   \n",
       "1981                 6.62               0.909293            1.884211   \n",
       "1982                 6.60               0.895456            1.665526   \n",
       "1983                 6.86               0.905155            1.081316   \n",
       "...                   ...                    ...                 ...   \n",
       "2465                 6.62               1.046406            1.579474   \n",
       "2466                 6.61               1.161802            1.628947   \n",
       "2467                 6.51               1.000858            1.948421   \n",
       "2468                 6.62               1.037986            1.540789   \n",
       "2469                 6.64               0.865460            1.554211   \n",
       "\n",
       "      agent_2_feat_Rating  agent_2_feat_XGrealiz  agent_2_feat_ScoredAv  \\\n",
       "1979                 6.83               0.997129               1.736842   \n",
       "1980                 6.72               0.998573               1.289474   \n",
       "1981                 6.63               0.822438               1.026316   \n",
       "1982                 6.52               0.698362               0.684211   \n",
       "1983                 6.65               1.041381               1.000000   \n",
       "...                   ...                    ...                    ...   \n",
       "2465                 6.77               1.046237               1.631579   \n",
       "2466                 6.77               1.027511               1.631579   \n",
       "2467                 7.01               1.067936               2.184211   \n",
       "2468                 6.69               1.052632               1.447368   \n",
       "2469                 6.84               0.969676               1.447368   \n",
       "\n",
       "      agent_2_feat_XgaAv  agent_2_feat_missed_3  agent_2_feat_pl_mean  \\\n",
       "1979            1.001579                    0.0             78.727273   \n",
       "1980            1.797895                    0.0             78.818182   \n",
       "1981            1.590000                    0.0             75.000000   \n",
       "1982            1.884474                    2.0             72.818182   \n",
       "1983            1.763947                    0.0             76.727273   \n",
       "...                  ...                    ...                   ...   \n",
       "2465            1.658421                    0.0             74.727273   \n",
       "2466            1.312105                    0.0             77.909091   \n",
       "2467            0.805526                    0.0             83.545455   \n",
       "2468            1.137632                    0.0             80.090909   \n",
       "2469            1.401316                    2.0             76.090909   \n",
       "\n",
       "      agent_1_feat_scheme_1  ...  agent_2_feat_scheme_10  \\\n",
       "1979                    0.0  ...                     0.0   \n",
       "1980                    0.0  ...                     0.0   \n",
       "1981                    0.0  ...                     0.0   \n",
       "1982                    1.0  ...                     0.0   \n",
       "1983                    0.0  ...                     0.0   \n",
       "...                     ...  ...                     ...   \n",
       "2465                    0.0  ...                     0.0   \n",
       "2466                    1.0  ...                     0.0   \n",
       "2467                    0.0  ...                     0.0   \n",
       "2468                    1.0  ...                     0.0   \n",
       "2469                    1.0  ...                     0.0   \n",
       "\n",
       "      agent_2_feat_scheme_12  agent_2_feat_scheme_13  agent_2_feat_scheme_14  \\\n",
       "1979                     0.0                     0.0                     0.0   \n",
       "1980                     0.0                     0.0                     0.0   \n",
       "1981                     0.0                     0.0                     0.0   \n",
       "1982                     0.0                     0.0                     0.0   \n",
       "1983                     0.0                     0.0                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "2465                     0.0                     0.0                     0.0   \n",
       "2466                     0.0                     0.0                     0.0   \n",
       "2467                     0.0                     0.0                     0.0   \n",
       "2468                     0.0                     0.0                     0.0   \n",
       "2469                     0.0                     0.0                     0.0   \n",
       "\n",
       "      agent_2_feat_scheme_15  agent_2_feat_scheme_16  agent_2_feat_scheme_18  \\\n",
       "1979                     0.0                     0.0                     0.0   \n",
       "1980                     0.0                     0.0                     0.0   \n",
       "1981                     0.0                     0.0                     0.0   \n",
       "1982                     0.0                     0.0                     0.0   \n",
       "1983                     0.0                     1.0                     0.0   \n",
       "...                      ...                     ...                     ...   \n",
       "2465                     0.0                     0.0                     0.0   \n",
       "2466                     0.0                     0.0                     0.0   \n",
       "2467                     0.0                     0.0                     0.0   \n",
       "2468                     0.0                     0.0                     0.0   \n",
       "2469                     0.0                     0.0                     0.0   \n",
       "\n",
       "      agent_2_feat_scheme_19  agent_1_feat_both_scored_mean  \\\n",
       "1979                     0.0                       0.428571   \n",
       "1980                     0.0                       0.375000   \n",
       "1981                     0.0                       0.625000   \n",
       "1982                     0.0                       0.875000   \n",
       "1983                     0.0                       0.750000   \n",
       "...                      ...                            ...   \n",
       "2465                     0.0                       0.473684   \n",
       "2466                     0.0                       0.473684   \n",
       "2467                     0.0                       0.473684   \n",
       "2468                     0.0                       0.388889   \n",
       "2469                     0.0                       0.222222   \n",
       "\n",
       "      agent_2_feat_both_scored_mean  \n",
       "1979                       0.571429  \n",
       "1980                       0.500000  \n",
       "1981                       0.250000  \n",
       "1982                       0.625000  \n",
       "1983                       0.375000  \n",
       "...                             ...  \n",
       "2465                       0.500000  \n",
       "2466                       0.526316  \n",
       "2467                       0.388889  \n",
       "2468                       0.368421  \n",
       "2469                       0.352941  \n",
       "\n",
       "[433 rows x 38 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_test2 = X_test[list(fearues_names2)]\n",
    "new_X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_Rating</th>\n",
       "      <th>agent_2_feat_XGrealiz</th>\n",
       "      <th>agent_2_feat_ScoredAv</th>\n",
       "      <th>agent_2_feat_XgaAv</th>\n",
       "      <th>agent_2_feat_missed_3</th>\n",
       "      <th>agent_2_feat_pl_mean</th>\n",
       "      <th>agent_1_feat_scheme_1</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feat_scheme_10</th>\n",
       "      <th>agent_2_feat_scheme_12</th>\n",
       "      <th>agent_2_feat_scheme_13</th>\n",
       "      <th>agent_2_feat_scheme_14</th>\n",
       "      <th>agent_2_feat_scheme_15</th>\n",
       "      <th>agent_2_feat_scheme_16</th>\n",
       "      <th>agent_2_feat_scheme_18</th>\n",
       "      <th>agent_2_feat_scheme_19</th>\n",
       "      <th>agent_1_feat_both_scored_mean</th>\n",
       "      <th>agent_2_feat_both_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.83</td>\n",
       "      <td>0.844742</td>\n",
       "      <td>0.813158</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.932160</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>1.373421</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.65</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>1.050263</td>\n",
       "      <td>6.63</td>\n",
       "      <td>0.657574</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>1.516842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.73</td>\n",
       "      <td>0.954509</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.156463</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>1.238684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.85</td>\n",
       "      <td>1.155612</td>\n",
       "      <td>1.103158</td>\n",
       "      <td>6.46</td>\n",
       "      <td>0.603136</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.739737</td>\n",
       "      <td>2.0</td>\n",
       "      <td>74.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.81</td>\n",
       "      <td>1.199718</td>\n",
       "      <td>1.382895</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.941698</td>\n",
       "      <td>1.789474</td>\n",
       "      <td>1.244737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>6.72</td>\n",
       "      <td>0.814332</td>\n",
       "      <td>1.238000</td>\n",
       "      <td>6.71</td>\n",
       "      <td>1.443570</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.892500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>6.69</td>\n",
       "      <td>1.186944</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.63</td>\n",
       "      <td>0.688468</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.558000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>76.181818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>7.05</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>6.69</td>\n",
       "      <td>0.243309</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.170000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.727273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.11</td>\n",
       "      <td>0.846805</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>6.68</td>\n",
       "      <td>1.702128</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.018000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>75.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>6.42</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>2.122000</td>\n",
       "      <td>6.88</td>\n",
       "      <td>0.791557</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.777500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.363636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.378378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XgaAv  \\\n",
       "0                   6.83               0.844742            0.813158   \n",
       "1                   6.65               0.743218            1.050263   \n",
       "2                   6.73               0.954509            1.320000   \n",
       "3                   6.85               1.155612            1.103158   \n",
       "4                   6.81               1.199718            1.382895   \n",
       "..                   ...                    ...                 ...   \n",
       "565                 6.72               0.814332            1.238000   \n",
       "566                 6.69               1.186944            1.950000   \n",
       "567                 7.05               0.877193            0.778000   \n",
       "568                 7.11               0.846805            0.498000   \n",
       "569                 6.42               0.480769            2.122000   \n",
       "\n",
       "     agent_2_feat_Rating  agent_2_feat_XGrealiz  agent_2_feat_ScoredAv  \\\n",
       "0                   6.67               0.932160               0.947368   \n",
       "1                   6.63               0.657574               0.710526   \n",
       "2                   6.80               1.156463               1.789474   \n",
       "3                   6.46               0.603136               0.526316   \n",
       "4                   6.82               0.941698               1.789474   \n",
       "..                   ...                    ...                    ...   \n",
       "565                 6.71               1.443570               2.750000   \n",
       "566                 6.63               0.688468               0.800000   \n",
       "567                 6.69               0.243309               0.400000   \n",
       "568                 6.68               1.702128               1.600000   \n",
       "569                 6.88               0.791557               0.750000   \n",
       "\n",
       "     agent_2_feat_XgaAv  agent_2_feat_missed_3  agent_2_feat_pl_mean  \\\n",
       "0              1.373421                    3.0             76.909091   \n",
       "1              1.516842                    1.0             75.181818   \n",
       "2              1.238684                    1.0             77.727273   \n",
       "3              1.739737                    2.0             74.909091   \n",
       "4              1.244737                    1.0             86.181818   \n",
       "..                  ...                    ...                   ...   \n",
       "565            0.892500                    1.0             81.090909   \n",
       "566            1.558000                    2.0             76.181818   \n",
       "567            1.170000                    2.0             78.727273   \n",
       "568            1.018000                    2.0             75.363636   \n",
       "569            1.777500                    1.0             81.363636   \n",
       "\n",
       "     agent_1_feat_scheme_1  ...  agent_2_feat_scheme_10  \\\n",
       "0                      0.0  ...                     0.0   \n",
       "1                      0.0  ...                     0.0   \n",
       "2                      1.0  ...                     0.0   \n",
       "3                      0.0  ...                     0.0   \n",
       "4                      0.0  ...                     0.0   \n",
       "..                     ...  ...                     ...   \n",
       "565                    0.0  ...                     0.0   \n",
       "566                    0.0  ...                     0.0   \n",
       "567                    0.0  ...                     0.0   \n",
       "568                    0.0  ...                     0.0   \n",
       "569                    0.0  ...                     0.0   \n",
       "\n",
       "     agent_2_feat_scheme_12  agent_2_feat_scheme_13  agent_2_feat_scheme_14  \\\n",
       "0                       0.0                     1.0                     0.0   \n",
       "1                       0.0                     0.0                     0.0   \n",
       "2                       0.0                     0.0                     0.0   \n",
       "3                       0.0                     0.0                     0.0   \n",
       "4                       0.0                     0.0                     0.0   \n",
       "..                      ...                     ...                     ...   \n",
       "565                     0.0                     0.0                     0.0   \n",
       "566                     0.0                     0.0                     0.0   \n",
       "567                     0.0                     0.0                     0.0   \n",
       "568                     0.0                     0.0                     0.0   \n",
       "569                     0.0                     0.0                     0.0   \n",
       "\n",
       "     agent_2_feat_scheme_15  agent_2_feat_scheme_16  agent_2_feat_scheme_18  \\\n",
       "0                       0.0                     0.0                     0.0   \n",
       "1                       0.0                     0.0                     1.0   \n",
       "2                       0.0                     0.0                     0.0   \n",
       "3                       0.0                     0.0                     0.0   \n",
       "4                       0.0                     0.0                     0.0   \n",
       "..                      ...                     ...                     ...   \n",
       "565                     0.0                     0.0                     0.0   \n",
       "566                     0.0                     0.0                     0.0   \n",
       "567                     0.0                     0.0                     0.0   \n",
       "568                     1.0                     0.0                     0.0   \n",
       "569                     0.0                     0.0                     0.0   \n",
       "\n",
       "     agent_2_feat_scheme_19  agent_1_feat_both_scored_mean  \\\n",
       "0                       0.0                       0.473684   \n",
       "1                       0.0                       0.631579   \n",
       "2                       0.0                       0.588235   \n",
       "3                       0.0                       0.631579   \n",
       "4                       0.0                       0.555556   \n",
       "..                      ...                            ...   \n",
       "565                     0.0                       0.513514   \n",
       "566                     0.0                       0.675676   \n",
       "567                     0.0                       0.405405   \n",
       "568                     0.0                       0.378378   \n",
       "569                     0.0                       0.378378   \n",
       "\n",
       "     agent_2_feat_both_scored_mean  \n",
       "0                         0.526316  \n",
       "1                         0.500000  \n",
       "2                         0.421053  \n",
       "3                         0.421053  \n",
       "4                         0.578947  \n",
       "..                             ...  \n",
       "565                       0.594595  \n",
       "566                       0.594595  \n",
       "567                       0.351351  \n",
       "568                       0.513514  \n",
       "569                       0.378378  \n",
       "\n",
       "[570 rows x 38 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df2 = test_df[list(fearues_names2)]\n",
    "new_test_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train2, new_X_test2, new_test_df2 = scale_data(new_X_train2, new_X_test2, new_test_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1730, 9) (433, 9)\n"
     ]
    }
   ],
   "source": [
    "y_train2 = pd.get_dummies(y_train2)\n",
    "y_test2 = pd.get_dummies(y_test2)\n",
    "y_train2, y_test2 = make_equal_dummies(y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_results2 = grid_search(new_X_train2, y_train2, 'expected_target2')\n",
    "# batch_size2 = grid_results2.best_params_['batch_size']\n",
    "# epochs2 = grid_results2.best_params_['epochs']\n",
    "# learning_rate2 = grid_results2.best_params_['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size2 = 32\n",
    "epochs2 = 100\n",
    "learning_rate2 = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 2s 7ms/step - loss: 2.8354 - accuracy: 0.0919 - val_loss: 2.2886 - val_accuracy: 0.0115\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.8305 - accuracy: 0.0942 - val_loss: 2.3586 - val_accuracy: 0.0092\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.7581 - accuracy: 0.1017 - val_loss: 2.3892 - val_accuracy: 0.0162\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.6963 - accuracy: 0.1006 - val_loss: 2.3868 - val_accuracy: 0.0370\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.6733 - accuracy: 0.1191 - val_loss: 2.3670 - val_accuracy: 0.0624\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.6189 - accuracy: 0.1179 - val_loss: 2.3476 - val_accuracy: 0.0808\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.5787 - accuracy: 0.1358 - val_loss: 2.3220 - val_accuracy: 0.0855\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.5657 - accuracy: 0.1347 - val_loss: 2.2835 - val_accuracy: 0.1062\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.5261 - accuracy: 0.1382 - val_loss: 2.2578 - val_accuracy: 0.1201\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.5213 - accuracy: 0.1347 - val_loss: 2.2419 - val_accuracy: 0.1432\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4902 - accuracy: 0.1439 - val_loss: 2.2185 - val_accuracy: 0.1455\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4288 - accuracy: 0.1555 - val_loss: 2.2081 - val_accuracy: 0.1409\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4059 - accuracy: 0.1549 - val_loss: 2.1849 - val_accuracy: 0.1663\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.4379 - accuracy: 0.1491 - val_loss: 2.1739 - val_accuracy: 0.1801\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3704 - accuracy: 0.1728 - val_loss: 2.1466 - val_accuracy: 0.1917\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3658 - accuracy: 0.1618 - val_loss: 2.1394 - val_accuracy: 0.1940\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.3112 - accuracy: 0.1867 - val_loss: 2.1161 - val_accuracy: 0.2171\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 2.2955 - accuracy: 0.1855 - val_loss: 2.1050 - val_accuracy: 0.2333\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 2.3209 - accuracy: 0.1850 - val_loss: 2.1223 - val_accuracy: 0.1848\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2981 - accuracy: 0.1850 - val_loss: 2.0884 - val_accuracy: 0.2148\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2526 - accuracy: 0.2006 - val_loss: 2.0813 - val_accuracy: 0.2125\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2333 - accuracy: 0.2052 - val_loss: 2.0776 - val_accuracy: 0.2379\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2379 - accuracy: 0.1815 - val_loss: 2.0625 - val_accuracy: 0.2425\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2153 - accuracy: 0.2133 - val_loss: 2.0449 - val_accuracy: 0.2517\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1962 - accuracy: 0.2023 - val_loss: 2.0281 - val_accuracy: 0.2471\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.2312 - accuracy: 0.2150 - val_loss: 1.9540 - val_accuracy: 0.2956\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1948 - accuracy: 0.2110 - val_loss: 1.9773 - val_accuracy: 0.2633\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1183 - accuracy: 0.2231 - val_loss: 1.9631 - val_accuracy: 0.2702\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1329 - accuracy: 0.2214 - val_loss: 1.9713 - val_accuracy: 0.2748\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.1216 - accuracy: 0.2168 - val_loss: 1.9675 - val_accuracy: 0.2656\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0756 - accuracy: 0.2457 - val_loss: 1.9578 - val_accuracy: 0.2679\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0582 - accuracy: 0.2486 - val_loss: 1.9578 - val_accuracy: 0.2610\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0937 - accuracy: 0.2312 - val_loss: 1.9495 - val_accuracy: 0.2610\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0441 - accuracy: 0.2422 - val_loss: 1.9227 - val_accuracy: 0.2564\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0338 - accuracy: 0.2387 - val_loss: 1.9009 - val_accuracy: 0.2517\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 2.0213 - accuracy: 0.2578 - val_loss: 1.8964 - val_accuracy: 0.2425\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9942 - accuracy: 0.2491 - val_loss: 1.8750 - val_accuracy: 0.2587\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9917 - accuracy: 0.2740 - val_loss: 1.8595 - val_accuracy: 0.2794\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9751 - accuracy: 0.2711 - val_loss: 1.8493 - val_accuracy: 0.2864\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9408 - accuracy: 0.2931 - val_loss: 1.8383 - val_accuracy: 0.2933\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9453 - accuracy: 0.2699 - val_loss: 1.8398 - val_accuracy: 0.2679\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9460 - accuracy: 0.2746 - val_loss: 1.8344 - val_accuracy: 0.2910\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9328 - accuracy: 0.2642 - val_loss: 1.8259 - val_accuracy: 0.3002\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8708 - accuracy: 0.2925 - val_loss: 1.8199 - val_accuracy: 0.3048\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.9077 - accuracy: 0.2780 - val_loss: 1.8056 - val_accuracy: 0.3048\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8834 - accuracy: 0.2983 - val_loss: 1.7975 - val_accuracy: 0.3048\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.8895 - accuracy: 0.2908 - val_loss: 1.7763 - val_accuracy: 0.3533\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8522 - accuracy: 0.3069 - val_loss: 1.7683 - val_accuracy: 0.3072\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8849 - accuracy: 0.2780 - val_loss: 1.7623 - val_accuracy: 0.3048\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8553 - accuracy: 0.3156 - val_loss: 1.7606 - val_accuracy: 0.3072\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8694 - accuracy: 0.2983 - val_loss: 1.7565 - val_accuracy: 0.3025\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8403 - accuracy: 0.3000 - val_loss: 1.7515 - val_accuracy: 0.3095\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8342 - accuracy: 0.3064 - val_loss: 1.7535 - val_accuracy: 0.3048\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8158 - accuracy: 0.3092 - val_loss: 1.7460 - val_accuracy: 0.2933\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8117 - accuracy: 0.3133 - val_loss: 1.7401 - val_accuracy: 0.2979\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8038 - accuracy: 0.3179 - val_loss: 1.7361 - val_accuracy: 0.2864\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.8022 - accuracy: 0.3127 - val_loss: 1.7216 - val_accuracy: 0.2933\n",
      "Epoch 58/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7681 - accuracy: 0.3254 - val_loss: 1.7165 - val_accuracy: 0.2910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7686 - accuracy: 0.3104 - val_loss: 1.7116 - val_accuracy: 0.2933\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7495 - accuracy: 0.3283 - val_loss: 1.7087 - val_accuracy: 0.2956\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7526 - accuracy: 0.3139 - val_loss: 1.7047 - val_accuracy: 0.2864\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7280 - accuracy: 0.3283 - val_loss: 1.6878 - val_accuracy: 0.2956\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7506 - accuracy: 0.3029 - val_loss: 1.6808 - val_accuracy: 0.2956\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7355 - accuracy: 0.3191 - val_loss: 1.6755 - val_accuracy: 0.3025\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7284 - accuracy: 0.3283 - val_loss: 1.6686 - val_accuracy: 0.3048\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7491 - accuracy: 0.3162 - val_loss: 1.6604 - val_accuracy: 0.3164\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7138 - accuracy: 0.3329 - val_loss: 1.6618 - val_accuracy: 0.3210\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7135 - accuracy: 0.3162 - val_loss: 1.6584 - val_accuracy: 0.3141\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7036 - accuracy: 0.3410 - val_loss: 1.6496 - val_accuracy: 0.3164\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.6946 - accuracy: 0.3347 - val_loss: 1.6462 - val_accuracy: 0.3187\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.7111 - accuracy: 0.3202 - val_loss: 1.6424 - val_accuracy: 0.3210\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6482 - accuracy: 0.3399 - val_loss: 1.6372 - val_accuracy: 0.3233\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6746 - accuracy: 0.3376 - val_loss: 1.6377 - val_accuracy: 0.3118\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6868 - accuracy: 0.3237 - val_loss: 1.6321 - val_accuracy: 0.3164\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6760 - accuracy: 0.3277 - val_loss: 1.6267 - val_accuracy: 0.3164\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6613 - accuracy: 0.3422 - val_loss: 1.6242 - val_accuracy: 0.3072\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6880 - accuracy: 0.3237 - val_loss: 1.6340 - val_accuracy: 0.3164\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6628 - accuracy: 0.3387 - val_loss: 1.6143 - val_accuracy: 0.3395\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6870 - accuracy: 0.3306 - val_loss: 1.6094 - val_accuracy: 0.3210\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6725 - accuracy: 0.3197 - val_loss: 1.6051 - val_accuracy: 0.3326\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6503 - accuracy: 0.3422 - val_loss: 1.6023 - val_accuracy: 0.3095\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.6560 - accuracy: 0.3266 - val_loss: 1.6014 - val_accuracy: 0.3187\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6302 - accuracy: 0.3549 - val_loss: 1.5857 - val_accuracy: 0.3141\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6459 - accuracy: 0.3231 - val_loss: 1.5784 - val_accuracy: 0.3256\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6382 - accuracy: 0.3410 - val_loss: 1.5774 - val_accuracy: 0.3187\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6254 - accuracy: 0.3370 - val_loss: 1.5732 - val_accuracy: 0.3303\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 1.6222 - accuracy: 0.3220 - val_loss: 1.5711 - val_accuracy: 0.3349\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6436 - accuracy: 0.3208 - val_loss: 1.5688 - val_accuracy: 0.3279\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6181 - accuracy: 0.3324 - val_loss: 1.5640 - val_accuracy: 0.3326\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6078 - accuracy: 0.3462 - val_loss: 1.5584 - val_accuracy: 0.3210\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6171 - accuracy: 0.3468 - val_loss: 1.5554 - val_accuracy: 0.3233\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6021 - accuracy: 0.3422 - val_loss: 1.5500 - val_accuracy: 0.3279\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.5991 - accuracy: 0.3364 - val_loss: 1.5587 - val_accuracy: 0.3279\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6036 - accuracy: 0.3428 - val_loss: 1.5606 - val_accuracy: 0.3233\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.5856 - accuracy: 0.3462 - val_loss: 1.5725 - val_accuracy: 0.3256\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6100 - accuracy: 0.3358 - val_loss: 1.5657 - val_accuracy: 0.3349\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6089 - accuracy: 0.3179 - val_loss: 1.5606 - val_accuracy: 0.3418\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.6090 - accuracy: 0.3451 - val_loss: 1.5579 - val_accuracy: 0.3303\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.5940 - accuracy: 0.3428 - val_loss: 1.5552 - val_accuracy: 0.3349\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 1.5839 - accuracy: 0.3428 - val_loss: 1.5537 - val_accuracy: 0.3395\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_df['expected_target2'].nunique()\n",
    "model2 = create_model(batch_size2, epochs2, learning_rate2, num_classes, new_X_train2.shape[1])\n",
    "history2 = model2.fit(new_X_train2, y_train2, \n",
    "                      batch_size = batch_size2, \n",
    "                      epochs = epochs2,\n",
    "                      validation_data = (new_X_test2, y_test2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_graphs(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.575\n"
     ]
    }
   ],
   "source": [
    "tmp_pred_value2 = calc_train_acc(model2, 'expected_target2', Y_expected2, new_X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.logical_and(tmp_pred_value1, tmp_pred_value2)\n",
    "test_pred = [0 if x==False else x for x in test_pred]\n",
    "test_pred = [1 if x==True else x for x in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1979    0\n",
       "1980    0\n",
       "1981    1\n",
       "1982    0\n",
       "1983    0\n",
       "       ..\n",
       "2465    1\n",
       "2466    1\n",
       "2467    0\n",
       "2468    1\n",
       "2469    1\n",
       "Name: category, Length: 433, dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_real_value = train_df['category'][int(len(Y_expected1)*0.8):len(Y_expected1)]\n",
    "test_real_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.515\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for elem1, elem2 in zip(test_pred, test_real_value):\n",
    "    if elem1 == elem2:\n",
    "        acc += 1\n",
    "print(\"ACC: \", np.round((acc / len(test_real_value)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKm-keClFa1Q"
   },
   "source": [
    "# Make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "fin_pred1 = model1.predict(new_test_df1)\n",
    "tmp1 = []\n",
    "for i in fin_pred1:\n",
    "    if i.argmax() != 0:\n",
    "        tmp1.append(1)\n",
    "    else:\n",
    "        tmp1.append(0)\n",
    "\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "fin_pred2 = model2.predict(new_test_df2)\n",
    "tmp2 = []\n",
    "for i in fin_pred2:\n",
    "    if i.argmax() != 0:\n",
    "        tmp2.append(1)\n",
    "    else:\n",
    "        tmp2.append(0)\n",
    "\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer = np.logical_and(tmp1, tmp2)\n",
    "Answer = [0 if x==False else x for x in Answer]\n",
    "Answer = [1 if x==True else x for x in Answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "_b27gGlzPE2w"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['tmp'] = Answer\n",
    "sample_submission.drop(['category'], axis = 1, inplace= True)\n",
    "sample_submission = sample_submission.rename(columns={\"tmp\": \"category\"})\n",
    "sample_submission.to_csv('Answer.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  category\n",
       "0      0         0\n",
       "1      1         0\n",
       "2      2         1\n",
       "3      3         0\n",
       "4      4         1\n",
       "..   ...       ...\n",
       "565  565         1\n",
       "566  566         0\n",
       "567  567         0\n",
       "568  568         1\n",
       "569  569         1\n",
       "\n",
       "[570 rows x 2 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check 33% acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv('released_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5797872340425532\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for i, j in zip(sample_submission.iloc[0:len(answers)]['category'], answers['category']):\n",
    "    if i == j:\n",
    "        num +=1\n",
    "print(num / len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
