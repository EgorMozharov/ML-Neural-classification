{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erc2A41DMzku"
   },
   "source": [
    "# DSBA 22/23 HSE & University of London\n",
    "\n",
    "# Practical assignment 1. DL in classification.\n",
    "\n",
    "## General info\n",
    "Release data: 26.09.2022\n",
    "\n",
    "Soft deadline: 10.10.2022 23:59 MSK\n",
    "\n",
    "Hard deadline: 13.10.2021 23:59 MSK\n",
    "\n",
    "In this task, you are to build a NN for a binary classification task. We suggest using Google Colab for access to GPU. Competition invite link: https://www.kaggle.com/t/1917e22edb71437ca24d790ab1d57695\n",
    "\n",
    "## Evaluation and fines\n",
    "\n",
    "Each section has a defined \"value\" (in brackets near the section). Maximum grade for the task - 10 points, other points can be assigned to your tests.\n",
    "\n",
    "**Your notebook with the best solution must be reproducible should be sent to the dropbox!** If the assessor cannot reproduce your results, you may be assigned score = 0, so make all your computations fixed!\n",
    "\n",
    "**You can only use neural networks / linear / nearest neighbors models for this task - tree-based models are forbidden!**\n",
    "\n",
    "All the parts must be done independently.\n",
    "\n",
    "After the hard deadline is passed, the hometask is not accepted. If you send the hometask after the soft deadline, you will be excluded from competition among your mates and the homework will only be scored by the \"Beating the baseline\" part.\n",
    "\n",
    "Feel free to ask questions both the teacher and your mates, but __do not copy the code or do it together__. \"Similar\" solutions are considered a plagiarism and all the involved students (the ones who gave & the ones who did) cannot get more than 0.01 points for the task. If you found a solution in some open source, you __must__ reference it in a special block at the end of your work (to exclude the suspicions in plagiarism).\n",
    "\n",
    "\n",
    "## Format of handing over\n",
    "\n",
    "The tasks are sent to the dropbox: https://www.dropbox.com/request/Y6TJouxNbm3r0RgcBL35. Don't forget to attach your name, surname & your group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwMZDBm4S9o3"
   },
   "source": [
    "## 1. Model training\n",
    "\n",
    "**Important!** Public Leaderboard contains only 33% of the test data. Your points will be measured wrt to the whole test set, therefore your position on the LB after the end of the competition may change.\n",
    "\n",
    "* test_accuracy > weak baseline (public LB): 3 points\n",
    "\n",
    "* test_accuracy > medium baseline (public LB): + 3 points\n",
    "\n",
    "* test_accuracy > strong baseline (public LB): + 2 points\n",
    "\n",
    "* You are among 25% most successful students (private LB): + 2 point\n",
    "\n",
    "* You are among top-3 most successful students (private LB): + 1 point\n",
    "\n",
    "* You are among top-2 most successful students (private LB): + 1 point\n",
    "\n",
    "* You are among top-1 most successful students (private LB): + 1 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VnJmCRD8S9o3"
   },
   "outputs": [],
   "source": [
    "# Your code here ╰( ͡° ͜ʖ ͡° )つ──☆*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "WLBmP2zTFmnB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "c6tn9gN7ohs9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "3Tj4gkZnWENb"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "LudqW7xct2rH"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9PHJ1f-gPTm"
   },
   "source": [
    "# **Preprocessing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "P3YAH9EgS9o3"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "target_df = pd.read_csv('train_target.csv')\n",
    "train_expected_target1 = pd.read_csv('train_expected_target_agent_1.csv')\n",
    "train_expected_target2 = pd.read_csv('train_expected_target_agent_2.csv')\n",
    "train_target_agent_1 = pd.read_csv('train_target_agent_1.csv')\n",
    "train_target_agent_2 = pd.read_csv('train_target_agent_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_agent_1 = train_target_agent_1.rename(columns={\"0\": \"expected_target1\"})\n",
    "train_target_agent_2 = train_target_agent_2.rename(columns={\"0\": \"expected_target2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_target_agent_1, train_target_agent_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "XtxGrhyjVEee",
    "outputId": "d81db566-83f9-47d1-c8e8-4c9333b09d31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>agent_1_feat_ODC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>14.16</td>\n",
       "      <td>267.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>7.66</td>\n",
       "      <td>191.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.53</td>\n",
       "      <td>195.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>8.76</td>\n",
       "      <td>161.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.8                85.1                     15.8   \n",
       "1                      44.8                71.1                     23.4   \n",
       "2                      46.3                70.8                     21.7   \n",
       "3                      50.2                77.5                     24.4   \n",
       "4                      44.9                75.0                     17.2   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.99               1.143700                0.928715   \n",
       "1                 6.84               0.954159                0.975350   \n",
       "2                 6.77               0.918434                1.118603   \n",
       "3                 6.87               1.037613                0.956836   \n",
       "4                 6.77               0.983691                0.948837   \n",
       "\n",
       "   agent_1_feat_PPDA  agent_1_feat_OPPDA  agent_1_feat_DC  agent_1_feat_ODC  \\\n",
       "0               7.13               14.16            267.0             194.0   \n",
       "1               9.99                7.66            191.0             287.0   \n",
       "2               9.56                7.34            179.0             298.0   \n",
       "3               9.60                9.53            195.0             239.0   \n",
       "4              12.24                8.76            161.0             283.0   \n",
       "\n",
       "   ...  agent_2_feattotal_xg_1  agent_2_feattotal_xg_mean_3  \\\n",
       "0  ...                2.739439                     2.739439   \n",
       "1  ...                2.336756                     2.336756   \n",
       "2  ...                2.120322                     2.120322   \n",
       "3  ...                2.216415                     2.216415   \n",
       "4  ...                2.604025                     2.604025   \n",
       "\n",
       "   agent_2_feattotal_xg_mean  agent_2_featboth_scored_3  \\\n",
       "0                        NaN                   0.473684   \n",
       "1                        NaN                   0.578947   \n",
       "2                        NaN                   0.368421   \n",
       "3                        NaN                   0.210526   \n",
       "4                        NaN                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_2  agent_2_featboth_scored_1  \\\n",
       "0                   0.473684                   0.473684   \n",
       "1                   0.578947                   0.578947   \n",
       "2                   0.368421                   0.368421   \n",
       "3                   0.210526                   0.210526   \n",
       "4                   0.421053                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_mean_3  agent_2_featboth_scored_mean  \\\n",
       "0                        0.473684                           NaN   \n",
       "1                        0.578947                           NaN   \n",
       "2                        0.368421                           NaN   \n",
       "3                        0.210526                           NaN   \n",
       "4                        0.421053                           NaN   \n",
       "\n",
       "   expected_target1  expected_target2  \n",
       "0                 1                 2  \n",
       "1                 2                 2  \n",
       "2                 0                 1  \n",
       "3                 0                 1  \n",
       "4                 2                 2  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "fi9w8WcKVID2",
    "outputId": "3acc7dd6-6503-4c25-ccee-9bbc933f764b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>agent_1_feat_ODC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_3</th>\n",
       "      <th>agent_2_feattotal_xg_2</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>6.83</td>\n",
       "      <td>0.844742</td>\n",
       "      <td>1.165049</td>\n",
       "      <td>9.19</td>\n",
       "      <td>16.50</td>\n",
       "      <td>337.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.661870</td>\n",
       "      <td>1.893116</td>\n",
       "      <td>4.241360</td>\n",
       "      <td>2.932115</td>\n",
       "      <td>2.690442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.7</td>\n",
       "      <td>81.3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.743218</td>\n",
       "      <td>1.152593</td>\n",
       "      <td>10.31</td>\n",
       "      <td>13.63</td>\n",
       "      <td>311.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.550724</td>\n",
       "      <td>2.373700</td>\n",
       "      <td>4.197010</td>\n",
       "      <td>3.373811</td>\n",
       "      <td>3.075302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.3</td>\n",
       "      <td>81.4</td>\n",
       "      <td>17.7</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.954509</td>\n",
       "      <td>0.956938</td>\n",
       "      <td>14.21</td>\n",
       "      <td>11.82</td>\n",
       "      <td>207.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.693652</td>\n",
       "      <td>2.042668</td>\n",
       "      <td>0.966665</td>\n",
       "      <td>1.900995</td>\n",
       "      <td>3.007033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.5</td>\n",
       "      <td>84.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1.155612</td>\n",
       "      <td>1.049618</td>\n",
       "      <td>10.95</td>\n",
       "      <td>12.46</td>\n",
       "      <td>339.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.938100</td>\n",
       "      <td>1.466409</td>\n",
       "      <td>0.922046</td>\n",
       "      <td>2.108852</td>\n",
       "      <td>2.643923</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>16.4</td>\n",
       "      <td>6.81</td>\n",
       "      <td>1.199718</td>\n",
       "      <td>0.856327</td>\n",
       "      <td>11.27</td>\n",
       "      <td>11.52</td>\n",
       "      <td>193.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.358338</td>\n",
       "      <td>2.138405</td>\n",
       "      <td>1.872476</td>\n",
       "      <td>2.456406</td>\n",
       "      <td>3.113815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.6                87.0                     15.2   \n",
       "1                      50.7                81.3                     14.2   \n",
       "2                      47.3                81.4                     17.7   \n",
       "3                      54.5                84.8                     14.5   \n",
       "4                      51.3                81.8                     16.4   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.83               0.844742                1.165049   \n",
       "1                 6.65               0.743218                1.152593   \n",
       "2                 6.73               0.954509                0.956938   \n",
       "3                 6.85               1.155612                1.049618   \n",
       "4                 6.81               1.199718                0.856327   \n",
       "\n",
       "   agent_1_feat_PPDA  agent_1_feat_OPPDA  agent_1_feat_DC  agent_1_feat_ODC  \\\n",
       "0               9.19               16.50            337.0             179.0   \n",
       "1              10.31               13.63            311.0             208.0   \n",
       "2              14.21               11.82            207.0             270.0   \n",
       "3              10.95               12.46            339.0             186.0   \n",
       "4              11.27               11.52            193.0             293.0   \n",
       "\n",
       "   ...  agent_2_feattotal_xg_3  agent_2_feattotal_xg_2  \\\n",
       "0  ...                2.661870                1.893116   \n",
       "1  ...                3.550724                2.373700   \n",
       "2  ...                2.693652                2.042668   \n",
       "3  ...                3.938100                1.466409   \n",
       "4  ...                3.358338                2.138405   \n",
       "\n",
       "   agent_2_feattotal_xg_1  agent_2_feattotal_xg_mean_3  \\\n",
       "0                4.241360                     2.932115   \n",
       "1                4.197010                     3.373811   \n",
       "2                0.966665                     1.900995   \n",
       "3                0.922046                     2.108852   \n",
       "4                1.872476                     2.456406   \n",
       "\n",
       "   agent_2_feattotal_xg_mean  agent_2_featboth_scored_3  \\\n",
       "0                   2.690442                        1.0   \n",
       "1                   3.075302                        0.0   \n",
       "2                   3.007033                        0.0   \n",
       "3                   2.643923                        1.0   \n",
       "4                   3.113815                        0.0   \n",
       "\n",
       "   agent_2_featboth_scored_2  agent_2_featboth_scored_1  \\\n",
       "0                        0.0                        1.0   \n",
       "1                        1.0                        1.0   \n",
       "2                        1.0                        1.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        0.0                        0.0   \n",
       "\n",
       "   agent_2_featboth_scored_mean_3  agent_2_featboth_scored_mean  \n",
       "0                        0.666667                      0.333333  \n",
       "1                        0.666667                      0.625000  \n",
       "2                        0.666667                      0.555556  \n",
       "3                        0.333333                      0.444444  \n",
       "4                        0.000000                      0.555556  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WlvCdFqVUSf",
    "outputId": "95181e8f-d145-49d6-8c1f-7520814b665c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2470, 236)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjIbnhiPVYT-",
    "outputId": "8c96af8c-bf60-401c-b737-9294f66f3cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2470 entries, 0 to 2469\n",
      "Columns: 236 entries, agent_1_feat_Possession% to expected_target2\n",
      "dtypes: float64(212), int64(24)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ceY_OeBgqdO8"
   },
   "outputs": [],
   "source": [
    "target_df.drop('id', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "p0N_mUFAqMIj"
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([target_df, train_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "1TZbR6awq_C9",
    "outputId": "12ad58c1-8a7b-4bb0-dff6-5aac2487450b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>14.16</td>\n",
       "      <td>267.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>7.66</td>\n",
       "      <td>191.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.53</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>8.76</td>\n",
       "      <td>161.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.032989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.684860</td>\n",
       "      <td>4.024907</td>\n",
       "      <td>3.872622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1</td>\n",
       "      <td>42.9</td>\n",
       "      <td>76.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.066236</td>\n",
       "      <td>16.14</td>\n",
       "      <td>7.60</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568175</td>\n",
       "      <td>2.000313</td>\n",
       "      <td>2.572016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.026472</td>\n",
       "      <td>15.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.871643</td>\n",
       "      <td>2.496854</td>\n",
       "      <td>2.555157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1</td>\n",
       "      <td>51.4</td>\n",
       "      <td>79.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.161401</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.47</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.904164</td>\n",
       "      <td>2.977092</td>\n",
       "      <td>2.495116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>13.16</td>\n",
       "      <td>9.72</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.945618</td>\n",
       "      <td>3.414186</td>\n",
       "      <td>2.861741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2470 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  agent_1_feat_Possession%  agent_1_feat_Pass%  \\\n",
       "0            1                      58.8                85.1   \n",
       "1            1                      44.8                71.1   \n",
       "2            0                      46.3                70.8   \n",
       "3            0                      50.2                77.5   \n",
       "4            1                      44.9                75.0   \n",
       "...        ...                       ...                 ...   \n",
       "2465         1                      41.6                76.0   \n",
       "2466         1                      42.9                76.1   \n",
       "2467         0                      41.0                72.2   \n",
       "2468         1                      51.4                79.3   \n",
       "2469         1                      43.5                71.6   \n",
       "\n",
       "      agent_1_feat_AerialsWon  agent_1_feat_Rating  agent_1_feat_XGrealiz  \\\n",
       "0                        15.8                 6.99               1.143700   \n",
       "1                        23.4                 6.84               0.954159   \n",
       "2                        21.7                 6.77               0.918434   \n",
       "3                        24.4                 6.87               1.037613   \n",
       "4                        17.2                 6.77               0.983691   \n",
       "...                       ...                  ...                    ...   \n",
       "2465                     17.1                 6.62               1.046406   \n",
       "2466                     18.3                 6.61               1.161802   \n",
       "2467                     19.1                 6.51               1.000858   \n",
       "2468                     14.1                 6.62               1.037986   \n",
       "2469                     23.4                 6.64               0.865460   \n",
       "\n",
       "      agent_1_feat_XGArealiz  agent_1_feat_PPDA  agent_1_feat_OPPDA  \\\n",
       "0                   0.928715               7.13               14.16   \n",
       "1                   0.975350               9.99                7.66   \n",
       "2                   1.118603               9.56                7.34   \n",
       "3                   0.956836               9.60                9.53   \n",
       "4                   0.948837              12.24                8.76   \n",
       "...                      ...                ...                 ...   \n",
       "2465                1.032989              18.00                8.27   \n",
       "2466                1.066236              16.14                7.60   \n",
       "2467                1.026472              15.99                7.99   \n",
       "2468                1.161401               9.73               10.47   \n",
       "2469                0.931256              13.16                9.72   \n",
       "\n",
       "      agent_1_feat_DC  ...  agent_2_feattotal_xg_1  \\\n",
       "0               267.0  ...                2.739439   \n",
       "1               191.0  ...                2.336756   \n",
       "2               179.0  ...                2.120322   \n",
       "3               195.0  ...                2.216415   \n",
       "4               161.0  ...                2.604025   \n",
       "...               ...  ...                     ...   \n",
       "2465            138.0  ...                3.684860   \n",
       "2466            201.0  ...                1.568175   \n",
       "2467            164.0  ...                3.871643   \n",
       "2468            222.0  ...                4.904164   \n",
       "2469            233.0  ...                3.945618   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "0                        2.739439                        NaN   \n",
       "1                        2.336756                        NaN   \n",
       "2                        2.120322                        NaN   \n",
       "3                        2.216415                        NaN   \n",
       "4                        2.604025                        NaN   \n",
       "...                           ...                        ...   \n",
       "2465                     4.024907                   3.872622   \n",
       "2466                     2.000313                   2.572016   \n",
       "2467                     2.496854                   2.555157   \n",
       "2468                     2.977092                   2.495116   \n",
       "2469                     3.414186                   2.861741   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "0                      0.473684                   0.473684   \n",
       "1                      0.578947                   0.578947   \n",
       "2                      0.368421                   0.368421   \n",
       "3                      0.210526                   0.210526   \n",
       "4                      0.421053                   0.421053   \n",
       "...                         ...                        ...   \n",
       "2465                   1.000000                   0.000000   \n",
       "2466                   0.000000                   0.000000   \n",
       "2467                   0.000000                   0.000000   \n",
       "2468                   1.000000                   0.000000   \n",
       "2469                   1.000000                   1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "0                      0.473684                        0.473684   \n",
       "1                      0.578947                        0.578947   \n",
       "2                      0.368421                        0.368421   \n",
       "3                      0.210526                        0.210526   \n",
       "4                      0.421053                        0.421053   \n",
       "...                         ...                             ...   \n",
       "2465                   0.000000                        0.333333   \n",
       "2466                   0.000000                        0.000000   \n",
       "2467                   1.000000                        0.333333   \n",
       "2468                   0.000000                        0.333333   \n",
       "2469                   0.000000                        0.666667   \n",
       "\n",
       "      agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "0                              NaN                 1                 2  \n",
       "1                              NaN                 2                 2  \n",
       "2                              NaN                 0                 1  \n",
       "3                              NaN                 0                 1  \n",
       "4                              NaN                 2                 2  \n",
       "...                            ...               ...               ...  \n",
       "2465                      0.444444                 1                 2  \n",
       "2466                      0.444444                 2                 3  \n",
       "2467                      0.500000                 0                 5  \n",
       "2468                      0.222222                 1                 3  \n",
       "2469                      0.333333                 3                 2  \n",
       "\n",
       "[2470 rows x 237 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VaUeSE29_6w"
   },
   "source": [
    "## Delete outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "CkheOAfn_zOK",
    "outputId": "000d0384-64b4-4d66-f341-0a872abe165e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_expected_target2</th>\n",
       "      <th>train_expected_target1</th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278076</td>\n",
       "      <td>1.166350</td>\n",
       "      <td>1</td>\n",
       "      <td>58.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>6.99</td>\n",
       "      <td>1.143700</td>\n",
       "      <td>0.928715</td>\n",
       "      <td>7.13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>2.739439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613273</td>\n",
       "      <td>1.278300</td>\n",
       "      <td>1</td>\n",
       "      <td>44.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.84</td>\n",
       "      <td>0.954159</td>\n",
       "      <td>0.975350</td>\n",
       "      <td>9.99</td>\n",
       "      <td>...</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>2.336756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.117570</td>\n",
       "      <td>1.900670</td>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>2.120322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>77.5</td>\n",
       "      <td>24.4</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.037613</td>\n",
       "      <td>0.956836</td>\n",
       "      <td>9.60</td>\n",
       "      <td>...</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>2.216415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991901</td>\n",
       "      <td>1.683430</td>\n",
       "      <td>1</td>\n",
       "      <td>44.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>12.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>2.604025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_expected_target2  train_expected_target1  category  \\\n",
       "0                0.278076                1.166350         1   \n",
       "1                0.613273                1.278300         1   \n",
       "2                1.117570                1.900670         0   \n",
       "3                0.909774                0.423368         0   \n",
       "4                0.991901                1.683430         1   \n",
       "\n",
       "   agent_1_feat_Possession%  agent_1_feat_Pass%  agent_1_feat_AerialsWon  \\\n",
       "0                      58.8                85.1                     15.8   \n",
       "1                      44.8                71.1                     23.4   \n",
       "2                      46.3                70.8                     21.7   \n",
       "3                      50.2                77.5                     24.4   \n",
       "4                      44.9                75.0                     17.2   \n",
       "\n",
       "   agent_1_feat_Rating  agent_1_feat_XGrealiz  agent_1_feat_XGArealiz  \\\n",
       "0                 6.99               1.143700                0.928715   \n",
       "1                 6.84               0.954159                0.975350   \n",
       "2                 6.77               0.918434                1.118603   \n",
       "3                 6.87               1.037613                0.956836   \n",
       "4                 6.77               0.983691                0.948837   \n",
       "\n",
       "   agent_1_feat_PPDA  ...  agent_2_feattotal_xg_1  \\\n",
       "0               7.13  ...                2.739439   \n",
       "1               9.99  ...                2.336756   \n",
       "2               9.56  ...                2.120322   \n",
       "3               9.60  ...                2.216415   \n",
       "4              12.24  ...                2.604025   \n",
       "\n",
       "   agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "0                     2.739439                        NaN   \n",
       "1                     2.336756                        NaN   \n",
       "2                     2.120322                        NaN   \n",
       "3                     2.216415                        NaN   \n",
       "4                     2.604025                        NaN   \n",
       "\n",
       "   agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "0                   0.473684                   0.473684   \n",
       "1                   0.578947                   0.578947   \n",
       "2                   0.368421                   0.368421   \n",
       "3                   0.210526                   0.210526   \n",
       "4                   0.421053                   0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "0                   0.473684                        0.473684   \n",
       "1                   0.578947                        0.578947   \n",
       "2                   0.368421                        0.368421   \n",
       "3                   0.210526                        0.210526   \n",
       "4                   0.421053                        0.421053   \n",
       "\n",
       "   agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "0                           NaN                 1                 2  \n",
       "1                           NaN                 2                 2  \n",
       "2                           NaN                 0                 1  \n",
       "3                           NaN                 0                 1  \n",
       "4                           NaN                 2                 2  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_expected_target1 = train_expected_target1.rename(columns={\"0\": \"train_expected_target1\"})\n",
    "train_expected_target2 = train_expected_target2.rename(columns={\"0\": \"train_expected_target2\"})\n",
    "train_df = pd.concat([train_expected_target1, train_df], axis = 1)\n",
    "train_df = pd.concat([train_expected_target2, train_df], axis = 1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJHCElVu-906",
    "outputId": "df35fdc8-6e8d-4af7-9ecf-e96d0c76a9c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deleting:  2470\n",
      "Rows after deleting:  2295\n"
     ]
    }
   ],
   "source": [
    "print('Rows before deleting: ', train_df.shape[0])\n",
    "train_df = train_df.drop(train_df[(train_df.train_expected_target2 > 1) &\n",
    "                                  (train_df.train_expected_target1 > 1) &\n",
    "                                  (train_df.category == 0)].index)\n",
    "train_df.drop(['train_expected_target1', 'train_expected_target2'], axis = 1, inplace = True)\n",
    "print('Rows after deleting: ', train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ruuBsKl75SR"
   },
   "source": [
    "## Work with missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc2PbEGDRIjw",
    "outputId": "3042e755-cbf8-4661-ac14-71b4a75e601c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before deleting:  2295\n",
      "Rows after deleting:  2163\n"
     ]
    }
   ],
   "source": [
    "print('Rows before deleting: ', train_df.shape[0])\n",
    "train_df = train_df.dropna()  \n",
    "print('Rows after deleting: ', train_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>agent_1_feat_Possession%</th>\n",
       "      <th>agent_1_feat_Pass%</th>\n",
       "      <th>agent_1_feat_AerialsWon</th>\n",
       "      <th>agent_1_feat_Rating</th>\n",
       "      <th>agent_1_feat_XGrealiz</th>\n",
       "      <th>agent_1_feat_XGArealiz</th>\n",
       "      <th>agent_1_feat_PPDA</th>\n",
       "      <th>agent_1_feat_OPPDA</th>\n",
       "      <th>agent_1_feat_DC</th>\n",
       "      <th>...</th>\n",
       "      <th>agent_2_feattotal_xg_1</th>\n",
       "      <th>agent_2_feattotal_xg_mean_3</th>\n",
       "      <th>agent_2_feattotal_xg_mean</th>\n",
       "      <th>agent_2_featboth_scored_3</th>\n",
       "      <th>agent_2_featboth_scored_2</th>\n",
       "      <th>agent_2_featboth_scored_1</th>\n",
       "      <th>agent_2_featboth_scored_mean_3</th>\n",
       "      <th>agent_2_featboth_scored_mean</th>\n",
       "      <th>expected_target1</th>\n",
       "      <th>expected_target2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>25.1</td>\n",
       "      <td>6.79</td>\n",
       "      <td>0.711201</td>\n",
       "      <td>0.915529</td>\n",
       "      <td>10.74</td>\n",
       "      <td>9.43</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.608046</td>\n",
       "      <td>2.112304</td>\n",
       "      <td>1.608046</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>15.9</td>\n",
       "      <td>7.07</td>\n",
       "      <td>1.094698</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>7.57</td>\n",
       "      <td>13.92</td>\n",
       "      <td>575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479335</td>\n",
       "      <td>2.214160</td>\n",
       "      <td>2.479335</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>48.1</td>\n",
       "      <td>76.9</td>\n",
       "      <td>17.7</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.994530</td>\n",
       "      <td>1.235052</td>\n",
       "      <td>9.77</td>\n",
       "      <td>8.24</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.712261</td>\n",
       "      <td>2.183093</td>\n",
       "      <td>1.712261</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>70.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.77</td>\n",
       "      <td>0.918434</td>\n",
       "      <td>1.118603</td>\n",
       "      <td>9.56</td>\n",
       "      <td>7.34</td>\n",
       "      <td>179.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.675331</td>\n",
       "      <td>2.627794</td>\n",
       "      <td>2.675331</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>50.7</td>\n",
       "      <td>82.1</td>\n",
       "      <td>14.4</td>\n",
       "      <td>6.86</td>\n",
       "      <td>1.124694</td>\n",
       "      <td>0.875939</td>\n",
       "      <td>11.79</td>\n",
       "      <td>10.66</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>2.260683</td>\n",
       "      <td>1.331644</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.046406</td>\n",
       "      <td>1.032989</td>\n",
       "      <td>18.00</td>\n",
       "      <td>8.27</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.684860</td>\n",
       "      <td>4.024907</td>\n",
       "      <td>3.872622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>1</td>\n",
       "      <td>42.9</td>\n",
       "      <td>76.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.61</td>\n",
       "      <td>1.161802</td>\n",
       "      <td>1.066236</td>\n",
       "      <td>16.14</td>\n",
       "      <td>7.60</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.568175</td>\n",
       "      <td>2.000313</td>\n",
       "      <td>2.572016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>6.51</td>\n",
       "      <td>1.000858</td>\n",
       "      <td>1.026472</td>\n",
       "      <td>15.99</td>\n",
       "      <td>7.99</td>\n",
       "      <td>164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.871643</td>\n",
       "      <td>2.496854</td>\n",
       "      <td>2.555157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>1</td>\n",
       "      <td>51.4</td>\n",
       "      <td>79.3</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.037986</td>\n",
       "      <td>1.161401</td>\n",
       "      <td>9.73</td>\n",
       "      <td>10.47</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.904164</td>\n",
       "      <td>2.977092</td>\n",
       "      <td>2.495116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>71.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>6.64</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.931256</td>\n",
       "      <td>13.16</td>\n",
       "      <td>9.72</td>\n",
       "      <td>233.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.945618</td>\n",
       "      <td>3.414186</td>\n",
       "      <td>2.861741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2163 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category  agent_1_feat_Possession%  agent_1_feat_Pass%  \\\n",
       "20           0                      44.0                70.3   \n",
       "21           0                      57.0                84.6   \n",
       "22           1                      48.1                76.9   \n",
       "23           0                      46.3                70.8   \n",
       "24           0                      50.7                82.1   \n",
       "...        ...                       ...                 ...   \n",
       "2465         1                      41.6                76.0   \n",
       "2466         1                      42.9                76.1   \n",
       "2467         0                      41.0                72.2   \n",
       "2468         1                      51.4                79.3   \n",
       "2469         1                      43.5                71.6   \n",
       "\n",
       "      agent_1_feat_AerialsWon  agent_1_feat_Rating  agent_1_feat_XGrealiz  \\\n",
       "20                       25.1                 6.79               0.711201   \n",
       "21                       15.9                 7.07               1.094698   \n",
       "22                       17.7                 6.74               0.994530   \n",
       "23                       21.7                 6.77               0.918434   \n",
       "24                       14.4                 6.86               1.124694   \n",
       "...                       ...                  ...                    ...   \n",
       "2465                     17.1                 6.62               1.046406   \n",
       "2466                     18.3                 6.61               1.161802   \n",
       "2467                     19.1                 6.51               1.000858   \n",
       "2468                     14.1                 6.62               1.037986   \n",
       "2469                     23.4                 6.64               0.865460   \n",
       "\n",
       "      agent_1_feat_XGArealiz  agent_1_feat_PPDA  agent_1_feat_OPPDA  \\\n",
       "20                  0.915529              10.74                9.43   \n",
       "21                  0.938272               7.57               13.92   \n",
       "22                  1.235052               9.77                8.24   \n",
       "23                  1.118603               9.56                7.34   \n",
       "24                  0.875939              11.79               10.66   \n",
       "...                      ...                ...                 ...   \n",
       "2465                1.032989              18.00                8.27   \n",
       "2466                1.066236              16.14                7.60   \n",
       "2467                1.026472              15.99                7.99   \n",
       "2468                1.161401               9.73               10.47   \n",
       "2469                0.931256              13.16                9.72   \n",
       "\n",
       "      agent_1_feat_DC  ...  agent_2_feattotal_xg_1  \\\n",
       "20              218.0  ...                1.608046   \n",
       "21              575.0  ...                2.479335   \n",
       "22              175.0  ...                1.712261   \n",
       "23              179.0  ...                2.675331   \n",
       "24              156.0  ...                1.331644   \n",
       "...               ...  ...                     ...   \n",
       "2465            138.0  ...                3.684860   \n",
       "2466            201.0  ...                1.568175   \n",
       "2467            164.0  ...                3.871643   \n",
       "2468            222.0  ...                4.904164   \n",
       "2469            233.0  ...                3.945618   \n",
       "\n",
       "      agent_2_feattotal_xg_mean_3  agent_2_feattotal_xg_mean  \\\n",
       "20                       2.112304                   1.608046   \n",
       "21                       2.214160                   2.479335   \n",
       "22                       2.183093                   1.712261   \n",
       "23                       2.627794                   2.675331   \n",
       "24                       2.260683                   1.331644   \n",
       "...                           ...                        ...   \n",
       "2465                     4.024907                   3.872622   \n",
       "2466                     2.000313                   2.572016   \n",
       "2467                     2.496854                   2.555157   \n",
       "2468                     2.977092                   2.495116   \n",
       "2469                     3.414186                   2.861741   \n",
       "\n",
       "      agent_2_featboth_scored_3  agent_2_featboth_scored_2  \\\n",
       "20                     0.578947                   0.578947   \n",
       "21                     0.526316                   0.526316   \n",
       "22                     0.526316                   0.526316   \n",
       "23                     0.421053                   0.421053   \n",
       "24                     0.368421                   0.368421   \n",
       "...                         ...                        ...   \n",
       "2465                   1.000000                   0.000000   \n",
       "2466                   0.000000                   0.000000   \n",
       "2467                   0.000000                   0.000000   \n",
       "2468                   1.000000                   0.000000   \n",
       "2469                   1.000000                   1.000000   \n",
       "\n",
       "      agent_2_featboth_scored_1  agent_2_featboth_scored_mean_3  \\\n",
       "20                          1.0                        0.719298   \n",
       "21                          1.0                        0.684211   \n",
       "22                          1.0                        0.684211   \n",
       "23                          1.0                        0.614035   \n",
       "24                          0.0                        0.245614   \n",
       "...                         ...                             ...   \n",
       "2465                        0.0                        0.333333   \n",
       "2466                        0.0                        0.000000   \n",
       "2467                        1.0                        0.333333   \n",
       "2468                        0.0                        0.333333   \n",
       "2469                        0.0                        0.666667   \n",
       "\n",
       "      agent_2_featboth_scored_mean  expected_target1  expected_target2  \n",
       "20                        1.000000                 0                 0  \n",
       "21                        1.000000                 0                 1  \n",
       "22                        1.000000                 3                 3  \n",
       "23                        1.000000                 1                 0  \n",
       "24                        0.000000                 3                 0  \n",
       "...                            ...               ...               ...  \n",
       "2465                      0.444444                 1                 2  \n",
       "2466                      0.444444                 2                 3  \n",
       "2467                      0.500000                 0                 5  \n",
       "2468                      0.222222                 1                 3  \n",
       "2469                      0.333333                 3                 2  \n",
       "\n",
       "[2163 rows x 237 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_target1          1.000000\n",
      "agent_1_feat_ScoredAv     0.385431\n",
      "agent_1_feat_XgAv         0.360820\n",
      "agent_1_feat_DC           0.341588\n",
      "agent_1_feat_pl_median    0.328869\n",
      "                            ...   \n",
      "agent_1_feat_PPDA        -0.213783\n",
      "agent_2_feat_Rating      -0.215384\n",
      "agent_1_feat_MissedAv    -0.260551\n",
      "agent_1_feat_XgaAv       -0.267009\n",
      "agent_1_feat_ODC         -0.290223\n",
      "Name: expected_target1, Length: 237, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix1 = train_df.corr()\n",
    "print(corr_matrix1[\"expected_target1\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_target2         1.000000\n",
      "category                 0.471964\n",
      "agent_2_feat_ScoredAv    0.335948\n",
      "agent_2_feat_XgAv        0.324758\n",
      "agent_2_feat_pl_mean     0.294398\n",
      "                           ...   \n",
      "agent_2_feat_MissedAv   -0.225085\n",
      "agent_1_feat_pl_mean    -0.225340\n",
      "agent_2_feat_XgaAv      -0.241378\n",
      "agent_1_feat_Rating     -0.250496\n",
      "agent_2_feat_ODC        -0.263211\n",
      "Name: expected_target2, Length: 237, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_matrix2 = train_df.corr()\n",
    "print(corr_matrix2[\"expected_target2\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6FEvgOH7tUX"
   },
   "source": [
    "## Split dataset on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "A3QmeYdOEhwI"
   },
   "outputs": [],
   "source": [
    "X = train_df.drop(['expected_target1','category','expected_target2'], axis=1)\n",
    "Y_category = train_df['category']\n",
    "Y_expected1 = train_df['expected_target1']\n",
    "Y_expected2 = train_df['expected_target2']\n",
    "X_train, X_test, y_train1, y_test1, y_train2, y_test2 = (X.iloc[0:int(len(X)*0.8)], \n",
    "                                    X.iloc[int(len(X)*0.8):len(X)], \n",
    "                                    Y_expected1.iloc[0:int(len(Y_expected1)*0.8)], \n",
    "                                    Y_expected1.iloc[int(len(Y_expected1)*0.8):len(Y_expected1)],\n",
    "                                    Y_expected2.iloc[0:int(len(Y_expected2)*0.8)], \n",
    "                                    Y_expected2.iloc[int(len(Y_expected2)*0.8):len(Y_expected2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1730, 234), (433, 234), (1730,), (433,), (1730,), (433,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train1.shape, y_test1.shape, y_train2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3lVH0n2lQK9"
   },
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwxG8mYMlPoG",
    "outputId": "4b90a530-9fb2-4f50-f459-e231bdbe6721"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "test_df = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCXvCiWHPn3F"
   },
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Agent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = KNeighborsClassifier(n_neighbors = 5)\n",
    "model1.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.39      0.31       100\n",
      "           1       0.36      0.41      0.39       145\n",
      "           2       0.30      0.20      0.24       111\n",
      "           3       0.18      0.12      0.15        49\n",
      "           4       0.14      0.06      0.08        18\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.30       433\n",
      "   macro avg       0.16      0.15      0.15       433\n",
      "weighted avg       0.28      0.30      0.28       433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rates = []\n",
    "\n",
    "for i in np.arange(1, 101):\n",
    "    new_model = KNeighborsClassifier(n_neighbors = i)\n",
    "    new_model.fit(X_train, y_train1)\n",
    "    model1 = KNeighborsClassifier(n_neighbors = 5)\n",
    "    model1.fit(X_train, y_train1)\n",
    "    new_predictions = new_model.predict(X_test)\n",
    "    error_rates.append(np.mean(new_predictions != y_test1))\n",
    "\n",
    "plt.plot(error_rates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=61)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = KNeighborsClassifier(n_neighbors = np.argmin(error_rates))\n",
    "model1.fit(X_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.14      0.21       100\n",
      "           1       0.39      0.85      0.53       145\n",
      "           2       0.49      0.32      0.39       111\n",
      "           3       0.43      0.06      0.11        49\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.41       433\n",
      "   macro avg       0.21      0.17      0.15       433\n",
      "weighted avg       0.39      0.41      0.34       433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1, predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for agent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = KNeighborsClassifier(n_neighbors = 5)\n",
    "model2.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.48      0.38       127\n",
      "           1       0.32      0.29      0.31       156\n",
      "           2       0.23      0.20      0.21        88\n",
      "           3       0.33      0.09      0.15        43\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.30       433\n",
      "   macro avg       0.13      0.12      0.12       433\n",
      "weighted avg       0.29      0.30      0.28       433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABKIElEQVR4nO29eXhkV3mv+341qySVppbU7VbPrXa7bWxjGruNA3hgMEMwJ5cQOyGB3BzITTBgkpCYm3M5CUmee8/h3DD6QGxCQjhgQxgcJ3EweMBM7rbbxnjotqVu9aS2W1JrrFKp5nX+2Hvt2lUqSSWpSkPVep+nHql27apaW6X69m//1re+T5RSGAwGg6F28az2AAwGg8FQXUygNxgMhhrHBHqDwWCocUygNxgMhhrHBHqDwWCocXyrPYBiNmzYoLZv377awzAYDIZ1xZNPPnleKdVZ6rE1F+i3b9/O4cOHV3sYBoPBsK4QkVNzPVaWdSMiN4rIiyJyTERuL/H4p0XkafvWJyIT9vbLReQxEXleRJ4Rkd9Y8lEYDAaDYUksqOhFxAvcAbwRGASeEJH7lFJH9D5KqY+69v8Q8Er7bhz4HaVUv4hcADwpIg8opSYqeAwGg8FgmIdyFP2VwDGl1IBSKgXcA9w0z/63AHcDKKX6lFL99u8vAcNASQ/JYDAYDNWhnEC/GTjjuj9ob5uFiGwDdgAPl3jsSiAAHF/8MA0Gg8GwVCqdXnkz8G2lVNa9UUQ2AV8DflcplSt+koh8QEQOi8jhkZGRCg/JYDAY6ptyAv1ZYIvrfo+9rRQ3Y9s2GhGJAP8O/LlS6mCpJyml7lRK7VdK7e/sNM6OwWAwVJJyAv0TQK+I7BCRAFYwv694JxHZC7QBj7m2BYDvAf+klPp2ZYZsMBgMhsWwYKBXSmWAW4EHgKPAt5RSz4vIJ0XkHa5dbwbuUYV1j98NvA54nyv98vLKDb88fvTiMGfG4iv9tgaDwbAmkLVWj37//v2q0gumLv7E93n3q7fwX3/14oq+rsFgMKwVRORJpdT+Uo/VfK2beCrDdCpLIj1rDthgMBjqgpoP9KOxFACpjAn0BoOhPqn5QD82bQf6rAn0BoOhPqn5QD86nQQglckusKfBYDDUJjUT6GdSWb7/3DlOnp8u2K6tm3R2bU06GwwGw0pRM4E+nsrwf/2vJ3nkxeGC7Y51Yzx6g8FQp9RMoG8LB/B7heFosmC7CfQGg6HeqZlA7/EInU1BhqYSBdvPx8xkrMFgqG9qJtADdEVCjMxS9Hoy1gR6g8FQn9RWoG+erehNeqXBYKh3airQd0dCszz6UePRGwyGOqemAn1Xc5CJeJpEOp8zrxV92ih6g8FQp9RUoO+OhAAcn34mlSWesoK+UfQGg6FeqalA3xkJAjActXx6vSq2MeA1gd5gMNQtNRXou5stRT88ZQV4bdtsbAmZyViDwVC31FSg77IVvc680ROxF7Q2kMrmWGu19w0Gg2ElqKlA3x4O4PPkV8fqOjfdkRBKQSZnAr3BYKg/airQezxCZ3OQIce6sX5uarEsHePTGwyGeqSsQC8iN4rIiyJyTERuL/H4p109YftEZML12PdFZEJE/q2C456TrkjINRmbIuDz0BYOACbF0mAw1Ce+hXYQES9wB/BGYBB4QkTuU0od0fsopT7q2v9DwCtdL/EpIAz8fqUGPR9dzUFOj1qNwMdiKToaAwR81vnMKHqDwVCPlKPorwSOKaUGlFIp4B7gpnn2vwW4W99RSj0ERJc1ykXQHQkWKPr2xgABr3WYSRPoDQZDHVJOoN8MnHHdH7S3zUJEtgE7gIcXMwgR+YCIHBaRwyMjI4t56iy6mkOMx9MkM9l8oLcVvbFuDAZDPVLpydibgW8rpRbVt08pdadSar9San9nZ+eyBtBtp1iORJOMTSfZ0BTMWzcm0BsMhjqknEB/Ftjiut9jbyvFzbhsm9Wgy140NTSVZCxmKXq/13j0BoOhfikn0D8B9IrIDhEJYAXz+4p3EpG9QBvwWGWHuDg6my1Ff2YsznQqW2DdmEBvMBjqkQUDvVIqA9wKPAAcBb6llHpeRD4pIu9w7XozcI8qWn4qIj8B/hm4QUQGReTNlRv+bHRhs6PnpgCsrBuvsW4MBkP9smB6JYBS6n7g/qJtnyi6/xdzPPe1Sx3cUuhoDOD1CEdfthJ9OtwevVH0BoOhDqmplbGQ7x37wsuWonenV5pAbzAY6pGaC/RgFTfT9W46CtIrTa0bg8FQf9RmoLczbwDam1yTsdlFZX0aDAZDTVCbgd7Opfd7heagD79XAGPdGAyG+qQmA71uQNLRGEREXIreWDcGg6H+qMlArxV9e6NVtTLo9QJG0RsMhvqkJgO9LoPQ0WQFepNeaTAY6pmaDPR6MlYreuPRGwyGeqY2A71W9I3WT5/Xg0dM9cq1ynQyw0NHh1Z7GAZDzVKTgb6jMcj2jjCXbI442wI+jymBsEa5+/HT/N5XDzNsN3U3GAyVpawSCOsNr0f40ceuK9jm93qMdbNGefGcVa5idDpFVyS0wN4Gg2Gx1KSiL0XQKPo1S/9wDICJeHqVR2Iw1CZ1E+gDRtGvSZRSHHMCfWqVR2Mw1Cb1E+h9JtCvRV6eTBBLZgCYmDGK3mCoBnUT6Et59KOxJJPGLlhVtG0DxroxGKpF3QT6gM8zK73yw/f8gtu/+8wqjcgA0D9kTcSKwMSMsW4MhmpQk1k3pSiVXjk8lWQ0ZoLLatI/FGNDUwCPiLm6MhiqRN0Eer/XQ7LIuplJZ4mnTOni1aRvOMruribGplOMm8lYg6EqlGXdiMiNIvKiiBwTkdtLPP5pEXnavvWJyITrsfeKSL99e28Fx74ogiWsm5lUlrHplJmkXSWUUhwbirGnu5nWcMB49AZDlVhQ0YuIF7gDeCMwCDwhIvcppY7ofZRSH3Xt/yHglfbv7cB/BfYDCnjSfu54RY+iDEqlV2o1PxJLsrm1YaWHVPecm0oQTWbo7Wri3GSC02Px1R6SwVCTlKPorwSOKaUGlFIp4B7gpnn2vwW42/79zcAPlVJjdnD/IXDjcga8VIqzbpRSzKStQG+W3q8O/UNWxk1vdzOtYb9R9AZDlSgn0G8GzrjuD9rbZiEi24AdwMOLea6IfEBEDovI4ZGRkXLGvWiKJ2MT6fzvQ1PJqrynYX767Iyb3q4my7oxWTcGQ1WodHrlzcC3lVKLmuFUSt2plNqvlNrf2dlZ4SFZBHwe0i5Fr9U8wEjUKPrV4NhwjPbGAB1NQVoa/CTSORJpMzluMFSacgL9WWCL636Pva0UN5O3bRb73KpSrOjjqYzzu1H0q0PfUJTeriYA2sJW7wBj3xgMlaecQP8E0CsiO0QkgBXM7yveSUT2Am3AY67NDwBvEpE2EWkD3mRvW3ECRemVM660ymGj6FccpRT9wzF6u61A3xr2A2bRlMFQDRbMulFKZUTkVqwA7QW+opR6XkQ+CRxWSumgfzNwj1JKuZ47JiJ/hXWyAPikUmqssodQHsUrY93WjVH0K8/QVJJoIsOe7mYAWhvsQG8UvcFQccpaMKWUuh+4v2jbJ4ru/8Ucz/0K8JUljq9iFKdX6tTKcMDLcNQE+pWmf9iaiN1tWzctYRPoDYZqUTe1bvxeDzkFGVvVa0W/raPRpFeuAk5qZZet6B2P3lg3BkOlqZtAH/BZh6onZLVHv2NDmNHplOknu8K8NDFDg9/LhiYrwLc5Hr1R9AZDpam7QJ/OWFMI2rrZ1tEIwIixb1aUoWiSrkgQEQGgwe8l4PUY68ZgqAJ1F+iTWSvAa+tme0cYwPj0K8zwVIKu5qBzX0RoCfuZNFk3BkPFqZ9A77WUo56QnbHz6LWiHzI+/YoyEk3OagTe2mDKIBgM1aB+Ar22brKWdTOTsgL+NqPoV4WhIkUPVi69KVVsMFSe+gn0Xi+QV/TxdIaAz0NXcwiPmMJmK0ksmWE6laW7WNGbUsUGQ1Wom0Dvn2XdZAkHvHg9woamIMNm0dSKoU+qsxR9g59Jk3VjMFScugn0+fRKezI2laXBb6n8rkiQIVMGYcXQNtlsRW88eoOhGtRfoNfpleksDQEr0Hc3h4yiX0GG5lL04QAz6aypYGkwVJj6CfTewgVTCdu6AUvRm8JmK4des1CcddNi17sx9o3BUFnqJ9A7it6ejHVbN80hszp2BRmaShD0eYiECkstmVLFBkN1qLtAr4O5Zd1YgaYrEkQpOB+bbd/0DUX5l6dXpYR+zTIcTdIdCTmrYjVOqWKTYmkwVJT6CfTeQkWfSGVp8FvbupstC6HYp1dK8dFvPs3Hv/vsCo609imVQw9568bUuzEYKkvdBHp/UaCPpzOEXYoeZq+OffDoMM+/NEU8lS0ocWxYHlrRF6MV/aSxbgyGilI3gT7o1LrJ59E7WTd20HGvjlVK8dmH+pz70YQJPpVieCpJZwlFrz16szrWYKgsdRPo89UrXYHenoztaAwgRatjHzo6zHNnp3jNrg4AphIZDMtnOpkhlsyUVPThgBe/V4x1YzBUmLoJ9H5XeqVSing6n17p83qs1bG2orfUfD9b2hv4nau3AzBlgk9F0H/jUh69iNDSYMogGAyVpqxALyI3isiLInJMRG6fY593i8gREXleRL7h2v7fROQ5+/YblRr4YnGnVyYzOZTCsW7ACjzPDE7yrcNn+PSD/Tx7dpJbr9tNh90YY6rC1s0vTo8znay/qwR91VRK0YPl0+tSxdmc4tG+EVxtiA0GwxJYMNCLiBe4A3gLsA+4RUT2Fe3TC3wcuEYpdTFwm739bcAVwOXAVcCfiEikguMvG59HELHSK3V3KW3dAOzpbubIy1P86bef4XMP9bNjQyO/dkUPkZA1QTg1U7mgnEhn+fUvPcbdj5+u2GuuFxxFH5mt6KGwVPE3Hj/Ne7/yOD96cWTFxmcw1CLlNAe/EjimlBoAEJF7gJuAI6593g/coZQaB1BKDdvb9wE/VkplgIyIPAPcCHyrQuMvGxFxGoTH0/nG4JpPvetS/vhNe5z77Y0B/F4PkQbrT1RJRT+dzJDJqbrsajVX+QNNazjA2YkZkpksX3zkGAA/P36e6/Z2rdgYDYZaoxzrZjNwxnV/0N7mZg+wR0R+JiIHReRGe/svgRtFJCwiG4DrgC3FbyAiHxCRwyJyeGSkeuot4PWQzOQVfcil6H1eDz1tYeemUy/zir5ygT5pTwjXoxc9Ek0S8HmcnPliWsN+JuMp/vnwIC9NJmhvDHBwYGyFR2kw1BaVmoz1Ab3AtcAtwF0i0qqU+gFwP/Bz4G7gMWBWxSql1J1Kqf1Kqf2dnZ0VGtJsAj5PgXWjg/l86FLGlVT0umhXPaYR6sVSxatiNa0NfsbiKf7nI8e4Ymsr7zmwjedfmqz4HInBUE+UE+jPUqjCe+xtbgaB+5RSaaXUCaAPK/CjlPobpdTlSqk3AmI/tioEfJZ1M1PCupkLEaE55CNawfRKR9HXYSbPXIulNK1hP4l0jpcmE9z2hj0c2NlOTsHhk0bVGwxLpZxA/wTQKyI7RCQA3AzcV7TPvVhqHtui2QMMiIhXRDrs7ZcClwI/qMzQF4/f6yGVzRG3+8W6rZv5iIT8FbVutKKvxxWgc5U/0LTYi6ZeubWV1/Zu4IqtbQS8HmPfGAzLYEHvQimVEZFbgQcAL/AVpdTzIvJJ4LBS6j77sTeJyBEsa+ZjSqlREQkBP7Ev06eA99gTs6uCo+hT5St6gEiDr6ILpvKKvv6sm+Foktf2zm3PbbLV/m1v2IOIEPJ7uXxLKwcHRldqiAZDzVFO1g1KqfuxvHb3tk+4flfAH9k39z4JrMybNUHAa3v0i7BuoHqKvt4mY2dSWaKJTMnyB5rr9nbxHx95LRdtymfhHtjZzhceOUY0kaY5VHoS12AwzE3drIwFS9EnMzniJfLo5yMS8ld0MlArencGUD2gm7vM59F7PVIQ5AEO7Oywffrxqo7PYKhV6ivQ23n0WlE3LMa6qfCCKU092TdDU3OXP5iPV25tw+8VY98YDEukvgK9nV65VhQ91Jd9U46iL0VDwPbpT5gJWYNhKdRdoE/ZgT7g9eDzlnf4kQY/8VS2Yq0Gk25FXweBPpXJkcrkeHli/lWx83FgZwfPnZ005aINhiVQ1mRsreD3imPdlGvbAE5v02giQ3tjYNnjcCv6yRq3bj7zYB+febDfuR/0eZwGI4vhwM4OPv/wMX7af563vGJTJYdoMNQ8dRXoAz6vVesmlSnbtgFL0YNVBqESgd7t0Y/XuKJ/+swEF7SE+K0D2wCreNxcq2Ln48od7Wxpb+CLjx7nxks2Luk1DIZ6pb4CvddDOquYSefKTq0EV72bCtkG9eTRD00luWhThA9et3tZr+P3erj1ut382Xee5UcvjpgiZwbDIqgzj17slMZM2atiwa3oK5N5k0hb3a0CPk/NZ92MRBN0LXLydS5+7Yoeetoa+MyDfaZGvcGwCOor0Hs9pDJZ4qns4hR9hUsVJzM5Qn4PrQ3+mi6DkM7mOB9LLWnytRR+r4cPXrebXw5O8qM+U6PeYCiX+gr0Pm3dLHYytrKlihPpLEGfl9awv6atm/MxK29+semU8/F/XNHD5tYGPvtgv1H1BkOZ1F2gT9llipc0GVtxRR+o6VLFS10gNR8Bn6Xqnz4zwc+PmwVUBkM51FWg93s9ZHOKWDKzKOumMeDFI5X16IM+Ly1hP5M1XKp4of6wS+Xtl1nplc+dnazo6xoMtUpdBXrdIHxyJk1DGU1HNFZNen/FFutoRd9W49bN0AL9YZdKc9BHOOB1+s8aDIb5qa9Ab6+EjSYWl0cPlS1VnPfoAzWddTMylcAj0FGBtQduRISu5qDTf9ZgMMxPfQV6X/5wF2PdQGVLFSczOYJ+q29qIp0rWEBVSwxHk3Q0BcsuNbEYuiIho+gNhjKpr0DvCjiLybqByhY2S6RzTtYN1O6iqaGpBN0Vtm00Xc1BZw7AYDDMT30FepeiX5J1U6HJ2GQm62TdQGGp4q8dPMXjNVKlcTiapKu5shOxmq5mS9GbFEuDYWHKCvQicqOIvCgix0Tk9jn2ebeIHBGR50XkG67t/93edlREPierWKRk2dZNpSZjbUXfVqTosznFX//bEb5+6FRF3me1GZpKVk3Rd0eCxFNZYslV60xpMKwbFkw9EREvcAfwRmAQeEJE7lNKHXHt0wt8HLhGKTUuIl329tcA12A1BQf4KfB64EeVPIhy8S/HummopEdvKfqWokB/ZixOMpNjbHr9T9BmsjlGp5N0VkvR2yeQ4WjStBc0GBagHEV/JXBMKTWglEoB9wA3Fe3zfuAOpdQ4gFJq2N6ugBAQAIKAHxiqxMCXwrKsm5Cf6VSWTAVq0uc9esu60aWK+4aiAJyPrf9Afz6WQimqp+jtE4jJvDEYFqacQL8ZOOO6P2hvc7MH2CMiPxORgyJyI4BS6jHgEeBl+/aAUuro8oe9NILLUvT5mvTLJe/RW0pUlyruH44BMDa9/rNJdDepqnn09glkxGTeGAwLUqnJWB/QC1wL3ALcJSKtIrIbuAjowTo5XC8iry1+soh8QEQOi8jhkZHqFavyL9Ojh+WXQcjmFOmsIujzEg548XvFsW76bUU/Np1a95OMuvxB1bJuIkbRGwzlUk6gPwtscd3vsbe5GQTuU0qllVIngD6swP+fgINKqZhSKgb8B3B18Rsope5USu1XSu3v7OxcynGURUF6pX9xpfgrVao4mbFy5kN+DyJCazjgWDda0aeziug6n2SstqJvDvoI+T0MTxlFbzAsRDmB/gmgV0R2iEgAuBm4r2ife7HUPCKyAcvKGQBOA68XEZ+I+LEmYlfNuinw6Bet6CtTqjiRtjz+oD2W1garDEI2pzg2HHNWkY6uc59+aCqJCGxoquyqWI2I0G0WTRkMZbFgoFdKZYBbgQewgvS3lFLPi8gnReQd9m4PAKMicgTLk/+YUmoU+DZwHHgW+CXwS6XUv1bhOMrCnXWzaOumoTKlivOK3np/Xap4cNzKuLlqZzuw/n36kWiCjsbqrIrVmDIIBkN5lOVfKKXuB+4v2vYJ1+8K+CP75t4nC/z+8odZGYLLUfQVKlXsKHq/NZaWhgCD43H6hyzb5sDODu5/9lxNKPpq+fOarkiIoy9NVfU9DIZawKyMLRPHuqmUR++z3r/NLlXcN2xNxF61owNg3efSD0cTFa1DXwqj6A2G8qivQG/bCH6vFNg45dAY8CHCsksVFyt6bd0cG4qxqSXEto4wAKPrPdBPJSteh76Y7kiIabM61mBYkLoK9Dq9cjGNwTUej9AczJcqTmdzS2p8kUwXKvrWcICZdJbnXppkd1cTIb+VdrmerZtsTnE+llwRRQ+Y4mZzkMsp05zFANRZoNeKfrETsRp3GYT//wd9vOMLP120xZLIFHv0lvffNxRjT3czAB1NgXU9GTsaS5JT+Vz3aqGvGEzmTWkeeXGYt3/+pxyz03YN9UtdBXq/16qnFl5Edyk3urDZ2HSKf3rsJDm1+AU7WtEHffmsG01vVxMA7Y3BdW3dVKNXbCn06xufvjRnJ2YAq4aSob6pq0AvIgS8niVZN5AvVXzXTwaIp6yAvVRFH7IVfVs4n2fe220F+o7GwLqejNWLpart0esrBlMGoTTa/tOfh6F+qatAD1bmzZKtm5CfwfE4X/35SS6+IAIsftK0WNFr6wZgd5dl3bQ3Bta1R+8o+iqnV0ZCPoI+j1H0c6DFwpBZPVz31GWgX2xqpSbS4OelyQQz6SyfePs+AMZii/sSFXv02rrpjgSdoG959Ou33s1wNGGviq1uoDerY+dHB3qj6A31F+i9nkUvltLowmZvv/QC9m9vxyMLK/qZVGE/WCfrxp/PugGciViwrJtUNrdu0waHppJ0NAYWncK6FEwu/dyct0XISin6TDbnrBMxrC3qLtBHGny0h5dWf2VDcwAR+PD1u/F6hLZwYN5Af2p0mkv/8gGeOj3ubEtmCmvdNAa8NAV9XLQp4uzT3mgp4fXq0780MVO1YmbFGEU/N3lFvzJ/n7+5/yjv+fKhFXkvw+JYWvrJOuZL73kVTaGlHfZ7DmzjV3ZvoLc776WPzeOlP31mgnRWcfL8NFdsbQMsRS+ST/UUEb71+1ezua3BeZ4ubHY+lmJbR+OSxrpaZHOKp06P8/ZLN63I+3U2B3m0zwT6UjiBfoWueI6PTPPM4CRKKVaxY6ihBHUX6Hd2Ni35uZGQn0t7Wp377Qtkx+j6Ne5CaIlMjqDPU/BF2HdBpOB57XagX4+K/ujLU0QTGQ7s7FiR9+uKBIklM8RTmSWnzdYi2ZxiPJ5CxMpKyuUUHk91g+9kPEUyk+N8LEVnlVNrDYuj7qybStLRFOD8PAubdGvAKVdXqmQ6u2B6Z0eTDvTrT6keHBgF8jV7qo1uKWjq0hcyEU+RU7CtPUwmpxiLV180TNiCRufvG9YOJtAvg47G4LyqW69ILFD06VxBFc25XhfWZ72bgwOjbO8Is7FlZTx6ncJpJmQL0f+Xeu5nJU6EulPa4LhZoLXWMIF+GbQ3BpiIp0s2DE+ks5wcnQYKSxtb/WLnV/QNAS8N/vVX7yabUzx+YmzFbBswZRDmYrQo0A9VOcUym1PO//nguFH0aw1jai4DbbGMx9OzPMkT56fJ2Wnw7tLG5Sh6WNj/X4scfXmKqRX05yFv3ZRS9H/49Se5cns777tmx4qNZ61QrOhHqqzop2bS6GUfS1H0L56L8ht3PkYiPTs9M+D18A+/+2peta19ucOsW0ygXwbuSdPiQK/9+UjIt2hFD1YLvvVm3Tj+/M6V+0JGGny0NPgZOD9dsD2RzvL9586Ry1GXgV7/7+zdaGWIVdvamnDZk0tR9D88co6JeJr3v3YHHleiQiKd5auPneLIS1Mm0C8DE+iXgeOlx5JAc8Fjx4ZjeAQu29LKuGsibDGKfmSRq25Xm4MDY2zrCLOppWHhnSuEiLCnu4l++8Sq0VdUo+twQrsSjNr/OxtbQrQ0+KtubU3Y/+MNfu+SAv3BgTH2bmzmz9+2r2C7DvTuhAbD4inLoxeRG0XkRRE5JiK3z7HPu0XkiIg8LyLfsLddJyJPu24JEXlnBce/qmjrppTy7huKsr2jkY7GQIF1U66ib28Mzpujv9bI5RRPnBzjwApl27jZ3dVM31CsoGSEvqJab1dFlWJsOkVLgx+/10N3pPqrh7Wi33dBhLPjM4sq35HK5Dh8qvTcTsjvJejzLLuFZ72zYKAXES9wB/AWYB9wi4jsK9qnF/g4cI1S6mLgNgCl1CNKqcuVUpcD1wNx4AeVPIDVZL589/7hGL3dTVYN+8Tism5Ap26un3o3R89NMTmT5sCulb+83tPdxORMuuAKSGc8rbd5jkoxOp1yFt51NVd/9bBW9JdcEGEmnV3U3/2ZwQkS6dyccztWHwij6JdDOYr+SuCYUmpAKZUC7gFuKtrn/cAdSqlxAKXUcInXeRfwH0qpmsm9agtbJRGKVWMyk+XUaJzermarhv1M2gnYyUyWYBmKvqMxQCqTYzq1PmqHHBwYA1Yuf95Nr13189hQvsGGVvRzZUXVOmOxlCNEuiLBqq+O1amVF29uARbn0x86Yf3vXLmjtEgonucyLJ5yAv1m4Izr/qC9zc0eYI+I/ExEDorIjSVe52bg7lJvICIfEJHDInJ4ZGSknHGvCXS9m+KFTSfOT5PNKVvR+8gpnIC9GI8eWDf2zaGBUba2h7mgdeX8ec0eu45/n8un73d1VRqPr80g8T8eeJFHXiiliZbP2LQr0DeHGIklq3p1OBFPIwL77CyfxQT6gwOj7N3Y7Iy3mOaQv2AtiuYv//V5DtkJAIb5qVQevQ/oBa4FbgHuEpFW/aCIbAJeATxQ6slKqTuVUvuVUvs7OzsrNKSVoVTteF36QCt6yC+aSmZyZXn0ef9/7U8m5nKKQyfGuGoORVZtOpuDREI+J7jrK6qdnVadoLX4N1RKcddPBvjXZ16qyuuPTifpsMtEd0eCpLOqqie8yZk0kZCfrXZz+3JTLNPZHIdPjs+bkmvZn4XWTTKT5R9+dpIfHhla+qDriHIC/Vlgi+t+j73NzSBwn1IqrZQ6AfRhBX7Nu4HvKaXWprRaBu2Ns9Mg+4eieAR2djYSsWvMR+1/1GQ6W6ai1xk9a1/Rv3AuyuRMmqt3rbxtAzrzptk5weorKh081uJV0XQqSzKTq8rnm8tZQd3t0UN1UyzH4ylaw34iIT+RkK9sRf/M4CQz6ey8IiES8hEtUvST9n1j6ZRHOYH+CaBXRHaISADLgrmvaJ97sdQ8IrIBy8oZcD1+C3PYNuudUm3/+odjbOtoJOT35hV9YpGKfh0VNsvnz69OoAerDWPfcBSllBPwdaBfi5k3+uRTjc93ciZNNqccK6TbLhNRzQnZiXiaVlvU9LSFy1b0+n9nLn8emJXQoN8PMJO0ZbJgoFdKZYBbsWyXo8C3lFLPi8gnReQd9m4PAKMicgR4BPiYUmoUQES2Y10RPFqF8a86pVaw9g1FnUbfkQZrqcKU/eVLZcvPuoG1GaSKOXRilC3tDWxeBX9es7urmYl4mvOxlHNFtX+bVRp6LZ4stZ1UjbHp/xn9P7QSin5iJk2L3eehp62h7MJmBwdGubC72bGZSmElNGQK5hicQG8UfVmUtWBKKXU/cH/Rtk+4flfAH9m34ueeZPbkbc3Q0RRkPJ4im1N4PUIqk+PkaJwbL9kIUKDoU05j8IUVfTjgI+T3rPkKltqff+NF3as6Dj0h2z8cpX84xvaORrojISsrag0uPNMBfnQ6WfH67fp49YI+Xfitmk3UJ+MptrVb/nxPW5ifHju/4HGlszmePDXOu17VM+9rRxp8pLK5gqthnc5pAn15mJWxy6SjMYBSlke5oSmYz7ixU/60Rz81k3HqeJSj6K3XDq55j/7FoSgT8fSK1rcphf579w/F6BuKsrurac4uYD96cZhkJsebL95YlbGkMjm+9OhxfvOqrXP2zdWfayKdI57K0hgs/VU8ODBKNJHhjfsKT6R9Q1GePj3Bu1+9ZdZz9ElEWzeWhehzFH0ineXOHw/wO1dvc1pZLpeJmbTT/7inrYF4Kst4PE17Y4AjL03xtYOnZmX9RBMZ4qnsgv877oQGJ9DbHn3UrJgtCxPol4l70dSGpiC/HJwA8s1EmkN56ya5CEUPcOHGZn7cP8JMKrvkPrfV5tAq1LcpRXckSHPIx5GXpjg5Guctl1gdrkpZa5/+YR/9wzF++mfXz5nStxy+efgMf/vDPpqCPv7PXyldZ8d98hmbTs0Z6O945Bhnx2dmBfqvPXaKrx86xX+6YvOs3rzF1g3YLRftwmb/6+Ap/vaHfWzf0Mg7Lrtg8QdYRDanmJxJOyeNHrtb2uB4nLawn/9y77M899IUbfaJwM3ejc1cs2vDvK/viKVEmi67Wqmj6EukXRpmYwL9MtGTpqOxFHRbCqy9McBuu5OV3+shHPAylUgvWtH/wbW7+PUvPcbXD53iP792Z3UOYJkcHBijp62Bnrbwqo5DROjtauKhF4acNQxQOitqcHyGeCrLXT8Z4M9u3FvRcSQzWb74yDGgMJe/GLclNzqdYkt76b/f+Viq5CTq0FSCnIJzk4lZz9UntjaXWu+KBBmKJkiks/zdj608iViF1HA0YVWudE/GgvV3npxJ89TpCf7qnZfw2we2Len1I7ZYmnRNvOY9+oxpXVgGph79MtGTSPrLdWjAyid3t23Tk0mLVfSv3t7ONbs7+NKjA8yswRWylj8/uuq2jWZPdzPnbUtEWzkbmgIFHn08lWF0OoXfK3z15ycrPhn6z4cHeWkyQSTk49hwdM79ChX93N752HSSWDLDdLIwKA/Zwf9MieyWsekUkZCPgEtQdDdbiv7rh047Xn20Qv62DrrautnsUvSfebCfTS0h3r1/fh9+PtyK3nlPW8lnc4r4GvxurDVMoF8m+tJ/dDrJmbE4ZydmZuUEN9tLuBer6AE+csMezseSfP3QqcoNukL0DUcZXwP+vGa3nemk1zDAbOvmJTsb5Pdft4uZdJYv/2Rg9gstkVQmxxd/dJxXbm3lbZdeMKvQmpvRWMoJjOfnmIdRSuUbfBep+hHbby+Vr34+lpyVxdIZCTIcTfClR49zYGc7HoFYsjKKXgddfTwtDVYu/XeePMuTp8b5w2t3EfQt3XrUHr3bj590Lf4yE7ILYwL9MtG+42gs5eQEHyhaOKTzgBer6MHKL37Nrg7+7scDJZsyrCaHnPo2a6NO+J5uS8XrNQxgLTybsFNbAc7YgfG6vZ287RWb+OrPTzJeIVX/7ScHOTsxw21v2FOy0JqbsekUe+yrjrmuKqYSGdJZa9zu1MhcTjmB/2yJQO8uf6Dpbg6RzipGoklue8MeGoO+ik1k6jLcLQ3599zcFubFoSgbI6GSE8aLwZ2irJmYyf/NTC79whiPfpn4vB5aw37GplMMjs/QFvY7X2BNJOTjfCy1JEUP8JEbevmNOw/y9UOn+b05JveWQiab47tPnWU6Nf8XxSPCW1+xaVZzlYMDo2xubZjTX15ptC+vlT3MzorSCnhza5gP39DLvz/7Ml/+6QAfe/PivfpkJsv3njrLjP253vXjAS7f0srrejfgtT3jY0MxJ4/dzdh0iqt2tvP0oGfOQO/e7lb04/EUGfvEVUrRj5Xw/HWK5VU72jmws4NIyF8xRa/VtXuytaetgaMvT/GH1y1PzQOzFh0CjE+nCfo8JDO5WYr+ubOTBeUYDCbQVwRtD/xycIKrdnQU+PNgKfqB89NLUvRgrTg9sLOdLz16nN+6auuinz8X3zx8hj//3nNl7fvS5Awff8tFBdueOj3O1WvEtgHYGAmxs7OxYEzOwrOYDvRx/F6hqznIxpYQN+zt4t5fvLSkQP+TvvPc/t1nnfsi8N/fdZnTDAWsNMjX7C7MKlFKMTqdZENTkA0laiVp3N69u/rkkKstYKkVqKPTKS7f0lqwbe/GCOGAlz9584UANAV9FZuM1Rkw7lTNy7e0cmw4xrv3L0/Ng/V9Cfg8Bcp9cibN1vYw/cOxWZk3t33zaXq7mvjie1617PeuFUygrwAbGoM8c3aCwfGZkopblypeqqIHy6u/5a6D3P34aX63Aq3xUpkc//MRy0/+h/e9et59f+PvDtJ3rnBicXImzdBUkr12tcK1gIjw8B9fW7DNPYcCzQyOz7C5tcE5GV++pZUHjw4TS2ZomiPFcS5enrTU9IN/9Do2NAXxez1OmmRxoTU38VSWRDpHe2OA9qbAnEXX3CcAt6Iftht9b20Pz1L0uZxifDpVkFoJ1lXOc3/xZue4m0K+inv0OjsG4IPX7eYPXr9rluhZKpFQYRmEiXiKvRs7rEBfpOiHphI0rtF05NXCePQVoL0xwJkx6wtXamIy0mD5oTrQL0WRX72rg6t2tPPFHx2viFev/eSP3NBLazgw723PxuZZAUtnlPS6bJK1iF4dqm2QwfGZglTQXtvXPz5PKuRcDEeTeAR2bGiiNRwoyIV3Cq2VeF33gqb2xuCc1o3OzAn4PAUevc6Hv2JrK+emEgX19qcSaTI55RTFc+MOuk1BX0WzbppDPnxF+fyVCvJg16S3Tyi6T4O2p9xKP5XJEU1kqt5oZb1hAn0FaLfVU2vYz4XdzbMej4T8ZHLKSUNbiqIHuO0NexiOJrnn8dNLHyzWl+GOR45x+ZZWXr9n4bLQe7qaGByfKUjx04XD9pQ43rVEcRews+MzzoIeyJ+o+obmToWci6GpBBuagnjnCGi9di/b4swbZ0FTY4COea0ba/ue7iYnuENe0V+xrY1sTvHyZP4k4H7t+WgK+YhWStHH8xlE1aLZVapYV67MB/r8CUv/zUaiSXK59dGdbSUwgb4C6C/VldvbS6oYnQesMzDK6TBViqt3dXDljna++OjyVP13nrLV/Bt6y1pooic5j4+4OzjFaPB7V7WQWTm0hf2I4EyGn48lCwL91vYwAZ/HaT24GIajSbojsydaNb1dzYzH07MWbGnvvd0O9HMq+liKxoCXre1hhqKFHn1Lg59d9qI8t31TXP5gLpor6dHPpGltqPwKYzduRa/nBDqbgzT4vQXWjbbBMjnFWHxtlw9ZSUygrwA60M/Z89LOGtATaktV9AC33dDL0FSSzz/cz2PHR3ns+GjZJWEhr+Yv29LKtWWoecjbG32uVn39w1Y9mUpenlcDn9dDa4OfsemkExDd1o3P62HnhsYlKvokXc1zV13sLdH5CvJ58xuagrQ3BZhJZ4mXyHwam07S3hSwOkQVKfruSNA5yborReqrg2KPvpjmOTz6wfE46UW2XpyIp6uu6N2lip28/QY/kQZfgXXjPmmWW61zJpXl4MCo831yC5pawUzGVoCtHWFE4LW9pWt26DxgR9EvI9BrVX/HI8e545HjgKVsDn38hrKC7nefGmRwfIa/uumSspeNb2sPE/B66Het9OwfivGaVWo0slh0VpQ+IboVPVj201Onxxf9uiPRxKzsluLXBatR+Wtc9VzcqttdQiPcXvh1HJ1O0d4YpCsSJJrMEE9lCAd89gkmxKZWqzqn+0SvF4QVp8IW0xT0E09lnaqrYKWLvunTP+bW63fzh9fuLvOvYFkp1U6x1avLIb8Sty0cmDVJW5ySenEZr/3pB/u488f5hXMBn4enP/FGwoHaCY9G0VeA6y7s4tE/uc5RvsXkFX2SoM+zrLocIsJdv72fu99/gLvff4AP39DLSDRJ3zzL7TXpbI4vPHKMS3tauPbC8ls2+rwednY2Os23pxJpzk0l2N29tidiNboKaClFD5ZPXzwHsRDpbI7R6dS8ir6r2Sq0Vqzox6ZTBH1WDaT2osliN6OxFB2NAScPX/v0I9EkXZEgQZ+X7uZQgXVz+NQYm1sbSubuu2myM2Tcqn4iniaeyvLjvsX1bZ6Ip5w6N9Ui0pBvEJ5P5/TPakriXmVcbkP0n/Sf5/Itrdz9/gN85IZeUplcyYVo6xkT6CuAiMy7OMPt0VciB74l7OfqXR1cvauDX7dreR88vnCT5O89dZbB8RluK9Obd7O7q8k5mTgTsV1reyJW09FkFTYbHJ9xcujdOJk3i7hkPx9LohTzevTFLQ41OoCLiGOxlAr0Y9PWfu4OUUophqMJJ5D3tDU4il4pxcGBsbIqiTbbGULRgpRF6/enTk+UPQeUcypXVjnQh/ykMjkS6awzGdsStkotuFf4jk1bmVBAwQT2XEzEU7xwborr93Zx9a4OXmfbmYtpbr4eMIF+BdCliifi6WXZNqXY0h6mp62BQyfG5t0vnc3x+Uf6ubSnhesu7Fr0++zpbrarPmbyqZXrRNFr6+bsxAwXuHLoNXkvvfxAr4PIfIoerKuF4oneUdt7B1f106JAr+vcaI8eLM95PJ4mnVVO8LcCvRWU+odjjE2nyqo9VFrRW2NIZXL88szEgq8BVv2ZnLLq21QTd+/l8XgKr0doDvosRV+UddPeGKQ17C+YwJ6Lx0+MoVR+fm2LqyBbLWEC/QrQ7FpIUqlVrW6u2tHBoRNj86aTfe8XZzkzZuXNL8U66u1qQik4PjxN31CMkN+z6qWJy6WjMcB4PMXp0elZ/jyUnoNYCD3RN5+iB+tKaHQ6VVBB01LqVqB2FnQV1cSJJTOksjnbuskrep1amVf0YV6etHLpdW+AclYr68Vh7sybCVfAPDgwv3DIP2d2SeRqoBdjTSXSTMTTtDT4ERHbo88fQ97uCpal6A8OjBH0ebhsSwtgTZAHfJ76VPQicqOIvCgix0Tk9jn2ebeIHBGR50XkG67tW0XkByJy1H58e4XGvm4I+ryE/B7798qfWw/sbGdsOjVrcc7kTJpxO8h84eFjvGJzC9fvXbyah7y9oVv17epsmjN/fK3R0RREKTh6LkpP6+yTk56DKLZY5kMvyNE1ZOZij/N3y7+2DkZgBdyAd3a9G509o9VpwOtheCrhlD/Qin5zWwPZnOLcVIKDA2Nc0BIqeTIrRiv6aAlF39EYcAr0abI5VbISZ3GJ4mqR79SWLuhmZWXdpJ2x6YJu3ZGQU8p5Pg4OjHLF1janHo/HI/S0NqxYoFdKrUi+/4JRR0S8wB3AW4B9wC0isq9on17g48A1SqmLgdtcD/8T8Cml1EXAlcBwZYa+vtATstVQ9Pqy89CJ/JfzH392gsv+8ge88q9+yKv++kFOj8WXrOYBtnWE8XuFvqEY/UPRNb9Qyo1WzalMbs4g2NvdPKei/49nX2b/X/+wIAVyeCqBRxZemKRtoRdennK2uatLap++2Lpxd4kSETqbg5ainypW9NbxnBmb4eCA1RugnM9YK+QCRW8H7Tfu6+ap0+MkM5ZPn87meMtnf8yf3zu7LtK4a2K0muQLm2WYjKedyV+9GFEXlhu17a7O5qBTynkuJuNpjp6bmmV1bXbNe1SbD3ztSW69+6mqv0858vJK4JhSakAplQLuAW4q2uf9wB1KqXEApdQwgH1C8Cmlfmhvjymlasv8KhOtSKqh6Le0h9nc2uCosJlUli/YufJ/8av7+Itf3cdnb76cGy5ampoHq1PWzg1N/OL0OC9PJgoqRK513MG4p32OQN/VxJmxmZL57M+cneR8LFWg+IejVs334mX/xWyMhNjUEuKJU1b6ZjyVYSaddTx6KN3ucKxohWt3JMjQVGLWlYS2zx7tG2G0TH8erPRKKKzxPjGTxucRrt/bRTKT45dnJgHL9usbivHNJ85w8vx0wes4E6NVXjDV4ipVPB5POQXUmp1+stZxjMaSbLAV/Uhs/tWxj5/U/nzh5LV73qPaPH1mgvufPcfTZc6JLJVyos5m4Izr/qC9zc0eYI+I/ExEDorIja7tEyLyXRH5hYh8yr5CKEBEPiAih0Xk8MjI4lK71gtaQVVD0YPVs/XgwBhKKb5+6BTnYyn+y9su4n3X7OB91+zgpss3L7vd2u7uJp44aXm3a73GjRt3UJ1rXkFXmzw+PD3rMe31utMkh6YSjn0yHyLCgZ0dHBoYtapWxgoDONjtDos8evfqWbAUvFb0kZDP+T+6oNVS9t/7xSBQfu/e/GRsYdZNa9jPVTs6ELFsjUzWWmC3u6sJn0f4gt0m0f0cWElFb3n0jqJvyHv36WyOqUTGWnvQHCSdVc4VRykODowS8Hm4rGgtRE9bmNHpVNW7uiXSWafb1+ce6q/qe1VKXvqAXuBa4BbgLhFptbe/FvgT4NXATuB9xU9WSt2plNqvlNrf2Vl+fvd6opqKHiz7Zmw6xbNnJ/nSowO8ZlcHr95e2YYgvV1NaIG0nqybDleBr7msm91devXvbPtGT4C6s2eGo8kFc9U1B3a2cz6W4vjItEup58fUUaKv7flY4X5a0Q9NFZZdCPq89mNJNrWE2FrmwqWw34tIoXUzOWMp5Zawn4s2Rjg4MMq9T7/EqdE4f/rmC/nNq7byvV+c5dRo/mSoA/1KZd1MzWSYnEnTEs5bN9b2tNNApr0p4PyN5ituZvnzrbPEl/4fOTtRXfNBr2jeu7GZh18Y5pnBiaq9VzlR5yzgLirdY29zMwjcp5RKK6VOAH1YgX8QeNq2fTLAvcAVyx71OqSaHj3kMy3+9NvPcD6W5CM39Fb8PXRwD/o8a6bZSDnohhg+j8wZnLfbcxClqk2WVvTJshQ9WFlRYAWWMVcw0nQ0za5gOTadIhzw0mCX2+2KhIgmMpwai8+aANZXKeX682BNOjYFfEWTsXmlfGBnB0+eGufzD/ezb1OEN+7r5g9ev8tS9Q/nVf3ETIrmoA//AhbWcgn6PPi94vTQ1Vk+7n6y511XSzpTaa4yCJMzaY68PNufB9e8R5XtG70o689u3EtLg5/PPlg9VV/Op/ME0CsiO0QkANwM3Fe0z71Yah4R2YBl2QzYz20VES3TrweOLH/Y6w99iVktRd/T1sDm1gZeOBfl6p0dXFWFhiDarllPGTeQ7wJ2QWvDnOP22XMQ/SUUvc7H1ieBTDbH6HSSzjIV/baOMBsjIQ4OjHLetmiKrZt4KltgFRS3A9SBq38oSnfR++qaN8Ve80I0hQoLm427atYc2NlOMpPj1GjcKX7XFQlxy5Vb+e4vznJ61FK7E/G8uq4mOpVSlwN3sm502uVMpmBeYyFF/0RR/rwbfeKstk+vX//Cjc28/7U7eOiFYZ4dnKzKey0YdWwlfivwAHAU+JZS6nkR+aSIvMPe7QFgVESOAI8AH1NKjSqlsli2zUMi8iwgwF3VOJC1jlb0S61cuRAi4vRu/cgbKq/mAbZvaMTvlXWzUMpNR2NgwbTD3u6mWaUkkpksE/E0jQGvUyZhdDqFUgsvltJYPn07h06MlawumV80lQ9Ko9OpgpNBlx24MjlF5yxFbx2XvnIol+LCZpPxlDOpeuWOdkRg36YIb9rX7ezzB9fuwusR3va5n3Dl3zzIvz/7ctX9eU2kwc+pMesE0+J49HlFr/9+HXbWDcxdBuGnx84T8HlK1irqbAoS8HqqnnkzOB7H5xG6IyHe+5rtlqp/qK8q71VW1R6l1P3A/UXbPuH6XQF/ZN+Kn/tD4NLlDXP9U22PHuD3X7+LS3tays68WCx+r4f/99cu5aJN68ef13z8LRcVLFwrxY4NjfzHc+fIZHNONo22ba7a2cHDLwwXlElYaLGUm6t2dnDv0y/xxMlxAl5PQTcrd818rSbHppN0NuUDutsmKrafbn71Vjqbg2xbZI/UpqIG4e789NZwgL9+5yVc1tNaYAd1R0J86l2XFuTZX7uEldZLIRLycXxk2hkf5BcjTrkawLc3Bgn5vbQ0+Esq+rHpFP98+Axv2tdd0kr1eMROsay+otdXmc0hPx99Qy/JTA6l1LITJ4qpnfJsa5xqe/RgXQJeuLG6Qfhddm2d9cYbXKp0Lja35hcf6YCrA8U1uzfw8AvD9A3FHB+7XEUPeYvgx/0jTm68psMO6O4J2dFYigu7820a3cG9eG5ga0d4Se0lm0J+Jz0ymckST2ULGnz/1lXbSj7vpss3c9PlxYl31SfSkG9o3uoIJ2sx4lQiQzKTwyMUfD6lPPov/2SAeDrLh+eZx9rc2lD1wmaD4/GCq8z3VaBF6FyYEggrhFYe1VT0huVRypsdsf35V29vc8okaM9+MYp+e0eY7kiQVCY3qymItmjG7MlEq3l4ig2uCdu2sB+/1zo5lJvtsxBW8xEr0OcLhVU3H345aLEEhSUXdE/m8zFrXkPXMuqOhGYp+vHpFF/9+Une+opN82aOrUQu/WBRt7NqYqLOCqGtm2oqesPy6HEKWuW/4LrkwKaWBqdMwvBUEhEKAvFC6Hx6mN39SWfgaI95OpWddUIQyWcMlZvtsxBNwbxH7+TDVzlNcjnohAagYAI40uAnmshYjVqKJrCL6938/U9PMJ3K8uHr55/H6mlr4HwsWZH+zKVIpLMMR5MrVi/KBPoVImIU/ZqnVCOP4WgCr0foaAzQ291M31CU4WiCjsaFV8UWoydLi8smWOmJ4lg3Y7HZE7aQbyZSKUXvzrpZqYVPy0Ereo/kyyxb261a9bMylSIhhqMJpw7ORDzFP/78JG97xaYFLc5qZ97oBjEr1YrTRJ0Vwij6tU+pRh5DU9akqMcjToOSk+fji/LnNTr9saOp8LkiQkdjkPNRK8Cfd2WPuOmOWI1MdG79cmkO+Zi2u0zpgmbVrkK5HPR3qKXBX1BqWpcqHnVVBQVcq2Otk9jf//QEsWSGD92wcPesngqXK/7cQ/0FE9h6sZSxbmqMre1hfu2KzVy9Ttrv1Ss9RQWtrAbgVvDQZRKePD2+JPtkx4ZGfvvANt588cZZj122pYUHjw4RTaQdRe8OWgC/dkUPv/crlZuwc0oVJzNOieJqr3BdDvqquLXoZKRLFY/GChV9Ppc+Yan5n53kLZdsZO/GCAtRSUWfzSk+82AfX/5Jvl2h0+1shRYemqybFcLv9fC37758tYdhWICetgYOn8r3jx12ZeDoMgmpTG5J9omI8FfvvKTkY7de18sDz/+Uf3rslJNWWWzdvPnijSVPEkul2dV8ZHI9WDcNOvWzcIzNIR+jsSRTiUzBVZBeQTw0leT+Z14mmszMm2njpqs5iN8rFQn0o9NJcgoOnRhzevQ6OfRLuDJcCkbRGwwu3I08oFDR6zIJULkJUc0reqxeAXf9ZIDT9qKgYuum0ugKlrFEhokZq2uTO79/raE9+uIJY6tvrDXX4J7/0CuI+4ei/IOt5i/atLCaByuX/oLWBsdiWQ56QjiayHDULlc9OD7DptbQoud5looJ9AaDC93IYyiaJJXJMTadctS7LpMA0LmI1Mpy+cgNvUzE03z1sZOE/B7CgeoGXXcFy3G7zk2lF+pUEp11U8q60bS7PXr7ZPzFHx1flJrXFNt4S2XY1dJQ+/SD4zMlm+BUCxPoDQYXziTcWJyRWGE3J8g3EqnGJfdlW1q57sJOoonMLH++GjQ5DcLtZh5r2LaBfEAvnkdwp1267a6Q30sk5GN0OsWNF5ev5jU9reGKWDda0TcHfU6LxsHxOJtXaCIWTKA3GApwT8LpVZXuapG9tk/fVQVFD/CRN+wBqm/bQKFHPzGTmqWU1xq6yUhxZpBb0RevbdCf02LVPFgn/ZFo+bn0Sinuefz0rEqkei3GGy/u5vETo8yksgxNJVcs4wZMoDcYCtCNPAbHZxwl5p54vfbCTvZubGZXZ2NV3v/yLa38+qt6eM2uDVV5fTc60EcTmYISxWuVjqYAl29p5YptrQXbIw1u66Yw0L+ut5PfvGor+y5YnJoHnOf84MhQWfufOD/N7d99lu88OViwfTiaoL0xwOt6O5lKZHj4Baub6kotlgKTdWMwFKAbeQyOx2lrtGumuBT9ZVta+f5tr6vqGD7165dV9fU1TnqlHeirXSdpufi9Hu794DWztuu0S5HZ/v0nfnXfrP3L5boLu9jT3cTnH+rnba/YtGBp7j671WSxrz80laSrOeh0//rOU9aJwCh6g2EV6WkLO4reWhW7MilwK02jPdkbTWaYiKfW9GKp+dCKvi0cqGifBI9H+PANvfQPx7j/2ZcX3P+YXeK62NcfiSboioTY1NLAto4wj/ZZ7VJNoDcYVpGetgYGJ+IMTSXY0FTZ4LGW8NjplOPTKaZT2TVv3cyF9uiLS0tUgrdesoneriY+91D/vI3Gwa3oCwP90FTSmbw/sKPDyaXfWKV5nlKYQG8wFNHT1sDLEwnOTSUWVaFyPdIU9Dm54ms962Yu9FxDsT9fCQpU/XPzq3rdgezsxIxTXyeXU4zEko79d2CXZd9sjKxcDj2YQG8wzGJza5hMTvHs2ckl1bRZTzSFfI6nvJZLFM9HyO8l6PNULVPpra/YxO4FVH02pzg+EiMc8Forje2SEqPTKbI55QgGXdhuJW0bMIHeYJiF/hJOxNNVS6NcKzSHfPk+rOvUugHY2dk0b3355eD1CB+8bhd9QzGePD1ecp/TY3FSmZyTLaXtG71YSguGC1ob2LcpwiWbW6oy1rkoK9CLyI0i8qKIHBOR2+fY590ickREnheRb7i2Z0XkaftW3FTcYFhzuNVWzSv6oI8ZO098vU7GAvzLB6/hQwvUmF8O113YhQgcPD5a8vE+u6n8dXs7gXzmjZOi6xIM3/vga/i/33pR1cZaigXTK0XEC9wBvBEYBJ4QkfuUUkdc+/QCHweuUUqNi4i7ieSMUuryyg7bYKgeF7hqhNe6R+/uo7tePXqAQJX7PLSGA1y0McLBE6N8iNknlGO2P6/7586l6MFK4V1pyvnrXAkcU0oNKKVSwD3ATUX7vB+4Qyk1DqCUGq7sMA2GlSPk9zpfzHpQ9JqWdRzoV4Krdrbz5KlxUpncrMf6hqJsbm3ggpYQzUGfE+j1qtjOVf4/KifQbwbOuO4P2tvc7AH2iMjPROSgiNzoeiwkIoft7e8s9QYi8gF7n8MjIyOLGb/BUBW0fVPril5XsPR6pKBrk2E2B3Z2kEjneGZwYtZj/UMxerubEBE2u4qhDUcTtIX9q6Li3VTqescH9ALXArcAd4lIq/3YNqXUfuA3gc+IyK7iJyul7lRK7VdK7e/s7KzQkAyGpaOXp9e8otfNPNZ45cq1wFU72i2ffqDQp9cZN71dVsE7veAO7Bz6NSAWygn0Z4Etrvs99jY3g8B9Sqm0UuoE0IcV+FFKnbV/DgA/Al65zDEbDFVnV2cTjQHvrLZ/tYZW8ca2WZjWcIALu5udCpSaM2NxkpkcvXbWj1Xe2MqlH44mV922gfIC/RNAr4jsEJEAcDNQnD1zL5aaR0Q2YFk5AyLSJiJB1/ZrgCMYDGuc979uB/d96FdqdlWsptml6A0Lc2BnB4dPjRX49DrjJq/oG4glM0zNZBheI4vuFgz0SqkMcCvwAHAU+JZS6nkR+aSIvMPe7QFgVESOAI8AH1NKjQIXAYdF5Jf29v/Pna1jMKxVwgEfuzqbVnsYVadpjj6shtJon/7ZsxPONr0i1q3owcqtH4km14T9V9bsi1LqfuD+om2fcP2ugD+yb+59fg68YvnDNBgM1UBn3RhFXx5X7rBKGBwcGONV26zf+4eiXNAScv6Wen7nmbMTZHJqTQR6szLWYKhjmo2iXxTtjQH2bmwumJDtH445ah7yiv6pUxPA2sjcMoHeYKhjdHrlel4stdIc2NnB4ZPjJNJZUpkcx4bzGTdgtTpsCvp4yi6X0FXhRvJLwSTOGgx1jO6/Wo3Kj7XKgZ3t/OPPT7L3//m+s81dZ0dE2NzawIv2JK27Q9lqYQK9wVDHbGwJccdvXsHr9lS/dWGtcP3ebv7L2y4inrJqBAV9Ht566aaCfXra8oF+LaRXmkBvMNQ5bysKUob5Cfg8/OfX7px3H+3Tt4b9hPyruyoWjEdvMBgMFWetraw2gd5gMBgqzFqrlWQCvcFgMFSYzXagXwv+PJhAbzAYDBUnb92sDUVvJmMNBoOhwrSF/XzszRfypn3dqz0UwAR6g8FgqDgiwgev273aw3Aw1o3BYDDUOCbQGwwGQ41jAr3BYDDUOCbQGwwGQ41jAr3BYDDUOCbQGwwGQ41jAr3BYDDUOCbQGwwGQ40jVrvXtYOIjACnlvESG4DzFRrOeqEejxnq87jr8ZihPo97sce8TSnVWeqBNRfol4uIHFZK7V/tcawk9XjMUJ/HXY/HDPV53JU8ZmPdGAwGQ41jAr3BYDDUOLUY6O9c7QGsAvV4zFCfx12Pxwz1edwVO+aa8+gNBoPBUEgtKnqDwWAwuDCB3mAwGGqcmgn0InKjiLwoIsdE5PbVHk+1EJEtIvKIiBwRkedF5CP29nYR+aGI9Ns/21Z7rJVGRLwi8gsR+Tf7/g4ROWR/5t8UkcBqj7HSiEiriHxbRF4QkaMicnWtf9Yi8lH7f/s5EblbREK1+FmLyFdEZFhEnnNtK/nZisXn7ON/RkSuWMx71USgFxEvcAfwFmAfcIuI7FvdUVWNDPDHSql9wAHgg/ax3g48pJTqBR6y79caHwGOuu7/N+DTSqndwDjwe6syquryWeD7Sqm9wGVYx1+zn7WIbAY+DOxXSl0CeIGbqc3P+h+BG4u2zfXZvgXotW8fAL64mDeqiUAPXAkcU0oNKKVSwD3ATas8pqqglHpZKfWU/XsU64u/Get4v2rv9lXgnasywCohIj3A24Av2/cFuB74tr1LLR5zC/A64O8BlFIppdQENf5ZY7U4bRARHxAGXqYGP2ul1I+BsaLNc322NwH/pCwOAq0isqnc96qVQL8ZOOO6P2hvq2lEZDvwSuAQ0K2Uetl+6BywNroSV47PAH8K5Oz7HcCEUipj36/Fz3wHMAL8g21ZfVlEGqnhz1opdRb4H8BprAA/CTxJ7X/Wmrk+22XFuFoJ9HWHiDQB3wFuU0pNuR9TVs5szeTNisjbgWGl1JOrPZYVxgdcAXxRKfVKYJoim6YGP+s2LPW6A7gAaGS2vVEXVPKzrZVAfxbY4rrfY2+rSUTEjxXkv66U+q69eUhfytk/h1drfFXgGuAdInISy5a7Hsu7brUv76E2P/NBYFApdci+/22swF/Ln/UbgBNKqRGlVBr4LtbnX+uftWauz3ZZMa5WAv0TQK89Mx/Amry5b5XHVBVsb/rvgaNKqb91PXQf8F779/cC/7LSY6sWSqmPK6V6lFLbsT7bh5VSvwU8ArzL3q2mjhlAKXUOOCMiF9qbbgCOUMOfNZZlc0BEwvb/uj7mmv6sXcz12d4H/I6dfXMAmHRZPAujlKqJG/BWoA84Dvz5ao+nisf5K1iXc88AT9u3t2J51g8B/cCDQPtqj7VKx38t8G/27zuBx4FjwD8DwdUeXxWO93LgsP153wu01fpnDfwl8ALwHPA1IFiLnzVwN9Y8RBrr6u335vpsAcHKLDwOPIuVlVT2e5kSCAaDwVDj1Ip1YzAYDIY5MIHeYDAYahwT6A0Gg6HGMYHeYDAYahwT6A0Gg6HGMYHeYDAYahwT6A0Gg6HG+d9as66f1lN1jwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rates = []\n",
    "\n",
    "for i in np.arange(1, 101):\n",
    "    new_model = KNeighborsClassifier(n_neighbors = i)\n",
    "    new_model.fit(X_train, y_train2)\n",
    "    model2 = KNeighborsClassifier(n_neighbors = 5)\n",
    "    model2.fit(X_train, y_train2)\n",
    "    new_predictions = new_model.predict(X_test)\n",
    "    error_rates.append(np.mean(new_predictions != y_test2))\n",
    "\n",
    "plt.plot(error_rates);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=95)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = KNeighborsClassifier(n_neighbors = np.argmin(error_rates))\n",
    "model2.fit(X_train, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.60      0.45       127\n",
      "           1       0.35      0.40      0.37       156\n",
      "           2       0.28      0.14      0.18        88\n",
      "           3       0.00      0.00      0.00        43\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.35       433\n",
      "   macro avg       0.11      0.13      0.11       433\n",
      "weighted avg       0.29      0.35      0.30       433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 2, 0, 0, 1, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       2, 1, 0, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 2, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 0, 0, 0, 0,\n",
       "       0, 0, 2, 0, 0, 0, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0, 2, 0, 1, 0, 0, 2,\n",
       "       0, 1, 1, 2, 1, 0, 1, 2, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 2, 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2,\n",
       "       0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 2, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 2, 1, 1, 0, 1, 2, 2, 2,\n",
       "       0, 1, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0,\n",
       "       1, 2, 0, 0, 1, 1, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       2, 2, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 2, 0, 2, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.logical_and(predictions1, predictions2)\n",
    "test_pred = [0 if x==False else x for x in test_pred]\n",
    "test_pred = [1 if x==True else x for x in test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1979    0\n",
       "1980    0\n",
       "1981    1\n",
       "1982    0\n",
       "1983    0\n",
       "       ..\n",
       "2465    1\n",
       "2466    1\n",
       "2467    0\n",
       "2468    1\n",
       "2469    1\n",
       "Name: category, Length: 433, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_real_value = train_df['category'][int(len(Y_expected1)*0.8):len(Y_expected1)]\n",
    "test_real_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.51\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for elem1, elem2 in zip(test_pred, test_real_value):\n",
    "    if elem1 == elem2:\n",
    "        acc += 1\n",
    "print(\"ACC: \", np.round((acc / len(test_real_value)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKm-keClFa1Q"
   },
   "source": [
    "# Make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-1158d68a9594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfin_pred1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtmp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfin_pred1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtmp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\egor\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "fin_pred1 = model1.predict(test_df)\n",
    "tmp1 = []\n",
    "for i in fin_pred1:\n",
    "    if i.argmax() != 0:\n",
    "        tmp1.append(1)\n",
    "    else:\n",
    "        tmp1.append(0)\n",
    "\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_pred2 = model2.predict(test_df)\n",
    "tmp2 = []\n",
    "for i in fin_pred2:\n",
    "    if i.argmax() != 0:\n",
    "        tmp2.append(1)\n",
    "    else:\n",
    "        tmp2.append(0)\n",
    "\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer = np.logical_and(tmp1, tmp2)\n",
    "Answer = [0 if x==False else x for x in Answer]\n",
    "Answer = [1 if x==True else x for x in Answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_b27gGlzPE2w"
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission['tmp'] = Answer\n",
    "sample_submission.drop(['category'], axis = 1, inplace= True)\n",
    "sample_submission = sample_submission.rename(columns={\"tmp\": \"category\"})\n",
    "sample_submission.to_csv('Answer.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
